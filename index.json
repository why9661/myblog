[{"categories":["Golang"],"content":"Go的标准库有几个内置的Handler：NotFoundHandler、RedirectHandler、StripPrefix、TimeoutHandler、FileServer。\nhttp.NotFoundHandler\n1func NotFound(w ResponseWriter, r *Request) { Error(w, \u0026#34;404 page not found\u0026#34;, StatusNotFound) 2func NotFoundHandler() Handler { return HandlerFunc(NotFound) } NotFoundHandler非常简单，直接返回“404 page not found”以及状态码404。\neg:\n1http.Handle(\u0026#34;/a\u0026#34;, http.NotFoundHandler()) //访问localhost:8080/a 404 2http.Handle(\u0026#34;/b\u0026#34;, http.NotFoundHandler()) //访问localhost:8080/b 404 3http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) http.RedirectHandler\n1func RedirectHandler(url string, code int) Handler {...} RedirectHandler会返回一个Handler，这个Handler会将请求重定向到指定的url，并响应指定的状态码(3XX)。\neg:\n1http.HandleFunc(\u0026#34;/hello\u0026#34;, func(w http.ResponseWriter, r *http.Request) { 2\tw.Write([]byte(\u0026#34;Hello\u0026#34;)) 3}) 4http.Handle(\u0026#34;/\u0026#34;, http.RedirectHandler(\u0026#34;http://localhost:8080/hello\u0026#34;,http.StatusMovedPermanently)) 5http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) 访问localhost:8080/会跳转到localhost:8080/hello并响应301。\nhttp.StripPrefix\n1func StripPrefix(prefix string, h Handler) Handler {...} StripPrefix会将请求路径中的prefix移除掉，再交由传入的Handler处理，如果请求路径中不包含prefix，那么会返回404。\neg:\n1type helloHandler struct{} 2 3func (h *helloHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { 4\tw.Write([]byte(r.URL.Path)) 5} 6 7func main() { 8\th := helloHandler{} 9\thttp.Handle(\u0026#34;/prefix/hello\u0026#34;, http.StripPrefix(\u0026#34;/prefix\u0026#34;, \u0026amp;h)) 10\thttp.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) 11} 访问localhost:8080/prefix/hello，会显示/hello，即把原请求路径中的“/prefix”移除掉再交给传入的Handler执行。\nhttp.TimeoutHandler\n1func TimeoutHandler(h Handler, dt time.Duration, msg string) Handler {...} TimeoutHandler会返回一个Handler，用来在指定时间dt内执行传入的Handler，如果超时会将msg返回并相应503。\neg:\n1type helloHandler struct{} 2 3func (h *helloHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { 4\ttime.Sleep(2 * time.Second) 5\tw.Write([]byte(\u0026#34;Hello\u0026#34;)) 6} 7 8func main() { 9\th := helloHandler{} 10\thttp.Handle(\u0026#34;/hello\u0026#34;, http.TimeoutHandler(\u0026amp;h, time.Second, \u0026#34;Timeout!\u0026#34;)) 11\thttp.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) 12} 访问localhost:8080/hello，返回Timeout!并响应503。\nhttp.FileServer\n1func FileServer(root FileSystem) Handler {...} 2type FileSystem interface { 3\tOpen(name string) (File, error) 4} 5type Dir string //实现了FileSystem接口 FileServer返回一个Handler，使用基于root的文件系统来处理请求。\nFileSystem是一个接口，而http.Dir实现了这个接口\neg:\n文件目录如下\n1--front 2\tindex.html 3--main.go 1func main() { 2\thttp.ListenAndServe(\u0026#34;:8080\u0026#34;, http.FileServer(http.Dir(\u0026#34;front\u0026#34;))) 3} 访问localhost:8080/index.html，会定位到front目录下的index.html。\n","date":"2021-09-01","permalink":"https://why9661.github.io/myblog/posts/golang/web/%E5%86%85%E7%BD%AEhandler/","series":null,"tags":["Golang"],"title":"Golang-Web编程之内置Handler"},{"categories":["Golang"],"content":"简介 Go的自动垃圾回收采用标记清扫算法，支持主体并发增量式回收，使用插入删除两种写屏障结合的混合写屏障。\n标记-清扫算法 标记清扫算法是最常见的垃圾收集算法，标记清扫收集器是跟踪式垃圾收集器，其执行过程可以分成标记和清扫两个阶段：\n  标记阶段 — 从根对象(栈、数据段上的对象)出发追踪并标记堆中所有存活的对象；\n  清扫阶段 — 遍历堆中的全部对象，回收未被标记的垃圾对象并将回收的内存加入空闲链表；\n  三色抽象 垃圾回收开始时所有数据都为白色，然后将根节点标记为灰色，灰色表示基于当前节点展开的追踪还未完成，当基于某个节点的追踪完成后将其标记为黑色，表示它是存活数据也不需要基于该节点再次进行追踪。当没有灰色节点时代表标记工作结束，存活对象都为黑色，垃圾对象都为白色。\nSTW\nSTW(Stop The World)即暂停用户程序只专注于垃圾回收。\n长时间STW进行垃圾回收是不合理的，所以通常是使用增量式垃圾回收。在增量式垃圾回收中，可能出现之前STW时标记为黑色的对象由于后面用户程序中的修改，到下一次STW标记时出现了黑色对象到白色对象的引用，同时又没有灰色对象指向这个白色对象，那么这个白色对象就会被误判为垃圾。\n强三色不变式：禁止出现黑色对象到白色对象的引用。\n弱三色不变式：存在黑色对象到白色对象的引用，但必须有灰色对象到该白色对象的引用。\n实现强弱三色不变式的通常做法是建立读写屏障。\n读写屏障 内存屏障技术是一种屏障指令，它可以让 CPU 或者编译器在执行内存相关操作时遵循特定的约束，目前多数的现代处理器都会乱序执行指令以最大化性能，但是该技术能够保证内存操作的顺序性，在内存屏障前执行的操作一定会先于内存屏障后执行的操作。\n垃圾收集中的屏障技术更像是一个钩子方法，它是在用户程序读取对象、创建新对象以及更新对象指针时执行的一段代码，根据操作类型的不同，我们可以将它们分成读屏障（Read barrier）和写屏障（Write barrier）两种，因为读屏障需要在读操作中加入代码片段，对用户程序的性能影响很大，所以编程语言往往都会采用写屏障保证三色不变性。\n插入写屏障：插入写屏障保证不会出现黑色到白色对象的引用，因此出现黑色对象到白色对象的引用时，可以将黑色对象退回为灰色，或者将白色对象变为灰色。\n删除写屏障：删除写屏障针对的是到白色对象的路径被破坏的行为，如一个灰色对象到白色对象的引用被删除，那么将这个白色对象变为灰色。\n增量和并发 增量式垃圾回收：用户程序和垃圾回收程序交替执行。增量式垃圾回收可以减少每次STW的时间，但会增加一次完整GC的总时间。\n并发垃圾回收：利用多核资源，使用户程序和垃圾回收并行执行。并发垃圾回收不仅能够减少每一次STW的时间，也能减少整个一次GC的时间。\n触发时机 手动触发\nruntime.GC()\n分配内存\n1、分配大对象时（\u0026gt;32KB）一定会尝试触发GC\n2、创建微对象、小对象需要从中心缓存或页堆中获取时，可能会触发\n超过特定时间\n在程序初始化时，会创建一个用于强制执行GC的协程（创建后进入休眠）。监控线程检测到距离上次GC超过指定时间时，会将这个协程添加到全局队列中，等到它调度执行时就会开启GC\n","date":"2021-08-30","permalink":"https://why9661.github.io/myblog/posts/golang/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","series":null,"tags":["Golang"],"title":"Golang-GC"},{"categories":["Redis"],"content":"RDB RDB做全量持久化，把数据以快照的形式保存在磁盘上，恢复时是将快照文件直接读到内存里。\nRDB保存的文件默认为dump.rdb。\n配置 SNAPSHOTTING\n 用来配置触发 Redis的持久化条件，也就是什么时候将内存中的数据保存到硬盘,如果只是用Redis的缓存功能，不需要持久化，那么可以注释掉所有的 save 行来停用保存功能。默认如下配置：  1save 900 1：表示900 秒内如果至少有 1 个 key 的值变化，则保存 2save 300 10：表示300 秒内如果至少有 10 个 key 的值变化，则保存 3save 60 10000：表示60 秒内如果至少有 10000 个 key 的值变化，则保存   stop-writes-on-bgsave-error ：最新的一次后台存储如果失败了,那么Redis是否停止接收新的写入。\n  rdbcompression ；默认值是yes。对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能，但是存储在磁盘上的快照会比较大。\n  rdbchecksum ：默认值是yes。在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。\n  dbfilename ：设置快照的文件名，默认是 dump.rdb。\n  dir：设置快照文件的存放路径(目录名)。\n  过程 Redis 使用操作系统的多进程 cow(Copy On Write) 机制来实现RDB快照持久化\n 执行bgsave命令的时候，Redis主进程会检查是否有子进程在执行RDB/AOF持久化任务，如果有的话，直接返回。 Redis主进程会fork一个子进程来执行执行RDB操作，fork操作会对主进程造成阻塞（影响Redis的读写），fork操作完成后会发消息给主进程，从而不再阻塞主进程。（阻塞仅指主进程fork子进程的过程，后续子进程执行操作时不会阻塞）。 RDB子进程会根据Redis主进程的内存生成临时的快照文件，持久化完成后会使用临时快照文件替换掉原来的RDB文件。（该过程中主进程的读写不受影响，但Redis的写操作不会同步到主进程的主内存中，而是会写到一个临时的内存区域作为一个副本）。 子进程完成RDB持久化后会发消息给主进程，通知RDB持久化完成（将上阶段内存副本中的增量写数据同步到主内存）。  触发   手动触发\nsave命令\n同步，在主线程中保存快照；阻塞当前Redis服务器，直到RDB过程完成为止，对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用。\nbgsave命令\n异步，Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短；BGSAVE命令是针对SAVE堵塞问题做的优化。因此Redis内部所有的设计RDB的操作都采用BGSAVE的方式，而save命令已经废弃。\n  自动触发\n根据配置文件的策略自动触发bgsave。\n  其它触发\n 如果从节点执行全量复制操作，主节点自动执行BGSAVE生成RDB文件并发送给从节点。 默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则自动执行BGSAVE。    优缺点   优点\n适合定时备份和灾难恢复,在恢复大数据集的时候比AOF的速度快。\n  缺点\n会丢失数据。\n  AOF 全量备份总是耗时的，AOF是一种更高效的方式，与RDB持久化通过保存数据库中的键值对来记录数据库状态不同，AOF持久化是增量持久化，通过保存Redis所执行的写命令来记录数据库状态的。redis会将每一个收到的写命令都通过write函数追加到文件中(默认文件appendonly.aof)。\n配置 APPEND ONLY MODE\n appendonly yes: 是否启用aof持久化方式。 appendfsync always: 每次收到写命令就立即强制写入磁盘，最慢的，但是保证完全的持久化，不推荐使用。 appendfsync everysec: 每秒钟强制写入磁盘一次，在性能和持久化方面做了很好的折中，推荐。 appendfsync no: 完全依赖os，性能最好,持久化没保证。 auto-aof-rewrite-percentage 100: 默认值为100。aof自动重写配置，当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，即当aof文件增长到一定大小的时候，Redis能够调用bgrewriteaof对日志文件进行重写。当前AOF文件大小是上次日志重写得到AOF文件大小的一倍（设置为100）时，自动启动新的日志重写过程。 auto-aof-rewrite-min-size 64mb: 设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写。  重写 由于AOF持久化是Redis不断将写命令记录到 AOF 文件中，随着Redis不断的进行，AOF 的文件会越来越大，文件越大，占用服务器内存越大以及 AOF 恢复要求时间越长。为了解决这个问题，Redis新增了重写机制，当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。\n重写过程可手动触发（redis-cli -h ip -p port bgrewriteaof）或自动触发（配置文件）。\n过程如下：\n①redis调用fork创建，现在有父子两个进程\n②子进程根据内存中的数据库快照，往临时文件中写入重建数据库状态的命令\n③父进程继续处理client请求，除了把写命令写入到原来的aof文件中。同时把收到的写命令缓存起来。这样就能保证如果子进程重写失败的话并不会出问题。\n④当子进程把快照内容写入已命令方式写到临时文件中后，子进程发信号通知父进程。然后父进程把缓存的写命令也写入到临时文件。\n⑤现在父进程可以使用临时文件替换老的aof文件，并重命名，后面收到的写命令也开始往新的aof文件中追加。\n需要注意重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件。\n优缺点   优点\n保证数据完整性更好。\n  缺点\n数据文件通常比RDB大,性能不如RDB。\n  混合持久化 当开启混合持久化时，主进程先fork出子进程将现有内存副本全量以RDB方式写入aof文件中，然后将缓冲区中的增量命令以AOF方式写入aof文件中，写入完成后通知主进程更新相关信息，并将新的含有 RDB和AOF两种格式的aof文件替换旧的aof文件。\n简单来说：混合持久化方式产生的文件一部分是RDB格式，一部分是AOF格式。\n配置  aof-use-rdb-preamble:yes表示开启，设置为no表示禁用。 ","date":"2021-08-28","permalink":"https://why9661.github.io/myblog/posts/redis/%E6%8C%81%E4%B9%85%E5%8C%96/","series":null,"tags":["Redis"],"title":"Redis-持久化"},{"categories":["redis"],"content":"哨兵模式 在Redis的主从模式下，一旦主节点由于故障不能提供服务（单点故障），需要人工将从节点晋升为主节点，在这段时间内，Redis不能提供正常服务。\nRedis Sentinel是一个分布式架构，其中包含若干个Sentinel节点和Redis数据节点，每个Sentinel节点会对数据节点和其余Sentinel节点进行监控，当它发现节点不可达时，会对节点做下线标识。如果被标识的是主节点，它还会和其他Sentinel节点进行“协商”，当大多数Sentinel节点都认为主节点不可达时，它们会选举出一个Sentinel节点来完成自动故障转移的工作，如将一个从节点晋升为主节点，同时会将这个变化通知给Redis应用方。整个过程完全是自动的，不需要人工来介入，所以哨兵模式能效地解决Redis的高可用问题。\n过程 三个定时监控任务\n1）每隔10秒，每个Sentinel节点会向主节点和从节点发送info命令获取最新的拓扑结构。\n2）每隔2秒，每个Sentinel节点会向Redis数据节点的__sentinel__:hello频道上发送该Sentinel节点对于主节点的判断以及当前Sentinel节点的信息，同时每个Sentinel节点也会订阅该频道，来了解其他Sentinel节点以及它们对主节点的判断。\n3）每隔1秒，每个Sentinel节点会向主节点、从节点、其余Sentinel节点发送一条ping命令做一次心跳检测，来确认这些节点当前是否可达。\n主观下线 因为每隔一秒，每个Sentinel节点会向主节点、从节点、其余Sentinel节点发送一条ping命令做一次心跳检测，当这些节点超过down-after-milliseconds没有进行有效回复，Sentinel节点就会对该节点做失败判定，这个行为叫做主观下线。\n客观下线 当Sentinel主观下线的节点是主节点时，该Sentinel节点会向其他Sentinel节点询问对主节点的判断，当超过个数，那么意味着大部分的Sentinel节点都对这个主节点的下线做了同意的判定，于是该Sentinel节点认为主节点确实有问题，这时该Sentinel节点会做出客观下线的决定。\n领导者Sentinel节点选举 Raft算法。\n故障转移 1）领导者Sentinel节点在从节点列表中选出一个节点作为新的主节点\n2）上一步的选取规则是与主节点复制相似度最高的从节点\n3）领导者Sentinel节点让剩余的从节点成为新的主节点的从节点\n4）Sentinel节点集合会将原来的主节点更新为从节点，并保持着对其关注，当其恢复后命令它去复制新的主节点\n配置 sentinel.conf\n哨兵节点1配置\n1port 26379 2daemonize yes 3pidfile /var/run/redis-sentinel_26379.pid 4logfile \u0026#34;26379.log\u0026#34; 5sentinel monitor mymaster 127.0.0.1 6379 2 哨兵节点2配置\n1port 26380 2daemonize yes 3pidfile /var/run/redis-sentinel_26380.pid 4logfile \u0026#34;26380.log\u0026#34; 5sentinel monitor mymaster 127.0.0.1 6379 2 哨兵节点3配置\n1port 26381 2daemonize yes 3pidfile /var/run/redis-sentinel_26381.pid 4logfile \u0026#34;26381.log\u0026#34; 5sentinel monitor mymaster 127.0.0.1 6379 2 哨兵节点启动\n1redis-sentinel sentinel26379.conf 2redis-sentinel sentinel26380.conf 3redis-sentinel sentinel26381.conf 查看节点状态\n测试\n将6379主节点shutdown，发现6380从节点变为master\n6379节点重新启动后，变为slave\n","date":"2021-08-12","permalink":"https://why9661.github.io/myblog/posts/redis/%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/","series":null,"tags":["redis"],"title":"Redis-哨兵模式"},{"categories":["Redis"],"content":"主从模式 主从模式可降低读写压力，Master以写为主，Slave以读为主，Master节点更新后根据配置自动同步到Slave节点。\n过程   全量复制\nRedis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下：\n　1）从服务器连接主服务器，发送SYNC命令；\n　2）主服务器接收到SYNC命令后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令；\n　3）主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令；\n　4）从服务器收到快照文件后丢弃所有旧数据，载入收到的快照；\n　5）主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令；\n　6）从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；\n  增量复制\nRedis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。\n增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。\n  配置 REPLICATION\n  replicaof ：添加Master节点的ip和端口。\n  slave-serve-stale-data：默认值为yes。当一个 slave 与 master 失去联系，或者复制正在进行的时候，slave 可能会有两种表现：\n 如果为 yes ，slave 仍然会应答客户端请求，但返回的数据可能是过时，或者数据可能是空的在第一次同步的时候 如果为 no ，在你执行除了 info he salveof 之外的其他命令时，slave 都将返回一个 \u0026ldquo;SYNC with master in progress\u0026rdquo; 的错误    slave-read-only：配置Redis的Slave实例是否接受写操作，即Slave是否为只读Redis。默认值为yes。\n  除此之外，还需配置端口port、pid文件pidfile、log文件logfile、持久化文件路径dir等选项。\n例子 主节点6379配置\n1port 6379 2daemonize yes 3pidfile /var/run/redis_6379.pid 4logfile \u0026#34;6379.log\u0026#34; 5dir ./ 从节点6380配置\n1port 6380 2daemonize yes 3pidfile /var/run/redis_6380.pid 4logfile \u0026#34;6380.log\u0026#34; 5dir ./ 6replicaof 127.0.0.1 6379 从节点6381配置\n1port 6381 2daemonize yes 3pidfile /var/run/redis_6381.pid 4logfile \u0026#34;6381.log\u0026#34; 5dir ./ 6replicaof 127.0.0.1 6379 分别启动\n1redis-server /usr/local/redis/master6379/redis.conf 2redis-server /usr/local/redis/slave6380/redis.conf 3redis-server /usr/local/redis/slave6381/redis.conf 查看节点状态\n一些测试(就不截图了)\n 增量复制：主从节点启动后，主节点写，看从节点是否同步 全量复制：主节点先写入一些数据，启动从节点看是否同步 从节点只读 主节点宕机：主节点宕机后从节点角色还是slave，主节点恢复后还是master； ","date":"2021-08-11","permalink":"https://why9661.github.io/myblog/posts/redis/%E4%B8%BB%E4%BB%8E%E6%A8%A1%E5%BC%8F/","series":null,"tags":["Redis"],"title":"Redis-主从模式"},{"categories":["algorithm"],"content":"LRU LRU（Least Recently Used）即最近最少使用。相较于仅考虑时间因素的 FIFO 和仅考虑访问频率的 LFU，LRU 算法可以认为是相对平衡的一种淘汰算法。\nLRU 算法的实现比较简单，维护一个队列，如果某条记录被访问了，则移动到队尾，那么队首则是最近最少访问的数据，淘汰该条记录即可。\nGolang实现\n1package lru 2 3import \u0026#34;container/list\u0026#34; 4 5type Lru struct { 6 mBytes int64 // max memory allowed 7 nbytes int64 // used memory 8 queue *list.List // double linked list 9 cache map[string]*list.Element // k-v map 10 OnEvicted func(key string, value Value) //callback function executed when an entry is purged 11} 12 13type entry struct { 14 key string 15 value Value 16} 17 18type Value interface { 19 Len() int 20} 21 22func New(mBytes int64, onEvicted func(string, Value)) *Lru { 23 return \u0026amp;Lru{ 24 mBytes: mBytes, 25 queue: list.New(), 26 cache: make(map[string]*list.Element), 27 OnEvicted: onEvicted, 28 } 29} 30 31// Get looks up a key\u0026#39;s value from the cache 32func (l *Lru) Get(key string) (value Value, ok bool) { 33 if l.cache == nil { 34 return 35 } 36 if ele, ok := l.cache[key]; ok { 37 value = ele.Value.(*entry).value 38 l.queue.MoveToFront(ele) 39 return value, true 40 } 41 return 42} 43 44//Remove removes key\u0026#39;s value from the cache 45func (l *Lru) Remove(key string) { 46 if l.cache == nil { 47 return 48 } 49 if ele, ok := l.cache[key]; ok { 50 l.RemoveElement(ele) 51 } 52} 53 54func (l *Lru) RemoveElement(ele *list.Element) { 55 e := ele.Value.(*entry) 56 delete(l.cache, e.key) 57 l.queue.Remove(ele) 58 l.nbytes -= int64(len(e.key)) + int64(e.value.Len()) 59 if l.OnEvicted != nil { 60 l.OnEvicted(e.key, e.value) 61 } 62} 63 64//RemoveOldest removes the oldest item from the cache 65func (l *Lru) RemoveOldest() { 66 ele := l.queue.Back() 67 if ele != nil { 68 e := ele.Value.(*entry) 69 delete(l.cache, e.key) 70 l.queue.Remove(ele) 71 l.nbytes -= int64(len(e.key)) + int64(e.value.Len()) 72 if l.OnEvicted != nil { 73 l.OnEvicted(e.key, e.value) 74 } 75 } 76} 77 78//Add adds a value to the cache (or update the provided key\u0026#39;s value) 79func (l *Lru) Add(key string, value Value) { 80 if ele, ok := l.cache[key]; ok { 81 l.queue.MoveToFront(ele) 82 e := ele.Value.(*entry) 83 l.nbytes += int64(value.Len()) - int64(e.value.Len()) 84 e.value = value 85 } else { 86 ele := l.queue.PushFront(\u0026amp;entry{key: key, value: value}) 87 l.cache[key] = ele 88 l.nbytes += int64(len(key)) + int64(value.Len()) 89 } 90 for l.nbytes \u0026gt; l.mBytes { 91 l.RemoveOldest() 92 } 93} 94 95//Len returns the number of items in the cache 96func (l *Lru) Len() int { 97 return l.queue.Len() 98} ","date":"2021-07-16","permalink":"https://why9661.github.io/myblog/posts/algorithm/lru/","series":null,"tags":["缓存淘汰策略"],"title":"缓存淘汰策略-LRU"},{"categories":["Golang"],"content":"GPM简介 G表示Goroutine，是Go语言调度的基本单位，可以认为是一种用户态的线程，与普通线程相比，Goroutine上下文切换在用户态可以减少开销，同时Goroutine本身是KB级别，而普通线程是MB级别。\nP表示处理器，可以认为是运行在线程上的本地调度器。P的数量由环境变量GOMAXPROCS决定，在程序初始化时创建。\nM表示操作系统线程，由操作系统的调度器调度和管理。最多可以创建10000个线程，但是同时只能有最多GOMAXPROCS个活跃线程能够正常运行。\ng0是一个特殊的Goroutine，会深度参与到运行时的调度。\nm0是主线程对应的M，调度器初始化时时m0会与allp[0]绑定，程序一开始m0上执行的就是g0。\nG的状态\n   状态 描述     _Gidle 刚刚被分配并且还没有被初始化   _Grunnable 没有执行代码，没有栈的所有权，存储在运行队列中   _Grunning 可以执行代码，拥有栈的所有权，被赋予了内核线程 M 和处理器 P   _Gsyscall 正在执行系统调用，拥有栈的所有权，没有执行用户代码，被赋予了内核线程 M 但是不在运行队列上   _Gwaiting 由于运行时而被阻塞，没有执行用户代码并且不在运行队列上，但是可能存在于 Channel 的等待队列上   _Gdead 没有被使用，没有执行代码，可能有分配的栈   _Gcopystack 栈正在被拷贝，没有执行代码，不在运行队列上   _Gpreempted 由于抢占而被阻塞，没有执行用户代码并且不在运行队列上，等待唤醒   _Gscan GC 正在扫描栈空间，没有执行代码，可以与其他状态同时存在    M的状态\n运行中、自旋、休眠。\nP的状态\n   状态 描述     _Pidle 处理器没有运行用户代码或者调度器，被空闲队列或者改变其状态的结构持有，运行队列为空   _Prunning 被线程 M 持有，并且正在执行用户代码或者调度器   _Psyscall 没有执行用户代码，当前线程陷入系统调用   _Pgcstop 被线程 M 持有，当前处理器由于垃圾回收被停止   _Pdead 当前处理器已经不被使用    程序初始化 在程序初始化过程中，会进行调度器初始化，此时会根据GOMAXPROCS这个环境变量决定创建多少个P，并将m0和allp[0]关联起来。此后会创建main goroutine，然后开启调度循环。当main goroutine被调度执行时，会以runtime.main作为执行入口，执行创建监控线程(sysmon)、包初始化(init)等工作，然后会调用用户编写的main.main。\nGoroutine创建 启动一个新的Goroutine需要使用go关键字，编译器会将go关键字转化为newproc函数调用。newproc函数首先会调用newproc1函数获取Goroutine结构体，在newproc1函数中：\n1、从当前G所在p的gFree列表或者调度器sched的gFree列表获取Goroutine:\n​\t①当处理器的Goroutine列表为空时，会将调度器持有的空闲Goroutine转移到当前处理器上，直到gFree 列表中的 Goroutine 数量达到 32；\n​ ②当处理器的Gorontine数量充足时，会从列表头部返回一个新的Goroutine。\n2、当调度器的gFree和处理器的gFree列表都不存在结构体时，会调用runtime.malg创建一个新的runtime.g并追加到全局的G列表allgs中，此时这个Goroutine的状态是_Gdead。\n3、newproc1会将Goroutine置为_Grunnable状态并赋goid。\nnewproc会调用runtime.runqput将G放到运行队列中。G会优先加入到P的本地队列，如果P的本地队列已满，会将本地队列中前一半的G和新创建的G打乱顺序添加到全局队列中。如果此时系统中有空闲的P并且没有自旋状态的M，那么会启动一个M并置为spinning状态与空闲的P关联开始调度循环寻找G执行。\n调度循环 函数runtime.schedule负责调度的逻辑：\n1、当全局运行队列中有待执行的G时，有较小的概率会从全局队列中获取G\n2、从p的本地队列获取G\n3、如果1、2都没有获取到G，那么会通过runtime.findrunnable寻找G，直到获取到带运行的G才会返回：\n​\t①从本地队列获取\n​\t②从全局队列获取\n​ ③轮询查找是否有G等待运行（IO事件就绪）\n​ ④从其它P的本地队列中窃取一半的G\n获取到G后开始执行，当G中的函数返回时会执行runtime.goexit，最终会在当前m的g0栈上执行goexit0函数，该函数会将G转换为_Gdead状态、清理其中的字段、移除G和线程的关联并调用runtime.gfput重新加入处理器的G空闲列表gFree。在最后runtime.goexit0会重新调用runtime.schedule触发新一轮的调度。\n触发调度时机   协程创建/结束时\n新的协程创建时可能会触发调度循环(当系统中有空闲P时)。\n协程执行结束时，goexit0会触发调度。\n   抢占    主动挂起\n如time.Sleep、channel阻塞，这些操作最终调用gopark函数最终将Goroutine从_Grunning切换至_Gwaiting，移除当前线程和G的关联，并触发一次新的调度循环。\n当Goroutine等待的特定条件满足后，将Goroutine唤醒并将准备就绪的Goroutine切换至_Grunnable，加入运行队列等待调度。\n  系统调用\n文件IO、网络IO。在陷入系统调用之前，当前M会与当前P分离(变为_Psyscall状态)，监控线程发现这个P在一定时间没有执行时，会重新启动一个M与之关联，从而发生新的调度循环。\n当M从系统调用中恢复时，会先检测之前绑定的P是否被占用，如果没有被占用，那么就获取这个P继续使用，否则会去P的空闲队列中申请一个，如果没有申请到的话，那么会把G放到全局队列中，M休眠。\n    GC之后\nSTW之后，会重新选择G开始执行。\n  抢占   基于协作的抢占式调度\n这种基于协作的抢占式调度在Go1.2引入，监控线程sysmon会对运行时间过长P（G运行时间超过10ms）执行抢占操作，而这个抢占操作与栈增长有关。\n  Go编译器会在调用函数前在函数头部插入runtime.morestack；\n  Go 语言运行时会在垃圾回收暂停程序、系统监控发现 Goroutine 运行超过 10ms 时发出抢占请求，通过栈增长的相关代码将Goroutine的stackguard0字段设置为StackPreempt；\n  当发生函数调用时，可能会执行编译器插入的runtime.morestack，它调用的runtime.newstack会检查 Goroutine 的stackguard0字段是否为StackPreempt；如果stackguard0是StackPreempt就会触发协程调度从而使Goroutine让出当前线程实现抢占；\n  这种抢占方式依赖栈增长代码。如果有一个空的for{}，与栈增长无关，那么上面的逻辑就无法得到执行，程序最终会卡死。\n  基于信号的抢占式调度\n基于信号的抢占式调度在Go1.4中引入。\n未完待续\u0026hellip;\n ","date":"2021-07-08","permalink":"https://why9661.github.io/myblog/posts/golang/gpm%E8%B0%83%E5%BA%A6/","series":null,"tags":["Golang"],"title":"Golang-GPM调度"},{"categories":["Protobuf"],"content":"简介 ProtoBuf 即 Protocol Buffers，是一种轻便高效的结构化数据存储格式，与语言、平台无关，可扩展可序列化。ProtoBuf 性能和效率大幅度优于 JSON、XML 等其他的结构化数据格式。ProtoBuf 是以二进制方式存储的，占用空间小，但也带来了可读性差的缺点。\n安装 https://github.com/protocolbuffers/protobuf/releases\r加入到环境变量。\nprotoc \u0026ndash;version验证是否安装成功。\n在 Golang 中使用 protobuf，还需要安装 protoc-gen-go，这个工具用来将 .proto 文件转换为 Go代码。\n1go get -u github.com/golang/protobuf/protoc-gen-go 这会自动安装到$GOPATH/bin下，同样加入到环境变量。\n使用 一个小例子\n创建.proto文件\n1syntax = \u0026#34;proto3\u0026#34;; 2package pb;3option go_package = \u0026#34;./\u0026#34;;45message Person {6 string name = 1;7 int32 age = 2;8 repeated string hobbies = 3;9}根据.proto文件生成代码\n1protoc --go_out=$DST_DIR $SRC_DIR/xxx.proto \u0026ndash;go_out表示生成Go代码\n$DST_DIR表示生成代码的目录\n$SRC_DIR/xxx.proto表示具体的proto文件\n1... 2type Person struct { 3 ... 4 5 Name string `protobuf:\u0026#34;bytes,1,opt,name=name,proto3\u0026#34; json:\u0026#34;name,omitempty\u0026#34;` 6 Age int32 `protobuf:\u0026#34;varint,2,opt,name=age,proto3\u0026#34; json:\u0026#34;age,omitempty\u0026#34;` 7 Hobbies []string `protobuf:\u0026#34;bytes,3,rep,name=hobbies,proto3\u0026#34; json:\u0026#34;hobbies,omitempty\u0026#34;` 8} 9... 接下来就可以在代码中使用了\n1func main() { 2 person := pb.Person{ 3 Name: \u0026#34;why\u0026#34;, 4 Age: 24, 5 Hobbies: []string{\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;}, 6 } 7 8 data, err := proto.Marshal(\u0026amp;person) 9 if err != nil { 10 log.Fatal(\u0026#34;Marshaling error: \u0026#34;, err) 11 } 12 13 newPerson := \u0026amp;pb.Person{} 14 err = proto.Unmarshal(data, newPerson) 15 if err != nil { 16 log.Fatal(\u0026#34;Unmarshaling error: \u0026#34;, err) 17 } 18 19 fmt.Printf(\u0026#34;%+v\u0026#34;, newPerson) //name:\u0026#34;why\u0026#34; age:24 hobbies:\u0026#34;A\u0026#34; hobbies:\u0026#34;B\u0026#34; hobbies:\u0026#34;C\u0026#34; 20 21} 基础知识 具体使用参考官方文档：https://developers.google.com/protocol-buffers/docs/proto3#simple\n注释使用//\u0026hellip;和/*\u0026hellip;*/\n如果要使用proto3必须在第一行syntax=\u0026quot;proto3\u0026quot;，否则会编译器会使用proto2\n一个.proto文件中可以定义多个message\n在一个message里字段编号是唯一的，且一旦使用不能再更改。编号范围为1~2^29-1，其中19000~19999不能使用。\n字段默认的修饰符是singular。repeated表示字段可重复（生成go代码后为切片）。\n标量类型（Scalar Value Types）\n   .proto Type Notes Go Type     double  float64   float  float32   int32 Uses variable-length encoding. Inefficient for encoding negative numbers – if your field is likely to have negative values, use sint32 instead. int32   int64 Uses variable-length encoding. Inefficient for encoding negative numbers – if your field is likely to have negative values, use sint64 instead. int64   uint32 Uses variable-length encoding. uint32   uint64 Uses variable-length encoding. uint64   sint32 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s. int32   sint64 Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s. int64   fixed32 Always four bytes. More efficient than uint32 if values are often greater than 228. uint32   fixed64 Always eight bytes. More efficient than uint64 if values are often greater than 256. uint64   sfixed32 Always four bytes. int32   sfixed64 Always eight bytes. int64   bool  bool   string A string must always contain UTF-8 encoded or 7-bit ASCII text, and cannot be longer than 232. string   bytes May contain any arbitrary sequence of bytes no longer than 232. []byte    枚举类型（Enumerations）\n枚举类型适用于提供一组预定义的值，选择其中一个。\n必须有0值，且为第一个。\n1message Person {2 string name = 1;3 int32 age = 2;4 repeated string hobbies = 3;5 enum Gender {6 MALE = 0;7 FEMALE = 1;8 }9 Gender gender = 4;10}1func main() { 2\tperson := pb.Person{ 3\tName: \u0026#34;why\u0026#34;, 4\tAge: 24, 5\tHobbies: []string{\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;}, 6\tGender: 0, 7\t} 8 9\tdata, err := proto.Marshal(\u0026amp;person) 10\tif err != nil { 11\tlog.Fatal(\u0026#34;Marshaling error: \u0026#34;, err) 12\t} 13 14\tnewPerson := \u0026amp;pb.Person{} 15\terr = proto.Unmarshal(data, newPerson) 16\tif err != nil { 17\tlog.Fatal(\u0026#34;Unmarshaling error: \u0026#34;, err) 18\t} 19 20\tfmt.Println(newPerson.GetGender()) //MALE 21} 使用其它消息类型\n可以使用其它message类型作为字段。\n1message SearchResponse {2 repeated Result results = 1;3}45message Result {6 string url = 1;7 string title = 2;8 repeated string snippets = 3;9}如果定义在其他文件中，可以先导入然后使用\n1import \u0026#34;myproject/other_protos.proto\u0026#34;;也可以直接嵌套\n1message SearchResponse {2 message Result {3 string url = 1;4 string title = 2;5 repeated string snippets = 3;6 }7 repeated Result results = 1;8}定义服务\n如果消息类型是用来远程通信的(Remote Procedure Call, RPC)，可以在 .proto 文件中定义 RPC 服务接口。\n如下面这个例子，定义了服务SearchService并提供了Search接口，入参是SearchRequest，返回类型是SearchResponse。\n1message SearchRequest {2 ...3}45message SearchResponse {6 ...7}89service SearchService {10 rpc Search(SearchRequest) returns (SearchResponse);11}","date":"2021-06-10","permalink":"https://why9661.github.io/myblog/posts/protobuf/protobuf01/","series":null,"tags":["Protobuf"],"title":"Protobuf基础"},{"categories":["Golang"],"content":"简介 go test命令是一个按照一定的约定和组织的测试代码的驱动程序。在包目录内，所有以_test.go为后缀名的源文件并不是go build构建包的一部分，它们是go test测试的一部分。\n在*_test.go文件中，有三种类型的函数：测试函数、基准测试函数、示例函数。一个测试函数是以Test为函数名前缀的函数，用于测试程序的一些逻辑行为是否正确；go test命令会调用这些测试函数并报告测试结果是PASS或FAIL。基准测试函数是以Benchmark为函数名前缀的函数，它们用于衡量一些函数的性能；go test命令会多次运行基准函数以计算一个平均的执行时间。示例函数是以Example为函数名前缀的函数，提供一个由编译器保证正确性的示例文档。\ngo test命令会遍历所有的*_test.go文件中符合上述命名规则的函数，然后生成一个临时的main包用于调用相应的测试函数，然后构建并运行、报告测试结果，最后清理测试中生成的临时文件。\n测试函数 每个测试函数必须导入 testing 包。测试函数签名如下：\n1func TestName(t *testing.T) { 2\t// ... 3} 测试函数的名字必须以Test开头, 可选的后缀名必须以大写字母开头。\n一个例子\ncalc.go文件如下：\n1func Add(a, b int) int { 2\treturn a + b 3} 4 5func Sub(a, b int) int { 6\treturn a - b 7} calc_test.go文件如下：\n1func TestAdd(t *testing.T) { 2\tif result := Add(3, 2); result != 5 { 3\tt.Errorf(\u0026#34;Result: %d, Expected result: 5\\n\u0026#34;, result) 4\t} 5} 6 7func TestSub(t *testing.T) { 8\tif result := Sub(3, 2); result != 1 { 9\tt.Errorf(\u0026#34;Result: %d, Expected result: 1\\n\u0026#34;, result) 10\t} 11} 执行go test\n1PASS 2ok go_test/testexample 0.125s 参数 -v 用于打印每个测试函数的名字和运行时间\n1go test -v 2=== RUN TestAdd 3--- PASS: TestAdd (0.00s) 4=== RUN TestSub 5--- PASS: TestSub (0.00s) 6PASS 7ok go_test/testexample 0.121s 参数 -run 是一个正则表达式, 只有测试函数名被它正确匹配的测试函数才会被 go test 运行。\ngo test默认会执行单元测试，可以使用-run=none禁止运行单元测试。\n1go test -run TestAdd -v 2=== RUN TestAdd 3--- PASS: TestAdd (0.00s) 4PASS 5ok go_test/testexample 0.106s 子测试\n使用t.Run创建不同的子测试用例\n1func TestAdd(t *testing.T) { 2 t.Run(\u0026#34;pos\u0026#34;, func(t *testing.T) { 3 if result := Add(2, 3); result != 5 { 4 t.Fatalf(\u0026#34;Result: %d, Expected result: 5\\n\u0026#34;, result) 5 } 6 }) 7 8 t.Run(\u0026#34;neg\u0026#34;, func(t *testing.T) { 9 if result := Add(-2, -3); result != -5 { 10 t.Fatalf(\u0026#34;Result: %d, Expected result: 05\\n\u0026#34;, result) 11 } 12 }) 13} 1go test -run TestAdd/neg -v 2=== RUN TestAdd 3=== RUN TestAdd/neg 4--- PASS: TestAdd (0.00s) 5 --- PASS: TestAdd/neg (0.00s) 6PASS 7ok go_test/testexample 0.111s 表格驱动测试\n1func TestAdd(t *testing.T) { 2 testcases := []struct{ 3 inputA int 4 inputB int 5 expected int 6 }{ 7 {1, 2, 3}, 8 {-1, -2, -3}, 9 {0, 0, 0}, 10 } 11 12 for _, c := range testcases { 13 if result := Add(c.inputA, c.inputB); result != c.expected { 14 t.Fatalf(\u0026#34;Result: %d Expected result: %d\u0026#34;, result, c.expected) 15 } 16 } 17} 这种测试方式可以方便的添加测试用例，并且输出的测试报告易于阅读。\n帮助函数\n对一些重复的逻辑，抽取出来作为公共的帮助函数(helpers)，可以增加测试代码的可读性和可维护性。\n1package testexample 2 3import \u0026#34;testing\u0026#34; 4 5type testcase struct{A, B, Expected int} 6 7func createAddTestcase(t *testing.T, c *testcase) { 8\t//t.Helper() 9\tif result := Add(c.A, c.B); result != c.Expected { 10\tt.Fatalf(\u0026#34;Result: %d Expected: %d\\n\u0026#34;, result, c.Expected) 11\t} 12} 13 14func TestAdd(t *testing.T) { 15\tcreateAddTestcase(t, \u0026amp;testcase{1, 2, 3}) 16\tcreateAddTestcase(t, \u0026amp;testcase{1, 3, 3}) //wrong 17} 这里添加了一个错误的测试用例，运行go test会报告在帮助函数内部即代码的第10行发生错误，但代码的第15、16行都调用了该方法，不能根据错误信息直接定位问题。\n1go test 2--- FAIL: TestAdd (0.00s) 3 calc_test.go:10: Result: 4 Expected: 3 4FAIL 5exit status 1 6FAIL go_test/testexample 0.140s 使用t.Helper()函数，会准确的定位到第16行代码发生错误。\n1go test 2--- FAIL: TestAdd (0.00s) 3 calc_test.go:16: Result: 4 Expected: 3 4FAIL 5exit status 1 6FAIL go_test/testexample 0.141s 网络测试\n假设需要测试某个 API 接口的 handler 能够正常工作，例如 helloHandler\n1func helloHandler(w http.ResponseWriter, r *http.Request) { 2\tw.Write([]byte(\u0026#34;hello world\u0026#34;)) 3} 那我们可以创建真实的网络连接进行测试：\n1func helloHandler(w http.ResponseWriter, r *http.Request) { 2\tw.Write([]byte(\u0026#34;Hello World!\u0026#34;)) 3} 4 5func handleError(t *testing.T, err error) { 6\tt.Helper() 7\tif err != nil { 8\tt.Fatal(\u0026#34;failed\u0026#34;, err) 9\t} 10} 11 12func TestConn(t *testing.T) { 13\tln, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:8000\u0026#34;) 14\thandleError(t, err) 15\tdefer ln.Close() 16 17\thttp.HandleFunc(\u0026#34;/hello\u0026#34;, helloHandler) 18\tgo http.Serve(ln, nil) 19 20\tresp, err := http.Get(\u0026#34;http://\u0026#34; + ln.Addr().String() + \u0026#34;/hello\u0026#34;) 21\thandleError(t, err) 22\tdefer resp.Body.Close() 23 24\tbody, err := ioutil.ReadAll(resp.Body) 25\thandleError(t, err) 26 27\tif string(body) != \u0026#34;Hello World!\u0026#34; { 28\tt.Fatal(\u0026#34;expected hello world, but got\u0026#34;, string(body)) 29\t} 30} 执行go test -run=TestConn\n1PASS 2ok go_test/testexample 0.223s 针对 http 开发的场景，使用标准库 net/http/httptest 进行测试更为高效。\n1func TestConn(t *testing.T) { 2 req := httptest.NewRequest(\u0026#34;GET\u0026#34;, \u0026#34;http://example.com/foo\u0026#34;, nil) 3 w := httptest.NewRecorder() 4 helloHandler(w, req) 5 bytes, _ := ioutil.ReadAll(w.Result().Body) 6 if string(bytes) != \u0026#34;hello world\u0026#34; { 7 t.Fatal(\u0026#34;expected hello world, but got\u0026#34;, string(bytes)) 8 } 9} 基准测试 基准测试是测量一个程序在固定工作负载下的性能. 在Go语言中, 基准测试函数和普通测试函数类似, 但是以Benchmark为前缀名, 并且带有一个 *testing.B 类型的参数; *testing.B 除了提供和 *testing.T 类似的方法, 还有额外一些和性能测量相关的方法. 它提供了一个整数N, 用于指定操作执行的循环次数。\n和普通测试不同的是, go test默认情况下不运行任何基准测试，需要通过 -bench 命令行标志参数手动指定要运行的基准测试函数. 该参数是一个正则表达式, 用于匹配要执行的基准测试函数的名字, 默认值是空的. 其中 ‘‘.’’ 模式将可以匹配所有基准测试函数。\n一个例子\n1func BenchmarkSprintf(b *testing.B) { 2\tnum := 123 3\tb.ResetTimer() 4\tfor i := 0; i \u0026lt; b.N; i++ { 5\tfmt.Sprintf(\u0026#34;%d\u0026#34;, num) 6\t} 7} 8 9func BenchmarkFormat(b *testing.B) { 10\tnum := int64(123) 11\tb.ResetTimer() 12\tfor i := 0; i \u0026lt; b.N; i++ { 13\tstrconv.FormatInt(num, 10) 14\t} 15} 16 17func BenchmarkItoa(b *testing.B) { 18\tnum := 123 19\tb.ResetTimer() 20\tfor i := 0; i \u0026lt; b.N; i++ { 21\tstrconv.Itoa(num) 22\t} 23} 1go test -bench=. 2... 3BenchmarkSprintf-4 7685479 155.8 ns/op 4BenchmarkFormat-4 25729987 46.18 ns/op 5BenchmarkItoa-4 25522030 46.91 ns/op 6PASS 7ok go_test/testexample 5.922s 基准测试名的数字后缀表示运行时GOMAXPROCS的值。报告显示每次调用Sprintf函数花费169.4纳秒，是执行8194918的平均时间。\nb.ResetTimer重置计时器，可以在真正的测试代码前调用以避免其它代码干扰。\n测试时间默认是1s，可以使用-benchtime指定运行时间\n1go test -bench=. -benchtime=3s 2... 3BenchmarkSprintf-4 21998582 164.9 ns/op 4BenchmarkFormat-4 61516693 52.66 ns/op 5BenchmarkItoa-4 63125335 55.21 ns/op 6PASS 7ok go_test/testexample 10.820s -benchmem可以显示每次分配内存的次数，以及每次分配内存的大小\n1go test -bench=. -benchmem 2... 3BenchmarkSprintf-4 8621544 134.9 ns/op 3 B/op 1 allocs/op 4BenchmarkFormat-4 26064914 45.87 ns/op 3 B/op 1 allocs/op 5BenchmarkItoa-4 25207171 47.30 ns/op 3 B/op 1 allocs/op 6PASS 7ok go_test/testexample 3.932s 示例函数 第三种 go test 特别处理的函数是示例函数, 以 Example 为函数名开头. 示例函数没有函数参数和返回值。\n","date":"2021-05-09","permalink":"https://why9661.github.io/myblog/posts/golang/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/","series":null,"tags":["测试"],"title":"Golang-单元测试"},{"categories":["RPC"],"content":"简介 RPC（Remote Procedure Call）即远程程序调用，是一种计算机通信协议，允许调用不同进程空间的程序。RPC 的客户端和服务器可以在一台机器上，也可以在不同的机器上。程序员使用时，就像调用本地程序一样，无需关注内部的实现细节。\n使用 Golang官方提供了使用RPC的标准库。\n一个例子\n服务器端\n被注册的方法需要满足以下条件： 1、\u0026ldquo;服务名\u0026quot;即绑定方法的类型是可导出的 2、方法名是可导出的 3、方法有两个参数均为可导出的，且第二个参数是指针 4、方法的返回值类型是error\n1type Params struct { 2 Width int 3 Height int 4} 5 6type Result struct { 7 Area int 8 Cir int 9} 10 11type Rect struct{} 12 13// RPC服务端提供的方法 14func (r *Rect) AreaAndCir(params Params, result *Result) error { 15 result.Area = params.Width * params.Height 16 result.Cir = (params.Height+params.Width)*2 17 return nil 18} 19 20func main() { 21 rect := new(Rect) 22 //注册服务，发布满足RPC注册条件的方法，此处为(Rect.AreaAndCir) 23 rpc.Register(rect) 24 //注册处理RPC消息的HTTP Handler 25 rpc.HandleHTTP() 26 //监听8000端口，等待RPC请求 27 log.Fatal(http.ListenAndServe(\u0026#34;:8000\u0026#34;, nil)) 28} 客户端\n1type Params struct { 2 Height int 3 Width int 4} 5 6type Result struct { 7 Area int 8 Cir int 9} 10 11func main() { 12 //创建client并与:8000建立连接 13 client, err := rpc.DialHTTP(\u0026#34;tcp\u0026#34;, \u0026#34;:8000\u0026#34;) 14 if err != nil { 15 log.Fatal(err) 16 } 17 18 result := Result{} 19 //调用远程服务的方法 20 err = client.Call(\u0026#34;Rect.AreaAndCir\u0026#34;, Params{10, 20}, \u0026amp;result) 21 if err != nil { 22 log.Fatal(err) 23 } 24 25 fmt.Printf(\u0026#34;面积:%d 周长:%d\\n\u0026#34;, result.Area, result.Cir) 26} 上面的RPC是使用gob编码，只能在Go开发的服务器和客户端之间交互，以下是基于json编码的RPC：\n服务器端\n1... 2func main() { 3 rpc.Register(new(Rect)) 4 lis, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:8000\u0026#34;) 5 if err != nil { 6 log.Fatal(err) 7 } 8 9 for { 10 conn, err := lis.Accept() 11 if err != nil { 12 continue 13 } 14 go func(conn net.Conn) { 15 jsonrpc.ServeConn(conn) 16 }(conn) 17 } 18} 客户端\n1... 2func main() { 3 client, err := jsonrpc.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:8000\u0026#34;) 4 if err != nil { 5 log.Fatal(err) 6 } 7 8 result := Result{} 9 err = client.Call(\u0026#34;Rect.AreaAndCir\u0026#34;, Params{10, 20}, \u0026amp;result) 10 if err != nil { 11 log.Fatal(err) 12 } 13 14 fmt.Printf(\u0026#34;面积:%d 周长:%d\\n\u0026#34;, result.Area, result.Cir) 15} 以上两个例子都是同步调用，如果需要异步调用，可以使用client.Go()：\n1\t... 2\tresult := Result{} 3\tasyncCall := client.Go(\u0026#34;Rect.AreaAndCir\u0026#34;, Params{10, 20}, \u0026amp;result, nil) 4\t//err = client.Call(\u0026#34;Rect.AreaAndCir\u0026#34;, Params{10, 20}, \u0026amp;result) 5\t//if err != nil { 6\t//\tlog.Fatal(err) 7\t//} 8\t\u0026lt;-asyncCall.Done 9\t... ","date":"2021-05-08","permalink":"https://why9661.github.io/myblog/posts/rpc/rpc01/","series":null,"tags":["微服务"],"title":"RPC基础"},{"categories":["Docker"],"content":"安装 https://docs.docker.com/engine/install/centos/\r配置镜像加速\n①修改配置文件\n  vim /etc/docker/daemon.json\n  1{ 2 \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;http://hub-mirror.c.163.com\u0026#34;] 3}   systemctl daemon-reload\nsystemctl restart docker\n  ②修改docker服务启动脚本\n vim /usr/lib/systemd/system/docker.service  简介 虚拟机vs容器 虚拟机是在宿主机上虚拟一个OS，所以虚拟机的运行需要消耗很多系统内存和CPU，这样不可避免的就同应用程序争抢资源，而容器化的应用是直接运行在宿主机上的和宿主机共享内核，基本上无需额外的CPU和内存消耗。\n虚拟机上的应用同宿主机进行IO等交互时由于需要经过虚拟机这个中间介质，所以IO效率相比容器就会低很多。\n隔离\u0026amp;资源限制 docker使用linux内核的namespace、cgroups机制来实现容器之间的隔离和资源限制的。\nnamespace namespace主要有PID namespace、 挂载点信息隔离的Mount namespace、 隔离网络资源的Network namespace、隔离用户的User namespace等。\ncgroup CGroup技术是用来限制单个进程对CPU、内存、磁盘等资源的占用，Docker通过cgroup限制docker启动的进程对以上资源的消耗。\nCPU相关的限制\n  \u0026ndash;cpus decimal\n限制容器使用的cpu数量\n  \u0026ndash;cpuset-cpus string\n限制容器在某个（可以多个）cpu上运行\n  \u0026ndash;cpu-shares int\n设置使用cpu的权重（当 cpu资源充足时，设置 cpu的权重是没有意义的。只有在容器争用 cpu资源的情况下， cpu的权重才能让不同的容器分到不同的 cpu用量）\n  内存相关的限制\n  -m(\u0026ndash;memory) bytes\n限制容器可以使用的最大内存\n  \u0026ndash;memory-swap bytes\n限制容器可以使用的swap大小（实际表示的是memory和swap之和！）\n必须和\u0026ndash;memory一起使用\n  Dockerfile 注释使用#\nFROM 指定基础镜像，在这个基础镜像之上进行修改定制。\n必须为第一个命令。\nDocker 还有一个特殊的镜像 scratch，这个镜像是虚拟的，表示空白镜像。\nLABEL 通常用于指定镜像制作者的信息以及其它的一些描述信息\nENV 设置环境变量\nENV WORKDIR WORKDIR 用来切换工作目录。Docker 默认的工作目录是/，只有 RUN 能执行 cd 命令切换目录，而且还只作用在当下的 RUN。如果想让其他指令在指定的目录下执行，就得靠 WORKDIR。\nWORKDIR 动作的目录改变是持久的，不用每个指令前都使用一次 WORKDIR。\nRUN 构建镜像时（docker build）执行的命令。\nRUN的默认权限是sudo。 需要注意的是，如果你需要执行多个RUN操作，那最好把它们合并在一行 (用\u0026amp;\u0026amp;连接)，因为每执行一次RUN就会在docker上新建一层镜像，所以分开来写很多个RUN的结果就是会导致整个镜像无意义的过大膨胀。\nCMD 与RUN不同，CMD是创建容器时（docker run）所执行的命令。\nDockerfile中只能设置一个CMD，如果设置多个，那么生效的是最后一个。\nCMD 指令指定的程序可被 docker run 命令行参数中指定要运行的程序所覆盖。\nCMD [\u0026ldquo;操作\u0026rdquo;，\u0026ldquo;参数1\u0026rdquo;，”参数2“]\nENTRYPOINT 与CMD非常类似，不同的是通过docker run执行的命令不会覆盖ENTRYPOINT。\nENTRYPOINT[”操作“，“参数1”，“参数2”]\nADD 从上下文目录中复制文件或者目录到容器里指定路径，tar类型会自动解压。\n可以访问网络资源（类似wget）\nCOPY 从上下文目录中复制文件或者目录到容器里指定路径，功能类似ADD，但是不会自动解压，也不能访问网络资源。\nEXPOSE 声明运行时容器提供的服务端口，这只是一个声明，并不会自动在宿主进行端口映射。\n常用命令 监控容器资源消耗 docker stats\n镜像 docker build 根据Dockerfile创建镜像\n\u0026ndash;file -f 指定Dockerfile，默认是当前路径下的Dockerfile\n\u0026ndash;tag -t 设置镜像名称和版本 name:tag\n.代表本次执行的上下文路径\n上下文路径，是指 docker 在构建镜像，有时候想要使用到本机的文件（比如复制），docker build 命令得知这个路径后，会将路径下的所有内容打包。\n解析：由于 docker 的运行模式是 C/S。我们本机是 C，docker 引擎是 S。实际的构建过程是在 docker 引擎下完成的，所以这个时候无法用到我们本机的文件。这就需要把我们本机的指定目录下的文件一起打包提供给 docker 引擎使用。\neg: docker build -t myapp:v1.0.0 .\ndocker commit 根据容器创建镜像\n-a 作者\n-m 描述\neg: docker commit -a \u0026ldquo;WHY\u0026rdquo; -m \u0026ldquo;centos7 with golang\u0026rdquo; mycontainer（容器名） mycentos:V1.0（镜像名）\ndocker images 查看本地镜像\ndocker rmi 删除镜像\neg: docker rmi xxxxxxx\ndocker image prune 删除所有未使用镜像\ndocker pull 从镜像仓库拉取或更新指定镜像\neg: docker pull redis\ndocker search 搜索镜像\neg：docker search golang\ndocker inspect 获取镜像/容器的元数据\ndocker save 保存镜像（将镜像打包成tar）\neg: docker save -o /root/helloweb.tar helloweb:v1.0\ndocker load 导入镜像\neg: docker load -i helloweb.tar\n容器 docker rm 删除容器\neg: docker rm xxxxxx\ndocker container prune 删除所有非运行状态的容器\ndocker ps 查看（运行中的）容器\n-a 查看所有容器\ndocker update 更新一些配置\ndocker run 创建容器\n\u0026ndash;name 指定容器名字\n-e 设置环境变量\n-h 指定容器的主机名\n-d 创建一个守护式容器在后台运行\n-p 指定容器暴露的端口 （将容器的端口映射到宿主机） 宿主机端口:容器端口\n-P 随机选取宿主机端口与容器内暴露的端口映射\n-i 表示以交互方式运行容器\n-t 容器启动后进入其命令行（为容器重新分配一个伪终端）\n  容器重启策略\n\u0026ndash;restart\n①no 默认策略，在容器退出时不重启\n②always 容器退出时总是重启\n③on-failure\n④on-failure:3\n⑤unless-stopped\n  目录挂载（数据卷操作）\n-v\n在创建容器的时候，可以将宿主机目录与容器内目录进行映射，从而达到持久化的目的。\n①指定目录挂载 -v 宿主机目录:容器目录\n②匿名挂载 -v 容器目录 （会存在宿主机的/var/lib/docker/volumes下）\n③具名挂载 -v 数据卷名:容器目录 （相对于匿名挂载，相当于给数据卷起了个名）\n④只读或读写 -v 宿主机目录:容器目录:ro/rw（默认读写rw） （容器不能写这个目录）\n⑤继承 \u0026ndash;volumes-from\n  \u0026ndash;rm参数\n当容器退出时自动删除容器，释放资源。可用与单元测试或压力测试\n  docker exec 进入容器\neg： docker exec -it mycontainer /bin/bash（要执行的命令，这里是打开bash）\ndocker start 启动容器\neg: docker start mycontainer01\ndocker stop 停止容器\neg: docker stop mycontainer01\ndocker kill 直接kill掉一个容器\ndocker cp 将文件拷贝到容器，或将容器中的文件拷贝到宿主机\ndocker cp 需要拷贝的文件或目录 容器名称：容器目录\ndocker cp 容器名称：容器目录 需要拷贝的文件或目录\ndocker logs 查看容器的日志\ndocker rename 容器重命名\n仓库 公共仓库 Docker Hub\n  docker login\t登录\n  docker tag 给image打标签\n  docker push 推送image\n  docker logout 退出\n  eg:\ndocker tag hello-world:latest hywong1996/hello-world-test:v1.0\ndocker push hywong1996/hello-world-test:v1.0\n注意：打标签时要改到自己的账户名下（hywong1996），否则会出错\n私有仓库   docker pull registry （用于搭建私有仓库的镜像）\n  修改配置文件\n/etc/docker/daemon.json\n添加\u0026quot;insecure-registries\u0026quot;:[\u0026ldquo;地址:5000\u0026rdquo;]\n  重新加载配置文件\nsystemctl daemon-reload\n  重新启动docker\nsystemctl restart docker\n  创建私有仓库容器\ndocker run \u0026ndash;name registry -id -p 5000:5000 registry\n  验证\n地址:5000/v2/_catalog\n  docker tag\n  docker pull\n  注意：如果出现”http: server gave HTTP response to HTTPS client“这个问题\nsystemctl enable docker.service\n修改 /usr/lib/systemd/system/docker.service 中的 ExecStart 选项，加入\u0026ndash;insecure-registry 地址:5000\nsystemctl daemon-reload\nsystemctl restart docker\n网络 docker network\nbridge模式（默认） Docker守护进程会在宿主机上创建一个名为docker0的虚拟网桥，此主机上启动的Docker容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。\n从docker0子网中分配一个IP给容器使用，并设置docker0的IP地址为容器的默认网关。在主机上创建一对虚拟网卡veth pair设备，Docker将veth pair设备的一端放在新创建的容器中，并命名为eth0（容器的网卡），另一端放在主机中，以vethxxx这样类似的名字命名，并将这个网络设备加入到docker0网桥中。\nhost模式 docker run \u0026ndash;network host\n如果启动容器的时候使用host模式，那么这个容器将不会获得一个独立的Network Namespace，而是和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。但是，容器的其他方面，如文件系统、进程列表等还是和宿主机隔离的。\ncontainer模式 docker run \u0026ndash;network container:容器\n这个模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过 lo 网卡设备通信。\nnone模式 docuer run \u0026ndash;network none\n使用none模式，Docker容器拥有自己的Network Namespace，但是，并不为Docker容器进行任何网络配置。也就是说，这个Docker容器没有网卡、IP、路由等信息。需要我们自己为Docker容器添加网卡、配置IP等。\n自定义网络 docker network create\ndocker daemon 实现了一个内嵌的DNS Server，但是只能在自定义网络中使用，这样就可以通过容器名进行通信。\n","date":"2021-05-02","permalink":"https://why9661.github.io/myblog/posts/docker/docker%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/","series":null,"tags":["容器化"],"title":"Docker基础"},{"categories":["Golang"],"content":"方法本质上是一个函数，方法接收者就是隐含的第一个参数\n1type A struct { 2\tName string 3} 4 5func (a A) SayHello1() string { 6\treturn \u0026#34;Hello \u0026#34; + a.Name 7} 8 9func SayHello2(a A) string { 10\treturn \u0026#34;Hello \u0026#34; + a.Name 11} 12 13func main() { 14\tt1 := reflect.TypeOf(A.SayHello1) 15\tt2 := reflect.TypeOf(SayHello2) 16\tfmt.Println(t1 == t2) // true 17} 以下是一个常见的方法调用，这其实是一个语法糖，等价于注释行的函数调用。\n1type A struct { 2\tName string 3} 4 5func (a A) SayHello() string { 6\treturn \u0026#34;Hello \u0026#34; + a.Name 7} 8 9func main() { 10\ta := A{\u0026#34;why\u0026#34;} 11\tfmt.Println(a.SayHello()) 12\t//fmt.Println(A.SayHello(a)) 13} 如果需要通过方法调用来完成对接收者的修改，那么需要使用指针接受者\n1type A struct { 2\tName string 3} 4 5func (a A) Rename1(name string) { 6\ta.Name = name 7} 8 9func (a *A) Rename2(name string) { 10\ta.Name = name 11} 12 13func main() { 14\ta := A{\u0026#34;why\u0026#34;} 15\tb := A{\u0026#34;why\u0026#34;} 16\ta.Rename1(\u0026#34;why123\u0026#34;) 17\tb.Rename2(\u0026#34;why123\u0026#34;) 18\tfmt.Println(a.Name) //why 19\tfmt.Println(b.Name) //why123 20} 可以通过值调用指针接受者的方法，也可以通过指针调用值接收者的方法，这也是一种语法糖\n1type A struct { 2 Name string 3} 4 5func (a A) Rename1(name string) { 6 a.Name = name 7} 8 9func (a *A) Rename2(name string) { 10 a.Name = name 11} 12 13func main() { 14 a := A{\u0026#34;why\u0026#34;} 15 b := \u0026amp;A{\u0026#34;why\u0026#34;} 16 a.Rename2(\u0026#34;why123\u0026#34;) //在编译阶段会转换为(\u0026amp;a).Rename2(string) 17 b.Rename1(\u0026#34;why123\u0026#34;) //在编译阶段会转换为(*b).Rename1(string) 18 fmt.Println(a.Name) // why123 19 fmt.Println(b.Name) // why 20} 方法和函数一样可以赋值给变量\n1type A struct { 2 Name string 3} 4 5func (a A) PrintName() { 6 fmt.Println(a.Name) 7} 8 9func main() { 10 a := A{\u0026#34;why\u0026#34;} 11 f1 := a.PrintName //有捕获列表的Function Value 12 f2 := A.PrintName //Function Value 13 f1() //why 14 f2(a) //why 15} ","date":"2021-04-28","permalink":"https://why9661.github.io/myblog/posts/golang/%E6%96%B9%E6%B3%95/","series":null,"tags":["Golang"],"title":"Golang-方法"},{"categories":["Golang"],"content":"Function Value 在Go语言中，函数是头等对象，可以作为参数传递，可以作为返回值返回，也可赋值给变量。Go语言称这样的参数、返回值、变量为Function Value。\nFunction Value是一个指针，指向一个runtime.funcval结构体：\n1type funcval struct { 2\tfn uintptr 3} 这个结构体持有一个指针fn，指向函数指令入口。\n例子\n函数A被赋值给变量f1和f2。\n编译器会做出优化，在只读数据段分配一个funcval结构体，f1和f2共用这个结构体，结构体中的fn指向函数A的指令入口。\n1func A() int { 2\ti := 1 3\treturn i 4} 5 6func main() { 7\tf1 := A 8\tf2 := A 9 fmt.Println(f1()) 10 fmt.Println(f2()) 11} 闭包 闭包可以简单理解为：函数+引用环境。\n例子\n返回的匿名函数引用了外部的局部变量x，因此返回的这个函数就是一个闭包。\n闭包是有捕获列表的Function Value。\n执行到f1:=A()时，函数A会在堆上分配一个funcval结构体，同时拷贝x的值到捕获列表，再将这个funcval的起始地址返回给f1。\n执行到f2:=A()时，函数A会在堆上再分配一个funcval结构体，同时拷贝x的值到捕获列表，再将这个funcval的起始地址返回给f2。\n1func A() func() int { 2\tx := 1 3\treturn func() int { //闭包 4\treturn x 5\t} 6} 7 8func main() { 9\tf1 := A() 10\tf2 := A() 11\tfmt.Println(f1()) //1 12\tfmt.Println(f2()) //1 13} 以上是被捕获的变量不会被修改的情况，直接拷贝值到捕获列表就ok。\n接下来看被捕获的变量会被修改的情况：\n捕获局部变量。\n执行到f1:=A()时，函数A会在堆上分配一个funcval结构体，由于被捕获的变量被外部引用且被修改，x会逃逸到堆上，并且捕获列表存x的地址，然后将这个funcval的起始地址返回给f1。\n执行到f2:=A()时，函数A会在堆上再分配一个funcval结构体，由于被捕获的变量被外部引用且被修改，x会逃逸到堆上，并且捕获列表存x的地址，然后将这个funcval的起始地址返回给f2。\n1func A() func() int { 2\tx := 1 3\treturn func() int { //闭包 4\tx++ 5\treturn x 6\t} 7} 8 9func main() { 10\tf1 := A() 11\tf2 := A() 12\tfmt.Println(f1()) //2 13\tfmt.Println(f2()) //2 14\tfmt.Println(f1()) //3 15\tfmt.Println(f2()) //3 16} 闭包引起的一些问题\n1func main() { 2\tfor i := 0; i \u0026lt; 5; i++ { 3\tdefer func() { 4\tfmt.Println(i) 5\t}() 6\t} 7} 8//输出 9//5 10//5 11//5 12//5 13//5 解决方法：\n1func main() { 2\tfor i := 0; i \u0026lt; 5; i++ { 3 x := i 4\tdefer func() { 5\tfmt.Println(x) 6\t}() 7\t} 8} 9 10func main() { 11\tfor i := 0; i \u0026lt; 5; i++ { 12\tdefer func(x int) { 13\tfmt.Println(x) 14\t}(i) 15\t} 16} ","date":"2021-04-27","permalink":"https://why9661.github.io/myblog/posts/golang/%E9%97%AD%E5%8C%85/","series":null,"tags":["Golang"],"title":"Golang-闭包"},{"categories":["Golang"],"content":"标准库中的 text/template包是 Go 语言内置的文本模板引擎。\nhtml/template是对text/template的封装，用法大同小异。\n常用方法：\n1//创建一个模板对象 2func New(name string) *Template {...} 3 4//从本地文件加载模板 5func ParseFiles(filenames ...string) (*Template, error) {...} 6func ParseGlob(pattern string) (*Template, error) {...} 7 8//Parse方法接受一个string类型的参数，即文本模板的内容，然后对内容进行解析并返回解析过程中发生的任何错误。 9func (t *Template) Parse(text string) (*Template, error) {...} 10 11//Execute方法用于渲染模板，该方法接受两个参数：输出对象和指定根对象 12func (t *Template) Execute(wr io.Writer, data interface{}) error {...} 13 14//当加载了多个模板文件时，使用ExecuteTemplate方法指定渲染某一个模板文件 15func (t *Template) ExecuteTemplate(wr io.Writer, name string, data interface{}) error {...} 16 17//除了内置的模板函数外，可以通过Funcs方法增加自定义模板函数 18func (t *Template) Funcs(funcMap FuncMap) *Template {...} 模板中的Action（赋值、逻辑控制、函数等等）需要使用{{}}包裹，除Action之外的内容会原封不动的进行输出。\n{{.}}操作符默认指向根对象。\n注释的语法和 Go 语言程序代码中的块注释语法相同，即使用 /* 和 */ 将注释内容包括起来，例如：{{/* 这是注释内容 */}}。\n{{- 用于剔除模板左侧多余的空格， -}}用于剔除模板中右侧多余的空格\n一些示例\n直接渲染文本\n1func main() { 2\thttp.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { 3\ttemp, _ := template.New(\u0026#34;test\u0026#34;).Parse(\u0026#34;hello template\u0026#34;) 4 5\t_ = temp.Execute(w, nil) 6\t}) 7 8\tlog.Println(\u0026#34;Starting HTTP server...\u0026#34;) 9\tlog.Fatal(http.ListenAndServe(\u0026#34;localhost:4000\u0026#34;, nil)) 10} 在模板中引用根对象\n1type Rect struct { 2\tWidth int 3\tHeight int 4} 5 6func (r *Rect) Area() int { 7\treturn r.Width * r.Height 8} 9 10func main() { 11\thttp.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { 12\ttemp, _ := template.New(\u0026#34;test\u0026#34;).Parse(`Rect 13Width: {{.Width}}14Height: {{.Height}}15Area: {{.Area}}16`) 17 18\twidth, _ := strconv.Atoi(r.URL.Query().Get(\u0026#34;w\u0026#34;)) 19\theight, _ := strconv.Atoi(r.URL.Query().Get(\u0026#34;h\u0026#34;)) 20 21\trect := \u0026amp;Rect{Width: width, Height: height} 22 23\t_ = temp.Execute(w, rect) 24\t}) 25 26\tlog.Println(\u0026#34;Starting HTTP server...\u0026#34;) 27\tlog.Fatal(http.ListenAndServe(\u0026#34;localhost:4000\u0026#34;, nil)) 28} 在模板中定义变量\n1{{$Width := 10}}\t//变量名使用$作为前缀，:=赋值 2{{$Height := 20}} 3{{$Height = 30}}\t//更改变量值 4Width: {{$Width}}\t//获取变量值 5Height: {{$Height}} 剔除空格\n1{{- $Width := 10 -}}\t//变量名使用$作为前缀，:=赋值 2{{- $Height := 20 -}} 3{{$Height = 30}}\t//更改变量值 4Width: {{$Width}}\t//获取变量值 5Height: {{$Height}} 给模板添加自定义函数\n1func main() { 2\thttp.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { 3\ttemp := template.New(\u0026#34;test\u0026#34;).Funcs(template.FuncMap{ 4\t\u0026#34;area\u0026#34;: func(a, b int) int { 5\treturn a * b 6\t}, 7\t}) 8 9\t_, _ = temp.Parse(` 10Area: {{area12}}11`) 12 13\ttemp.Execute(w, nil) 14\t}) 15 16\tlog.Println(\u0026#34;Starting HTTP server...\u0026#34;) 17\tlog.Fatal(http.ListenAndServe(\u0026#34;localhost:4000\u0026#34;, nil)) 18} ","date":"2021-04-10","permalink":"https://why9661.github.io/myblog/posts/golang/web/%E6%A8%A1%E6%9D%BF%E5%BC%95%E6%93%8E/","series":null,"tags":["Web编程"],"title":"Golang-Web编程之模板引擎"},{"categories":["Golang"],"content":"TCMalloc\nTCMalloc(Thread Cache Malloc)即线程缓存分配，Go语言的堆内存分配就借鉴了TCMalloc。\n同一进程的所有线程共享相同的内存空间，他们申请内存时需要加锁。\nTCMalloc为每个线程预分配一块缓存，线程申请小内存时，可以从缓存分配内存，有以下好处：\n 为线程预分配缓存需要进行1次系统调用，后续线程申请小内存时，从缓存分配，都是在用户态执行，没有系统调用，缩短了内存总体的分配和释放时间，这是快速分配内存的第二个层次。 多个线程同时申请小内存时，从各自的缓存分配，访问的是不同的地址空间，无需加锁，把内存并发访问的粒度进一步降低了，这是快速分配内存的第三个层次。  第一个层次：引入虚拟内存，让内存的并发访问问题的粒度从多进程级别，降低到多线程级别。\nTCMalloc的几个重要概念\n  Page\n操作系统对内存管理以页为单位，TCMalloc也是这样，只不过TCMalloc里的Page大小与操作系统里的大小并不一定相等，而是倍数关系。x64下Page大小是8KB。\n  Span：一组连续的Page被称为Span，比如可以有2个页大小的Span，也可以有16页大小的Span，Span比Page高一个层级，是为了方便管理一定大小的内存区域，Span是TCMalloc中内存管理的基本单位。\n  ThreadCache：每个线程各自的Cache，一个Cache包含多个空闲内存块链表，每个链表连接的都是内存块，同一个链表上内存块的大小是相同的，也可以说按内存块大小，给内存块分了个类，这样可以根据申请的内存大小，快速从合适的链表选择空闲内存块。由于每个线程有自己的ThreadCache，所以ThreadCache访问是无锁的。\n  CentralCache：是所有线程共享的缓存，也是保存的空闲内存块链表，链表的数量与ThreadCache中链表数量相同，当ThreadCache内存块不足时，可以从CentralCache取，当ThreadCache内存块多时，可以放回CentralCache。由于CentralCache是共享的，所以它的访问是要加锁的。\n  PageHeap：PageHeap是堆内存的抽象，PageHeap存的也是若干链表，链表保存的是Span，当CentralCache没有内存的时，会从PageHeap取，把1个Span拆成若干内存块，添加到对应大小的链表中，当CentralCache内存多的时候，会放回PageHeap。如下图，分别是1页Page的Span链表，2页Page的Span链表等，最后是large span set，这个是用来保存中大对象的。毫无疑问，PageHeap也是要加锁的。\n  小、中、大对象，Go内存管理中也有类似的概念，TCMalloc的定义：\n 小对象大小：0~256KB 中对象大小：257~1MB 大对象大小：\u0026gt;1MB  小对象的分配流程：ThreadCache -\u0026gt; CentralCache -\u0026gt; HeapPage，大部分时候，ThreadCache缓存都是足够的，不需要去访问CentralCache和HeapPage，无锁分配加无系统调用，分配效率是非常高的。\n中对象分配流程：直接在PageHeap中选择适当的大小即可，128 Page的Span所保存的最大内存就是1024KB即1MB。\n大对象分配流程：从large span set选择合适数量的页面组成span，用来存储数据。\n了解了TCMalloc，接下来看Go语言的内存分配。\n  Page\nx64下一个Page的大小是8KB。\n  Span\n一组连续的Page组成一个Span。（mspan）。\n  mcache\nmcache与TCMalloc中的ThreadCache类似，mcache保存的是各种大小的Span，并按Span class分类，小对象直接从mcache分配内存，它起到了缓存的作用，并且可以无锁访问。\n但mcache与ThreadCache也有不同点，TCMalloc中是每个线程1个ThreadCache，Go中是每个P拥有1个mcache，因为在Go程序中，当前最多有GOMAXPROCS个线程在运行，所以最多需要GOMAXPROCS个mcache就可以保证各线程对mcache的无锁访问，线程的运行又是与P绑定的，把mcache交给P刚刚好。\n  mcentral\nmcentral与TCMalloc中的CentralCache类似，是所有线程共享的缓存，需要加锁访问，它按Span class对Span分类，串联成链表，当mcache的某个级别Span的内存被分配光时，它会向mcentral申请1个当前级别的Span。\n但mcentral与CentralCache也有不同点，CentralCache是每个级别的Span有1个链表，mcache是每个级别的Span有2个链表，这和mcache申请内存有关。\n  mheap\nmheap与TCMalloc中的PageHeap类似，它是堆内存的抽象，把从OS申请出的内存页组织成Span，并保存起来。当mcentral的Span不够用时会向mheap申请，mheap的Span不够用时会向OS申请，向OS的内存申请是按页来的，然后把申请来的内存页生成Span组织起来，同样也是需要加锁访问的。\n但mheap与PageHeap也有不同点：mheap把Span组织成了树结构，而不是链表，并且还是2棵树，然后把Span分配到heapArena进行管理，它包含地址映射和span是否包含指针等位图，这样做的主要原因是为了更高效的利用内存：分配、回收和再利用。\n  微对象、小对象、大对象\n   类别 大小     微对象 (0, 16B)   小对象 [16B, 32KB]   大对象 (32KB, +∞)    堆上所有的对象都会通过调用 runtime.newobject 函数分配内存，该函数会调用 runtime.mallocgc 分配指定大小的内存空间，对于不同大小的对象，有以下的分配逻辑：\n1、微对象：先使用微型分配器(非指针类型)，再依次尝试线程缓存、中心缓存和堆分配内存；\n2、小对象：依次尝试使用线程缓存、中心缓存和堆分配内存；\n3、大对象：直接在堆上分配内存；\n","date":"2021-03-09","permalink":"https://why9661.github.io/myblog/posts/golang/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/","series":null,"tags":["Golang"],"title":"Golang-内存分配"},{"categories":["MySQL"],"content":"索引是帮助MySQL高效获取数据的数据结构。不过索引本身也很大，会占据不少的磁盘空间；索引还会降低表的更新效率，因为每创建一个索引，就会对应生成一个索引文件，在表数据更新时，需要更新这些索引文件。\n数据结构   哈希表\n可以使用key存储索引，value存储行记录或者行所在磁盘地址。\n精确查找速度快，但不支持范围查找。\n  二叉搜索树\n支持范围查找，查找效率也还不错。\n但在极端条件下会退化成链表。\n  平衡二叉树\n平衡二叉树不会出现极端情况下退化成链表地情况，但随着数据量的增大树的高度还是会很高（磁盘IO次数增多），而且在插入、删除操作密集的场景中，平衡二叉树需要频繁地rebalance，增加性能开销。\n  B树\nMySQL的数据文件是存储在磁盘上的，而磁盘的IO速度慢开销大，因此降低磁盘IO的次数能很大程度提高MySQL的性能。树越高，磁盘IO操作次数就会越多，因此需要尽量降低树的高度，这就要每个节点多存储元素。\nB树就是一种多叉平衡查找树。\n为了降低树的高度，需要让每个节点尽可能多的存储索引，因此就有了B+树。\n  B+树\nB+树与B树的区别在于B树的非叶子节点和叶子节点都会存储数据，而B+树的非叶子节点只存储索引，叶子节点存储数据，并且叶子节点之间使用双向指针连接。\n范围查询\n  不同存储引擎的实现 MyISAM MyISAM的索引文件和数据文件分开存储，索引文件存储在.MYI文件中，数据文件存储在.MYD文件中。\nMyISAM的主键索引和辅助索引的叶子节点都是存储的索引+索引所在行的磁盘地址（非行数据），属于非聚簇索引。\nInnoDB InnoDB的索引和数据存储在.ibd文件中。\n主键索引的叶子节点会存储索引+索引所在行的数据，属于聚簇索引；\n辅助索引的叶子节点会存储索引+索引所在行的主键值，属于非聚簇索引。\n 当表定义了primary key时，InnoDB将primary key用作聚簇索引 当表没有定义primary ket时，InnoDB会选择第一个not null的unique列用作聚簇索引 否则InnoDB会创建一个隐藏的row-id用作聚簇索引  联合索引\u0026amp;最左匹配\u0026amp;索引下推 联合索引是指多个字段联合组成一个索引，也是一种辅助索引（叶子节点会存主键值）。\n联合索引的存储方式：按联合索引的第一列排序，在前面列相等的情况下进行局部排序。\n联合索引的检索方式：和存储方式一样，先比较第一列，在前面列相等的情况下比较后面的列。\n向下面这种创建了联合索引(a,b,c)相当于创建了3个索引:(a)、(a,b)、(a,b,c)\n最左前缀匹配：\n  mysql会一直向右匹配直到遇到范围查询(\u0026gt;、\u0026lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c \u0026gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。\n  a = 1 and b = 2 and c = 3 建立(a,b,c)索引时可以任意顺序，mysql的查询优化器会优化成索引可以识别的形式\n  如果建立的索引顺序是 （a，b）那么直接采用 where b = 5 这种查询条件是无法利用到索引的，这一条最能体现最左匹配的特性。\n  索引下推：\n例如现在有一个联合索引(name,age)，需求是查出表中“姓王的10岁男孩”\n1select*frompersonwherenamelike\u0026#39;王%\u0026#39;andage=10\u0026amp;ismale=1;在这个查询中，能够使用到索引name。在MySQL5.6之前，找到name满足条件的主键后会一个一个回表，在主键索引上找到数据行，然后比对age和ismale的字段值。\n索引下推可以在索引遍历过程中，对索引包含的字段先做判断，过滤掉不满足条件的记录，减少回表次数。\n回表\u0026amp;覆盖索引 回表是指在使用辅助索引时，拿到主键值后还需要回到主键索引中查找需要的数据。\n覆盖索引是一种优化手段可以避免回表。\neg：\n主键为a,辅助索引为(b,c)，需要查询的数据为(a,b,c,d)\n在这种情况下，使用辅助索引查找时，需要先在辅助索引中找到主键a，再回到主键索引中找到记录a,b,c,d\n如果我们定义辅助索引为(b,c,d)，那么使用辅助索引查找到主键a即可得到a,b,c,d返回，不需要再进行回表查询。\n","date":"2021-02-22","permalink":"https://why9661.github.io/myblog/posts/mysql/%E7%B4%A2%E5%BC%95/","series":null,"tags":["MySQL"],"title":"MySQL-索引"},{"categories":["MySQL"],"content":"原理   MySQL主库在事务提交时会把数据变更作为事件记录在二进制日志binlog中；\n  主库推送二进制日志文件binlog中的事件到从库的中继日志Relay Log中，之后从库根据中继日志重做数据变更操作，通过逻辑复制来达到主库和从库的数据一致性；\n  MySql通过三个线程来完成主从库间的数据复制，其中Binlog Dump线程跑在主库上，I/O线程和SQL线程跑着从库上；\n  当在从库上启动复制时，首先创建I/O线程连接主库，主库随后创建Binlog Dump线程读取数据库事件并发送给I/O线程，I/O线程获取到事件数据后更新到从库的中继日志Relay Log中去，之后从库上的SQL线程读取中继日志Relay Log中更新的数据库事件并应用，如下图所示。\n  实践 ​\t本次实践docker容器使用bridge网络模式。\n  使用docker启动一个mysql主实例\n1docker run -p 3307:3306 --name mysql-master \\ 2-v /mydata/mysql-master/log:/var/log/mysql \\ 3-v /mydata/mysql-master/data:/var/lib/mysql \\ 4-v /mydata/mysql-master/conf:/etc/mysql \\ 5-v /mydata/mysql-master/mysql-files:/var/lib/mysql-files \\ （当指定了外部配置文件与外部存储路径时，也需要指定 /var/lib/mysql-files的外部目录） 6 7-e MYSQL_ROOT_PASSWORD=123456 \\ 8-d mysql   修改配置文件\n在/mydata/mysql-master/conf目录下新建my.cnf，并作如下配置\n1 [mysqld] 2 ## 设置server_id，同一局域网中需要唯一 3 server_id=101 4## 指定不需要同步的数据库名称 5binlog-ignore-db=mysql 6## 开启二进制日志功能 7log-bin=mall-mysql-bin 8## 设置二进制日志使用内存大小（事务） 9binlog_cache_size=1M 10## 设置使用的二进制日志格式（mixed,statement,row） 11binlog_format=mixed 12## 二进制日志过期清理时间。默认值为0，表示不自动清理。 13expire_logs_days=7 14## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。 15## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致 16slave_skip_errors=1062   修改完后重启实例\ndocker restart mysql-master\n  进入容器，进入MySQL，创建数据同步用户\ndocker exec -it mysql-master /bin/bash\n1CREATEUSER\u0026#39;slave\u0026#39;@\u0026#39;%\u0026#39;IDENTIFIEDBY\u0026#39;123456\u0026#39;;2GRANTREPLICATIONSLAVE,REPLICATIONCLIENTON*.*TO\u0026#39;slave\u0026#39;@\u0026#39;%\u0026#39;;3-- mysql 8.0 默认使用 caching_sha2_password 身份验证机制 4-- 从原来的 mysql_native_password 更改为 caching_sha2_password，现在改回来 5ALTERUSER\u0026#39;slave\u0026#39;@\u0026#39;%\u0026#39;IDENTIFIEDWITHmysql_native_passwordBY\u0026#39;123456\u0026#39;;  使用docker启动一个mysql从实例\n1docker run -p 3308:3306 --name mysql-slave \\ 2-v /mydata/mysql-slave/log:/var/log/mysql \\ 3-v /mydata/mysql-slave/data:/var/lib/mysql \\ 4-v /mydata/mysql-slave/conf:/etc/mysql \\ 5 6-v /mydata/mysql-slave/mysql-files:/var/lib/mysql-files \\ （当指定了外部配置文件与外部存储路径时，也需要指定 /var/lib/mysql-files的外部目录） 7 8-e MYSQL_ROOT_PASSWORD=123456 \\ 9-d mysql   修改配置文件\n在/mydata/mysql-slave/conf目录下新建my.cnf，并作如下配置\n1[mysqld] 2## 设置server_id，同一局域网中需要唯一 3server_id=102 4## 指定不需要同步的数据库名称 5binlog-ignore-db=mysql 6## 开启二进制日志功能，以备Slave作为其它数据库实例的Master时使用 7log-bin=mall-mysql-slave1-bin 8## 设置二进制日志使用内存大小（事务） 9binlog_cache_size=1M 10## 设置使用的二进制日志格式（mixed,statement,row） 11binlog_format=mixed 12## 二进制日志过期清理时间。默认值为0，表示不自动清理。 13expire_logs_days=7 14## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。 15## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致 16slave_skip_errors=1062 17## relay_log配置中继日志 18relay_log=mall-mysql-relay-bin 19## log_slave_updates表示slave将复制事件写进自己的二进制日志 20log_slave_updates=1 21## slave设置为只读（具有super权限的用户除外） 22read_only=1   修改完后重启实例\ndocker restart mysql-slave\n    连接到主数据库\nshow master status;\n  连接到从数据库\n1changemastertomaster_host=\u0026#39;172.17.0.1\u0026#39;,master_user=\u0026#39;slave\u0026#39;,master_password=\u0026#39;123456\u0026#39;,master_port=3307,master_log_file=\u0026#39;mall-mysql-bin.000001\u0026#39;,master_log_pos=713,master_connect_retry=30;master_host：主数据库的IP地址；\nmaster_port：主数据库的运行端口；\nmaster_user：在主数据库创建的用于同步数据的用户账号；\nmaster_password：在主数据库创建的用于同步数据的用户密码；\nmaster_log_file：指定从数据库要复制数据的日志文件，通过查看主数据的状态，获取File参数；\nmaster_log_pos：指定从数据库从哪个位置开始复制数据，通过查看主数据的状态，获取Position参数；\nmaster_connect_retry：连接失败重试的时间间隔，单位为秒。\n  ​\tstart slave开始同步\n​\tshow slave status \\G查看同步状态\n","date":"2021-02-17","permalink":"https://why9661.github.io/myblog/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","series":null,"tags":["MySQL"],"title":"MySQL-主从复制"},{"categories":["Golang"],"content":"channel可分为有缓冲channel和无缓冲channel，也可分为单向的只读chan、单向的只写chan\u0026lt;-以及双向channel。\nchannel常用操作是：发送数据、接收数据、关闭channel。\n发送数据 发送数据主要有以下情况：\n 向一个nil的channel发送数据，会阻塞 向一个closed的channel发送数据，会引起panic 当不存在缓冲区或者缓冲区已满时，当前goroutine陷入阻塞，等待其他 groutine 从 Channel 接收数据。 channel的缓冲区没有满时，将发送的数据写入channel的缓冲区。 当channel的等待队列存在被阻塞的接收goroutine时，那么channel会从等待队列中取出最先等待的goroutine并直接向它发送数据：  调用 runtime.sendDirect将发送的数据直接拷贝到 x = \u0026lt;-c 表达式中变量 x 所在的内存地址上； 调用 runtime.goready将等待接收数据的 Goroutine 标记成可运行状态 Grunnable 并把该 goroutine 放到发送方所在的处理器的 runnext 上等待执行，该处理器在下一次调度时会立刻唤醒数据的接收方；    接收数据   对一个nil的channel接收数据，会阻塞\n  对一个closed的channel接收数据，会返回零值；如果多使用一个接收参数，会返回false。\n  当缓冲区没有数据时且当前goroutine的发送队列中不存在等待的goroutine时，当前goroutine陷入阻塞，等待其他goroutine向channel发送数据。\n  channel的缓冲区有数据时，从缓冲区接收数据。\n  当channel的等待队列存在被阻塞的发送goroutine时：\n  如果 Channel 不存在缓冲区：\n调用 runtime.recvDirect 将 Channel 发送队列中 Goroutine 存储的 elem 数据拷贝到目标内存地址中；\n  如果 Channel 存在缓冲区：\n 将队列中的数据拷贝到接收方的内存地址； 将发送队列头的数据拷贝到缓冲区中，释放一个阻塞的发送方；    无论发生哪种情况，运行时都会调用 runtime.goready 将当前处理器的 runnext 设置成发送数据的 goroutine，在调度器下一次调度时将阻塞的发送方唤醒。\n  关闭channel  关闭已closed的channel，会引起panic 关闭nil的channel，会引起panic  select语句 在select语句中，当有一个case可以执行时就执行这个case，如果多个case同时可以执行，那么select会随机地选取一个执行，都不能执行就处于阻塞状态直到有可以执行的case，当然也可以添加default分支，当没有case可以执行时执行default。\nfor range 当需要从channel中连续的读取数据时，使用for range是比较好的选择。\nfor range会持续地从channel中读取，直到channel被关闭，for range自动退出。\n未完待续。。。","date":"2021-02-16","permalink":"https://why9661.github.io/myblog/posts/golang/channel/","series":null,"tags":["并发组件"],"title":"Golang-Channel"},{"categories":["Golang"],"content":"defer注册的函数会在函数返回前执行。\n以下是defer关键字常见的两个现象：\n  defer关键字会立刻拷贝函数中引用的外部参数，即入参的值在使用defer关键字时就已经确定。\n一个例子\n1func main() { 2 startTime := time.Now() 3 defer fmt.Println(time.Since(startTime)) 4 time.Sleep(10 * time.Second) 5} 6//输出： 7//0s 以上代码并不能实现我们想要统计函数执行时间的需求，因为time.Since(startTime)在传入时值就已经确定。\n可以使用defer+匿名函数来避免这个问题。\n1func main() { 2 startTime := time.Now() 3 defer func() {fmt.Println(time.Since(startTime))}() 4 time.Sleep(10 * time.Second) 5} 6//输出: 7//10.0119478s   defer关键字注册的函数会表现为\u0026quot;倒序执行\u0026quot;\n一个例子\n1func main() { 2\tdefer fmt.Println(\u0026#34;1\u0026#34;) 3\tdefer fmt.Println(\u0026#34;2\u0026#34;) 4\tdefer fmt.Println(\u0026#34;3\u0026#34;) 5} 6//输出： 7//3 8//2 9//1   除此之外，涉及到defer的还有几种容易搞混的情况：\n1func A() int { 2\ta := 1 3\tdefer func() { 4\ta++ 5\t}() 6\treturn a 7} 8 9func B() (a int) { 10\tdefer func() { 11\ta++ 12\t}() 13\treturn 1 14} 15 16func C() (a int) { 17\tdefer func(a int) { 18\ta++ 19\t}(a) 20\treturn 1 21} 22 23func D() (a int) { 24\tdefer func(a *int) { 25\t*a++ 26\t}(\u0026amp;a) 27\treturn 1 28} 29 30func main() { 31\tfmt.Println(A()) //1 32\tfmt.Println(B()) //2 33\tfmt.Println(C()) //1 34\tfmt.Println(D()) //2 35} 首先需要明白return并不是一个原子操作，函数执行到return时：\n1、返回值赋值\n2、如果有注册的defer函数则执行defer函数\n3、ret指令返回\n其次，在Go中函数传参都是值传递。\n在第一种情况中，return a会先将局部变量a的值1赋给返回值，接着执行defer函数，其中a++操作的对象还是局部变量a而不是返回值。\n在第二种情况中，return 1会先将值1赋给返回值a，接着执行defer函数，其中a++操作的对象是返回值a。\n在第三种情况中，return 1会先将值1赋给返回值a，接着执行defer函数，其中传参的值是返回值a的副本，因此修改的a非返回值a。\n在第四种情况中，return 1会先将值1赋给返回值a，接着执行defer函数，其中传参的值是返回值a的地址，因此修改对返回值a有效。\n","date":"2021-02-13","permalink":"https://why9661.github.io/myblog/posts/golang/defer01/","series":null,"tags":["Golang"],"title":"Golang-Defer"},{"categories":["MySQL"],"content":"创建Student表\n1createtableStudent(sidvarchar(10),snamevarchar(10),sagedatetime,ssexnvarchar(10));2insertintoStudentvalues(\u0026#39;01\u0026#39;,\u0026#39;赵雷\u0026#39;,\u0026#39;1990-01-01\u0026#39;,\u0026#39;男\u0026#39;);3insertintoStudentvalues(\u0026#39;02\u0026#39;,\u0026#39;钱电\u0026#39;,\u0026#39;1990-12-21\u0026#39;,\u0026#39;男\u0026#39;);4insertintoStudentvalues(\u0026#39;03\u0026#39;,\u0026#39;孙风\u0026#39;,\u0026#39;1990-05-20\u0026#39;,\u0026#39;男\u0026#39;);5insertintoStudentvalues(\u0026#39;04\u0026#39;,\u0026#39;李云\u0026#39;,\u0026#39;1990-08-06\u0026#39;,\u0026#39;男\u0026#39;);6insertintoStudentvalues(\u0026#39;05\u0026#39;,\u0026#39;周梅\u0026#39;,\u0026#39;1991-12-01\u0026#39;,\u0026#39;女\u0026#39;);7insertintoStudentvalues(\u0026#39;06\u0026#39;,\u0026#39;吴兰\u0026#39;,\u0026#39;1992-03-01\u0026#39;,\u0026#39;女\u0026#39;);8insertintoStudentvalues(\u0026#39;07\u0026#39;,\u0026#39;郑竹\u0026#39;,\u0026#39;1989-07-01\u0026#39;,\u0026#39;女\u0026#39;);9insertintoStudentvalues(\u0026#39;08\u0026#39;,\u0026#39;王菊\u0026#39;,\u0026#39;1990-01-20\u0026#39;,\u0026#39;女\u0026#39;);创建Course表\n1createtableCourse(cidvarchar(10),cnamevarchar(10),tidvarchar(10));2insertintoCoursevalues(\u0026#39;01\u0026#39;,\u0026#39;语文\u0026#39;,\u0026#39;02\u0026#39;);3insertintoCoursevalues(\u0026#39;02\u0026#39;,\u0026#39;数学\u0026#39;,\u0026#39;01\u0026#39;);4insertintoCoursevalues(\u0026#39;03\u0026#39;,\u0026#39;英语\u0026#39;,\u0026#39;03\u0026#39;);创建Teacher表\n1createtableTeacher(tidvarchar(10),tnamevarchar(10));2insertintoTeachervalues(\u0026#39;01\u0026#39;,\u0026#39;张三\u0026#39;);3insertintoTeachervalues(\u0026#39;02\u0026#39;,\u0026#39;李四\u0026#39;);4insertintoTeachervalues(\u0026#39;03\u0026#39;,\u0026#39;王五\u0026#39;);创建Score表\n1createtableScore(sidvarchar(10),cidvarchar(10),scoredecimal(5,2));2insertintoScorevalues(\u0026#39;01\u0026#39;,\u0026#39;01\u0026#39;,80);3insertintoScorevalues(\u0026#39;01\u0026#39;,\u0026#39;02\u0026#39;,90);4insertintoScorevalues(\u0026#39;01\u0026#39;,\u0026#39;03\u0026#39;,99);5insertintoScorevalues(\u0026#39;02\u0026#39;,\u0026#39;01\u0026#39;,70);6insertintoScorevalues(\u0026#39;02\u0026#39;,\u0026#39;02\u0026#39;,60);7insertintoScorevalues(\u0026#39;02\u0026#39;,\u0026#39;03\u0026#39;,80);8insertintoScorevalues(\u0026#39;03\u0026#39;,\u0026#39;01\u0026#39;,80);9insertintoScorevalues(\u0026#39;03\u0026#39;,\u0026#39;02\u0026#39;,80);10insertintoScorevalues(\u0026#39;03\u0026#39;,\u0026#39;03\u0026#39;,80);11insertintoScorevalues(\u0026#39;04\u0026#39;,\u0026#39;01\u0026#39;,50);12insertintoScorevalues(\u0026#39;04\u0026#39;,\u0026#39;02\u0026#39;,30);13insertintoScorevalues(\u0026#39;04\u0026#39;,\u0026#39;03\u0026#39;,20);14insertintoScorevalues(\u0026#39;05\u0026#39;,\u0026#39;01\u0026#39;,76);15insertintoScorevalues(\u0026#39;05\u0026#39;,\u0026#39;02\u0026#39;,87);16insertintoScorevalues(\u0026#39;06\u0026#39;,\u0026#39;01\u0026#39;,31);17insertintoScorevalues(\u0026#39;06\u0026#39;,\u0026#39;03\u0026#39;,34);18insertintoScorevalues(\u0026#39;07\u0026#39;,\u0026#39;02\u0026#39;,89);19insertintoScorevalues(\u0026#39;07\u0026#39;,\u0026#39;03\u0026#39;,98);  查询\u0026quot;01\u0026quot;课程比\u0026quot;02\u0026quot;课程成绩高的学生的信息及课程分数；\n解析：内连接join和别名as的使用\n1selecta.*,t3.c1_score,t3.c2_scorefrom2(selectt1.sid,t1.c1_score,t2.c2_scorefrom3(selectsid,scoreasc1_scorefromScorewherecid=\u0026#39;01\u0026#39;)ast14join5(selectsid,scoreasc2_scorefromScorewherecid=\u0026#39;02\u0026#39;)ast26ont1.sid=t2.sidwheret1.c1_score\u0026gt;t2.c2_score)ast37join8Studentasaona.sid=t3.sid;  查询学生选课存在\u0026quot; 01 \u0026ldquo;课程但可能不存在\u0026rdquo; 02 \u0026ldquo;课程的情况（不存在时显示为 null);\n解析：左连接left join的使用\n1select*from2(select*fromScorewherecid=\u0026#39;01\u0026#39;)ast13leftjoin4(select*fromScorewherecid=\u0026#39;02\u0026#39;)ast25ont1.sid=t2.sid;  查询平均成绩大于等于 60 分的同学的学生编号和学生姓名和平均成绩；\n解析：分组查询group by\u0026hellip;having\u0026hellip;以及聚合函数avg的使用\n1selectt2.sid,t2.sname,t1.avg_scorefrom2(selectsid,avg(score)asavg_scorefromScoregroupbysidhavingavg(score)\u0026gt;=60)ast13join4Studentast2ont1.sid=t2.sid;  查询在 Score 表存在成绩的学生信息；\n1select*fromStudentwheresidin(selectdistinctsidfromScore);  查询「李」姓老师的数量；\n解析：count函数like关键字以及通配符%的使用。\n1selectcount(*)fromteacherwheretnamelike\u0026#39;李%\u0026#39;;  查询各科成绩最高分、最低分和平均分,以如下形式显示：\n课程 id，最高分，最低分，平均分，及格率，中等率，优良率，优秀率\n及格为\u0026gt;=60，中等为：[70,80)，优良为：[80-90)，优秀为：\u0026gt;=90\n解析：max、min、avg、sum函数case when语句以及分组group by的使用\n1selectcidas课程iD,2max(score)as最高分,3min(score)as最低分,4avg(score)as平均分,5sum(casewhenscore\u0026gt;=60then1else0end)/count(sid)as及格率,6sum(casewhenscore\u0026gt;=70andscore\u0026lt;80then1else0end)/count(sid)as中等率,7sum(casewhenscore\u0026gt;=80andscore\u0026lt;90then1else0end)/count(sid)as优良率,8sum(casewhenscore\u0026gt;=90then1else0end)/count(sid)as优秀率9fromscoregroupbycid;  按各科成绩进行排序，并显示排名;\n解析：排序函数rank() over()、dense_rank() over()、row_number() over()的区别和使用,以及分区partition by的使用\n1select*,rank()over(partitionbycidorderbyscoredesc)asrankedfromscore;1select*,dense_rank()over(partitionbycidorderbyscoredesc)asrankedfromscore;1select*,row_number()over(partitionbycidorderbyscoredesc)asrankedfromscore;  查询学生的总成绩，并显示排名;\n1select*,(rank()over(orderbyt1.totaldesc))asrankedfrom2(selectsid,sum(score)astotalfromscoregroupbysid)ast1;  查询出只选修两门课程的学生学号和姓名;\n1selectsid,snamefromstudent2wheresidin(selectsidfromscoregroupbysidhavingcount(cid)=2);  查询 1990 年出生的学生名单;\n解析：year函数的使用\n1select*fromstudentwhereyear(sage)=1990;  查询各学生的年龄，只按年份来算；\n1selectsname,(year(now())-year(sage))asagefromstudent;  按照出生日期来算，当前月日 \u0026lt; 出生年月的月日则，年龄减一；\n解析：date_format函数的使用\n1selectsname,2(casewhen(date_format(now(),\u0026#39;%m-%d\u0026#39;)-date_format(sage,\u0026#39;%m-%d\u0026#39;))\u0026lt;03thenyear(now())-year(sage)-14elseyear(now())-year(sage)5end)asage6fromstudent;  查询本周过生日的学生；\n解析：week函数的使用（week函数返回的是今年的第几周）\n1select*fromstudentwhereweek(now())=week(sage);  查询下周过生日的学生;\n+1即可\n  查询本月过生日的学生;\n同理\n  查询下月过生日的学生;\n同理\n ","date":"2021-02-12","permalink":"https://why9661.github.io/myblog/posts/mysql/%E7%BB%83%E4%B9%A0%E9%A2%98/","series":null,"tags":["MySQL"],"title":"MySQL-基础练习题01"},{"categories":["MySQL"],"content":"当数据库中有多个事务同时执行的时候，就可能会出现以下问题：\n脏读：A事务还未提交，B事务就读到了A事务的结果。\n不可重复读：A事务在本次事务中，对某行多次读取，结果出现了前后不一致的情况。\n幻读：一个事务在前后两次查询同一范围的时候，后一次查询看到了前一次查询没有看到的行。\n为了解决上面的问题，就有了“隔离级别”的概念。\n事务的四个隔离级别\n  读未提交（read uncommitted）\n一个事务还未提交它做的变更就可以被另一个事务读取到。\n  读已提交（read committed）\n一个事务提交后它做的变更才可以被另一个事务读取到。\n  可重复读（repeatable read）\n一个事务执行过程中看到的数据总是跟这个事务在启动时看到的数据是一直的。\n  串行化（serializable）\n对同一行记录，写会加“写锁”，读会加“读锁”。当出现读写冲突时，后来的事务必须等前一个事务执行完成才能继续执行。\n  InnoDB默认的隔离级别是RR，默认开启事务自动提交（autocommit=on）。\n1showvariableslike\u0026#39;transaction_isolation\u0026#39;;2showvariableslike\u0026#39;autocommit\u0026#39;;事务的开启与提交有以下两种情况：\n1、若参数autocommit=off，事务在用户本次对数据进行操作时自动开启，在用户执行commit命令时提交，用户本次对数据库开始进行操作到用户执行commit命令之间的一系列操作为一个完整的事务周期。若不执行commit命令，系统则默认事务rollback。\n2、若参数autocommit=on，事务的开启与提交又分为两种状态：\n①当用户执行start transaction（begin）命令时，手动开启一个事务，当用户执行commit命令时当前事务提交。从用户开启事务到用户提交事务之间的一系列操作为一个完整的事务周期。若不执行commit命令，系统则默认事务rollback。\n②如果用户未执行start transaction（begin）命令而对数据库进行了操作，系统则默认用户对数据库的每一个操作为一个孤立的事务（除了select），也就是说用户每进行一次操作系都会即时提交。这种情况下用户的每一个操作都是一个完整的事务周期。\nInnoDB的行数据有多个版本，每个数据版本有自己的row trx_id，每个事务或者语句有自己的一致性视图，普通查询语句是一致性读（快照读），会根据row trx_id和一致性视图来确定数据版本的可见性。而更新数据都是先读后写的，这个读是当前读（读取当前数据的最新版本），此外加锁的查询语句（for update/lock in share mode）也是当前读。\n\u0026ldquo;可重复读\u0026quot;的一致性视图是在事务开始时创建的，而“读提交”的一致性视图是在每一个语句执行前创建的。需要说明的是，start transaction/begin并不是一个事务的开始，而是在执行第一个操作表的语句时事务才会真正启动，要想立马启动一个事务，可以用使用start transaction with consistent snapshot这个命令。\n接下来详细介绍数据版本的可见性是怎么确定的：\nInnoDB里面每个事务有一个唯一的事务ID，它是在事务开始前向InnoDB事务系统申请的，这个ID是按申请顺序严格递增的。\nInnoDB里每行数据也都是有多个版本的，每次事务更新数据的时候，都会生成一个新的数据版本，并且把事务ID赋给这个数据版本，记为row trx_id，同时旧的数据版本要保留，并且在新的数据版本中，能够有信息可以拿到它（回滚指针+undo log）。\nInnoDB为每个事务构造了一个数组，用来保存在这个事务启动瞬间，当前系统中\u0026quot;活跃\u0026quot;的所有事务ID（启动了但还未提交）。数组里面事务ID的最小值记为低水位，当前系统里面已经创建过的事务ID的最大值加1记为高水位。这个视图数组和高水位就组成了当前事务的一致性视图，而数据版本的可见性规则就是基于数据的row trx_id和这个一致性视图对比得到的。\n对于当前事务的启动瞬间，一个数据版本的row trx_id就有以下几种情况：\n1、如果落在绿色部分，表示这个版本是已提交的事务，可见\n2、如果落在红色部分，表示这个版本是由将来启动的事务生成的，不可见\n3、如果落在黄色部分，那就包括两种情况：\n​\ta.若row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见\n​\tb.若row trx_id不在数组中，表示这个版本是由已提交的事务生成的，可见\n更清晰明了的判断方式：\n1、一个事务的更新对自己本身总是可见的\n2、版本未提交，不可见；\n3、版本已提交，但是是在视图创建后提交的，不可见\n4、版本已提交，是在视图创建前提交的，可见\n例子\n1createtablet(2idintnotnullprimarykeyauto_increment,3ageint4);5insertintotvalues(1,10);   事务A 事务B 事务C     start transaction with consistent snapshot;      start transaction with consistent snapshot;      update t set age=age+1 where id =1;    update t set age=age+1 where id=1;select age from t where id=1;    select age from t where id=1;commit;      commit;     下面来看事务A的查询结果，事务A的一致性视图是最先创建的\n事务B更新后的(1,12)还未提交，不可见；\n事务C更新后的(1,11)提交了但是是在事务A视图创建后提交的，不可见；\n(1,10)是在事务A视图创建前提交的，可见；\n所以事务A查询到的结果是10。\n接下来看一下更新逻辑，需要注意的是更新逻辑是\u0026quot;先读后写\u0026rdquo;，这个读是当前读即读到的是这个数据最新的版本。\n所以对于事务B的查询结果：\n更新语句会先读，读到的是事务C更新后的(1,11)；\n然后写变为(1,12)；\n事务内的更新对自己总是可见的，因此查询B的查询结果是12。\n把上面的例子修改一下\n   事务B 事务C     start transaction with consistent snapshot;     start transaction with consistent snapshot;update t set age=age+1 where id=1;   update t set age=age+1 where id=1;\u0026ndash;阻塞select age from t where id=1;     commit;   commit;     再来看下更新逻辑：\n事务C更新后数据的最新版本为(1,11)，但还未提交；\n根据两阶段锁，事务C会一直持有id=1这行记录的写锁，直到事务C提交释放锁，因此事务B会先阻塞直至事务C提交；\n","date":"2021-01-20","permalink":"https://why9661.github.io/myblog/posts/mysql/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/","series":null,"tags":["MySQL"],"title":"MySQL-事务隔离级别"},{"categories":["Golang"],"content":"Golang中变量分配在栈上还是堆上，取决于变量是否发生了逃逸，逃逸分析是在编译阶段确定的。\n检测逃逸的命令\n1go run -gcflags \u0026#34;-m -l\u0026#34; main.go 变量逃逸场景\n  指针逃逸\n这是变量逃逸最普遍的一种场景，即变量在其作用域之外被引用。\n1func escape() *int { 2\tx := 10 3\treturn \u0026amp;x 4} 5 6func main() { 7\t_ = escape() 8} 运行go run -gcflags \u0026quot;-m -l\u0026quot; main.go\n1.\\main.go:4:2: moved to heap: x   闭包引起的变量堆分配\n1func closure() func() int { 2\tx := 10 3\treturn func() int { 4 x++ 5 return x 6\t} 7} 8 9func main() { 10\t_ = closure() 11} 运行go run -gcflags \u0026quot;-m -l\u0026quot; main.go\n1.\\main.go:4:2: moved to heap: x 2.\\main.go:5:9: func literal escapes to heap   interface{}类型在编译阶段无法确定具体类型，发生逃逸。\ninterface{}类型的值部分在堆上分配\n1func main() { 2\tx := 10 3\tfmt.Printf(\u0026#34;%v\u0026#34;, x) 4} 运行go run -gcflags \u0026quot;-m -l\u0026quot; main.go\n1.\\main.go:7:12: ... argument does not escape 2.\\main.go:7:13: x escapes to heap 310 1func main() { 2\tx := 10 3\tfmt.Printf(\u0026#34;%v\u0026#34;, \u0026amp;x) 4} 运行go run -gcflags \u0026quot;-m -l\u0026quot; main.go\n1.\\main.go:6:2: moved to heap: x 2.\\main.go:7:12: ... argument does not escape 30xc00000a0a8   变量太大\n1func generate8191() { 2\tnums := make([]int, 8191) // \u0026lt; 64KB 3\tfor i := 0; i \u0026lt; 8191; i++ { 4 nums[i] = rand.Int() 5\t} 6} 7 8func generate8192() { 9\tnums := make([]int, 8192) // = 64KB 10\tfor i := 0; i \u0026lt; 8192; i++ { 11 nums[i] = rand.Int() 12\t} 13} 14 15func generate(n int) { 16\tnums := make([]int, n) // 不确定大小 17\tfor i := 0; i \u0026lt; n; i++ { 18 nums[i] = rand.Int() 19\t} 20} 21 22func main() { 23\tgenerate8191() 24 generate8192() 25 generate(1) 26} 运行go run -gcflags \u0026quot;-m -l\u0026quot; main.go\n1.\\main.go:6:14: make([]int, 8191) does not escape 2.\\main.go:13:14: make([]int, 8192) escapes to heap 3.\\main.go:20:14: make([]int, n) escapes to heap   一个例子\n1type Person struct{} 2 3func main() { 4\ta := \u0026amp;Person{} 5\tb := \u0026amp;Person{} 6\tfmt.Println(a == b) //false 很合理，栈上两个不同变量的地址 7} 1type Person struct{} 2 3func main() { 4\ta := \u0026amp;Person{} 5\tb := \u0026amp;Person{} 6\tfmt.Printf(\u0026#34;%p\\n\u0026#34;, a) 7\tfmt.Printf(\u0026#34;%p\\n\u0026#34;, b) 8\tfmt.Println(a == b) //true ？？？ 9} 原因：\n1、fmt标准库的Printf的方法导致原本分配在栈上的变量a、b逃逸到了堆上\n2、runtime的一个优化细节：0字节在堆上分配时都会指向zerobase这一个地址\n1// base address for all 0-byte allocations 2var zerobase uintptr 1type Person struct{} 2 3type Animal struct{} 4 5func main() { 6\ta := \u0026amp;Person{} 7\tb := \u0026amp;Animal{} 8\tfmt.Printf(\u0026#34;%p\\n\u0026#34;, a) //0xb8c578 9\tfmt.Printf(\u0026#34;%p\\n\u0026#34;, b) //0xb8c578 10} ","date":"2020-12-02","permalink":"https://why9661.github.io/myblog/posts/golang/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/","series":null,"tags":["Golang"],"title":"Golang-逃逸分析"},{"categories":["algorithm"],"content":"为什么要使用一致性哈希？\n普通的基于模运算的哈希算法会因为节点数目的变化而容易引起缓存雪崩（缓存在同一时刻全部失效，造成瞬时DB请求量大，压力骤增）。\n一致性哈希算法将 key 和节点映射到 2^32 的空间中，将这个数字首尾相连，形成一个环。\n①计算节点/机器(通常使用节点的名称、编号和 IP 地址)的哈希值，放置在环上。\n②计算key的哈希值放置在环上，顺时针寻找到的第一个节点，就是应选取的节点/机器。\n对于一致性哈希可能产生的数据倾斜的问题，可以引入“虚拟节点”：\n1、将虚拟节点的哈希值映射在环上\n2、计算key的哈希值，在环上顺时针寻找到应选取的虚拟节点\n3、通过虚拟节点映射到真实节点\n1package consistenthash 2 3import ( 4\t\u0026#34;hash/crc32\u0026#34; 5\t\u0026#34;sort\u0026#34; 6\t\u0026#34;strconv\u0026#34; 7) 8 9type hash func(data []byte) uint32 10 11type CHash struct { 12\thash hash 13\treplicas int //the number of virtual nodes 14\tkeys []int 15\tvrMap map[int]string //mapping: virtual node-real node 16} 17 18func NewCHash(replicas int, hashFunc hash) *CHash { 19\tcHash := CHash{ 20\thash: hashFunc, 21\treplicas: replicas, 22\tvrMap: make(map[int]string), 23\t} 24 25\tif cHash.hash == nil { 26\tcHash.hash = crc32.ChecksumIEEE 27\t} 28 29\treturn \u0026amp;cHash 30} 31 32func (ch *CHash) Add(keys ...string) { 33\tfor _, key := range keys { 34\tfor i := 0; i \u0026lt; ch.replicas; i++ { 35\thashData := []byte(strconv.Itoa(i) + key) 36\thash := int(ch.hash(hashData)) 37\tch.keys = append(ch.keys, hash) 38\tch.vrMap[hash] = key 39\t} 40\t} 41 42\tsort.Ints(ch.keys) 43} 44 45func (ch *CHash) Get(key string) string { 46\tif ch.keys == nil { 47\treturn \u0026#34;\u0026#34; 48\t} 49 50\thash := int(ch.hash([]byte(key))) 51\tindex := sort.Search(len(ch.keys), func(i int) bool { 52\treturn ch.keys[i] \u0026gt;= hash 53\t}) 54 55\treturn ch.vrMap[ch.keys[index%len(ch.keys)]] 56} ","date":"2020-09-11","permalink":"https://why9661.github.io/myblog/posts/algorithm/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C/","series":null,"tags":["负载均衡"],"title":"负载均衡-一致性哈希"},{"categories":["algorithm"],"content":"普通轮询 1package roundrobin 2 3type RoundRobin struct { 4 curIndex int 5 nodes []string 6} 7 8func NewRoundRobin() *RoundRobin { 9 return \u0026amp;RoundRobin{} 10} 11 12func (rrb *RoundRobin) Add(keys ...string) { 13 for _, key := range keys { 14 rrb.nodes = append(rrb.nodes, key) 15 } 16} 17 18func (rrb *RoundRobin) Get() string { 19 rrb.curIndex++ 20 rrb.curIndex = rrb.curIndex % len(rrb.nodes) 21 return rrb.nodes[rrb.curIndex] 22} 平滑加权轮询 每个节点有3种权重：\nWeight：配置权重\nCurrentWeight：当前权重\nEffectiveWeight：有效权重\n初始化一个节点时配置权重=当前权重=有效权重\nTotalWeight：所有节点的总权重（有效权重）\n算法步骤：\n1、遍历所有节点，设置当前节点的CurrentWeight=CurrentWeight+EffectiveWegiht\n2、选取CurrentWeight最大的节点。\n2、被选取的节点CurrentWeight=CurrentWeight-TotalWeight\n在遍历过程中计算出TotalWeight\n1package weightroundrobin 2 3type WeightRoundRobin struct { 4 nodes []*Node 5} 6 7type Node struct { 8 weight int 9 curWeight int 10 effectiveWeight int 11 key string 12} 13 14func NewWeightRoundRobin() *WeightRoundRobin { 15 return \u0026amp;WeightRoundRobin{} 16} 17 18func newNode(key string, weight int) *Node { 19 node := Node{ 20 weight: weight, 21 curWeight: weight, 22 effectiveWeight: weight, 23 key: key, 24 } 25 26 return \u0026amp;node 27} 28 29func (wrrb *WeightRoundRobin) Add(key string, weight int) { 30 node := newNode(key, weight) 31 32 wrrb.nodes = append(wrrb.nodes, node) 33} 34 35func (wrrb *WeightRoundRobin) Get() string { 36 totalWeight := 0 37 38 var maxCurWeightNode *Node 39 40 for _, node := range wrrb.nodes { 41 totalWeight += node.effectiveWeight 42 43 node.curWeight += node.effectiveWeight 44 45 if maxCurWeightNode == nil || node.curWeight \u0026gt; maxCurWeightNode.curWeight { 46 maxCurWeightNode = node 47 } 48 } 49 50 maxCurWeightNode.curWeight -= totalWeight 51 52 return maxCurWeightNode.key 53} ","date":"2020-09-02","permalink":"https://why9661.github.io/myblog/posts/algorithm/%E8%BD%AE%E8%AF%A2/","series":null,"tags":["负载均衡"],"title":"负载均衡-轮询算法"},{"categories":["Golang"],"content":"Slice的底层数据结构\n1type SliceHeader struct { 2\tData uintptr //指向第一个slice元素对应的底层数组元素的地址 3\tLen int\t//切片长度（slice的元素数目） 4\tCap int\t//切片容量（从slice的开始位置到底层数据的结尾位置的长度） 5} 注意以下声明切片的方式：\n1var s1 []int //Data=nil Len=Cap=0 没有分配底层数组 2s2 := make([]int, 0) //Data!=nil Len=Cap=0 分配底层数组 3s3 := []int{} //Data!=nil Len=Cap=0\t分配底层数组 4s4 := new([]int) //指向一个（Data=nil, Len=Cap=0）的slice 没有分配底层数组 多个slice可以共享底层数组，因此对一个切片的元素修改会影响也会影响其它切片。\n1months := [...]string{1: \u0026#34;January\u0026#34;, /* ... */, 12: \u0026#34;December\u0026#34;} 2Q2 := months[4:7] 3summer := months[6:9] 4fmt.Println(Q2) // [\u0026#34;April\u0026#34; \u0026#34;May\u0026#34; \u0026#34;June\u0026#34;] 5fmt.Println(summer) // [\u0026#34;June\u0026#34; \u0026#34;July\u0026#34; \u0026#34;August\u0026#34;] slice比较\nslice不能直接用==比较。\n对于byte类型的slice，可以用标准库的bytes.Equal函数进行比较。\n对于其它类型的slice：\n  比较两个切片的长度，且两个切片对应下标的值也相等\n  reflect.DeepEqual\n两种方法简单的性能比较：\n1func genSlice(size int) ([]uint32, []uint32) { 2\trand.Seed(time.Now().UnixNano()) 3\ts1 := make([]uint32, 0, size) 4\tfor i := 0; i \u0026lt; size; i++ { 5 s1 = append(s1, rand.Uint32()) 6\t} 7\ts2 := make([]uint32, len(s1)) 8\tcopy(s2, s1) 9 10\treturn s1, s2 11} 12 13/* 14func compare(a, b []uint32) bool { 15if (a == nil) != (b == nil) { 16return false 17} 1819if len(a) != len(b) { 20return false 21} 2223for i := range a { 24if a[i] != b[i] { 25return false 26} 27} 2829return true 30} 31*/ 32func BenchmarkCompare(b *testing.B) { 33\ts1, s2 := genSlice(1000) 34\tb.ResetTimer() 35\tfor i := 0; i \u0026lt; b.N; i++ { 36 _ = compare(s1, s2) 37\t} 38} 39 40func BenchmarkDeepEqual(b *testing.B) { 41\ts1, s2 := genSlice(1000) 42\tb.ResetTimer() 43\tfor i := 0; i \u0026lt; b.N; i++ { 44 _ = reflect.DeepEqual(s1, s2) 45\t} 46} 1go test -bench=. 2BenchmarkCompare-4 1621315 672.8 ns/op 3BenchmarkDeepEqual-4 10000 137540 ns/op   ​\nslice扩容\n  预估扩容后容量\n 如果扩容前容量*2\u0026lt;所需容量，那么预估容量=所需容量 如果扩容前容量*2\u0026gt;所需容量  如果切片长度\u0026lt;1024，那么预估容量=扩容前容量*2 否则预估容量=扩容前容量*1.25，直到预估容量\u0026gt;所需容量      计算所需的内存\n预估容量*元素类型大小\n  匹配合适的内存规格\n匹配足够大且最接近的规格\n  确定容量\n内存大小/元素类型大小\n  slice拷贝\n拷贝的长度length=min(len(dst), len(src))\n1func copy(dst, src []Type) int 注意事项\n  Slice发生扩容时，会重新分配底层数组\n  对没有分配底层数组的slice进行赋值操作会触发panic，可以进行append操作。\n1var ints []int 2ints[0] = 1 //panic 3 4ints = append(ints, 1) //√  ","date":"2020-07-05","permalink":"https://why9661.github.io/myblog/posts/golang/slice/","series":null,"tags":["Golang"],"title":"Golang-切片"},{"categories":["Golang"],"content":"make和new有哪些不同？\n  make仅用于slice、map、channel三种类型的创建，返回的是所创建类型本身。\nnew可用于任意类型的创建，返回的是指向所创建类型的指针。\n  make创建slice、map、channel时会初始化内部数据结构，如slice的创建，会分配底层数组(Data)、初始化长度（Len）、初始化容量（Cap）。\nnew不会对内部数据结构进行初始化。\n  关于make和new创建的变量是分配在堆上还是在栈上，需要进行逃逸分析，这和其它一些语言的new分配在堆上不同。\n ","date":"2020-06-05","permalink":"https://why9661.github.io/myblog/posts/golang/make%E5%92%8Cnew/","series":null,"tags":["Golang"],"title":"Golang-内置函数make和new的区别"}]