[{"categories":["Docker"],"content":"安装 官网。\n配置镜像加速\n  vim /etc/docker/daemon.json\n  1{ 2 \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;http://hub-mirror.c.163.com\u0026#34;] 3}   systemctl daemon-reload\nsystemctl restart docker\n  简介 虚拟机vs容器 虚拟机是在宿主机上虚拟一个OS，所以虚拟机的运行需要消耗很多系统内存和CPU，这样不可避免的就同应用程序争抢资源，而容器化的应用是直接运行在宿主机上的和宿主机共享内核，基本上无需额外的CPU和内存消耗。\n虚拟机上的应用同宿主机进行IO等交互时由于需要经过虚拟机这个中间介质，所以IO效率相比容器就会低很多。\n隔离\u0026amp;资源限制 docker使用linux内核的namespace、cgroups机制来实现容器之间的隔离和资源限制的。\nnamespace namespace主要有PID namespace、 挂载点信息隔离的Mount namespace、 隔离网络资源的Network namespace、隔离用户的User namespace等。\ncgroup CGroup技术是用来限制单个进程对CPU、内存、磁盘等资源的占用，Docker通过cgroup限制docker启动的进程对以上资源的消耗。\nCPU相关的限制\n  \u0026ndash;cpus decimal\n限制容器使用的cpu数量\n  \u0026ndash;cpuset-cpus string\n限制容器在某个（可以多个）cpu上运行\n  \u0026ndash;cpu-shares int\n设置使用cpu的权重（当 cpu资源充足时，设置 cpu的权重是没有意义的。只有在容器争用 cpu资源的情况下， cpu的权重才能让不同的容器分到不同的 cpu用量）\n  内存相关的限制\n  -m(\u0026ndash;memory) bytes\n限制容器可以使用的最大内存\n  \u0026ndash;memory-swap bytes\n限制容器可以使用的swap大小（实际表示的是memory和swap之和！）\n必须和\u0026ndash;memory一起使用\n  Dockerfile 注释使用#\nFROM 指定基础镜像，在这个基础镜像之上进行修改定制。\n必须为第一个命令。\nDocker 还有一个特殊的镜像 scratch，这个镜像是虚拟的，表示空白镜像。\nLABEL 通常用于指定镜像制作者的信息以及其它的一些描述信息\nENV 设置环境变量\nENV ==\u0026hellip;\nWORKDIR WORKDIR 用来切换工作目录。Docker 默认的工作目录是/，只有 RUN 能执行 cd 命令切换目录，而且还只作用在当下的 RUN。如果想让其他指令在指定的目录下执行，就得靠 WORKDIR。\nWORKDIR 动作的目录改变是持久的，不用每个指令前都使用一次 WORKDIR。\nRUN 构建镜像时（docker build）执行的命令。\nRUN的默认权限是sudo。 需要注意的是，如果你需要执行多个RUN操作，那最好把它们合并在一行 (用\u0026amp;\u0026amp;连接)，因为每执行一次RUN就会在docker上新建一层镜像，所以分开来写很多个RUN的结果就是会导致整个镜像无意义的过大膨胀。\nCMD 与RUN不同，CMD是创建容器时（docker run）所执行的命令。\nDockerfile中只能设置一个CMD，如果设置多个，那么生效的是最后一个。\nCMD 指令指定的程序可被 docker run 命令行参数中指定要运行的程序所覆盖。\nCMD [\u0026ldquo;操作\u0026rdquo;，\u0026ldquo;参数1\u0026rdquo;，”参数2“]\nENTRYPOINT 与CMD非常类似，不同的是通过docker run执行的命令不会覆盖ENTRYPOINT。\nENTRYPOINT[”操作“，“参数1”，“参数2”]\nADD 从上下文目录中复制文件或者目录到容器里指定路径，tar类型会自动解压。\n可以访问网络资源（类似wget）\nCOPY 从上下文目录中复制文件或者目录到容器里指定路径，功能类似ADD，但是不会自动解压，也不能访问网络资源。\nEXPOSE 声明运行时容器提供的服务端口，这只是一个声明，并不会自动在宿主进行端口映射。\n简单例子 1FROMgolang:alpine2 3ENV GO111MODULE=on GOPROXY=\u0026#34;https://goproxy.cn,direct\u0026#34;45WORKDIR/app67ADD . .89RUN go build -o server1011CMD [\u0026#34;./server\u0026#34;]常用命令 镜像 构建镜像 docker build 基于Dockerfile创建镜像\neg: docker build -t myapp:v1.0.0 .\n\u0026ndash;file -f 指定Dockerfile，默认是当前路径下的Dockerfile\n\u0026ndash;tag -t 设置镜像名称和版本 name:tag\n.代表本次执行的上下文路径\n上下文路径，是指 docker 在构建镜像，有时候想要使用到本机的文件（比如复制），docker build 命令得知这个路径后，会将路径下的所有内容打包。\n解析：由于 docker 的运行模式是 C/S。我们本机是 C，docker 引擎是 S。实际的构建过程是在 docker 引擎下完成的，所以这个时候无法用到我们本机的文件。这就需要把我们本机的指定目录下的文件一起打包提供给 docker 引擎使用。\ndocker commit 基于容器创建镜像\n-a 作者\n-m 描述\neg: docker commit -a \u0026ldquo;WHY\u0026rdquo; -m \u0026ldquo;centos7 with golang\u0026rdquo; mycontainer（容器名） mycentos:V1.0（镜像名）\nexport和import(?) export 和 import也是根据容器来创建镜像，export将本机的容器导出为镜像包，import导入包为镜像。\neg：docker export e5d \u0026gt; golang-helloworld.tar\n​\tdocker import golang-helloworld.tar hello:v1.0\nsave和load save和load是根据镜像来创建镜像，save将本地的镜像导出为镜像包，load导入包为镜像。\neg：docker save hello-world:v1.0 \u0026gt; hello.tar\n​\tdocker load -i hello.tar\ndocker save -o同时打包多个镜像\neg: docker save -o many.tar hello-world:v1.0 mysql:v1.0\ndocker images 查看本地镜像\n删除镜像 docker rmi 删除镜像\neg: docker rmi xxxxxxx\ndocker image prune -a 清除所有未使用镜像\ndocker pull docker pull image:tag\n从镜像仓库拉取或更新指定镜像。当没有指定版本时，会默认拉取latest。\neg: docker pull redis\ndocker tag docker tag用于给本地镜像添加tag\neg:docker tag hello-world:latest hywong1996/hello-world-test:v1.0\ndocker search 搜索镜像\neg：docker search golang\ndocker inspect 获取镜像/容器的元数据\n容器 docker rm -f 强制删除（包括正在运行的容器）\n删除容器\neg: docker rm xxxxxx\ndocker container prune 删除所有非运行状态的容器\ndocker ps 查看（运行中的）容器\n-a 查看所有容器\ndocker update 更新一些配置\ndocker run 创建容器\neg：docker run -d -p 8000:8000 \u0026ndash;name container01 mytest:v1.1\n常用参数\n-d 创建一个守护式容器在后台运行\n-p 指定容器暴露的端口 （将容器的端口映射到宿主机） 宿主机端口:容器端口\n-P 随机选取宿主机端口与容器内暴露的端口映射\n-i 表示以交互方式运行容器\n-t 容器启动后进入其命令行（为容器重新分配一个伪终端）\n\u0026ndash;name 指定容器名字\n-e 设置环境变量(key=value)\n-h 指定容器的主机名\n  容器重启策略\n\u0026ndash;restart\n①no 默认策略，在容器退出时不重启\n②always 容器退出时总是重启\n③on-failure\n④on-failure:3\n⑤unless-stopped\n  目录挂载（数据卷操作）\n-v\n在创建容器的时候，可以将宿主机目录与容器内目录进行映射，从而达到持久化的目的。\n①指定目录挂载 -v 宿主机目录:容器目录\n②匿名挂载 -v 容器目录 （会存在宿主机的/var/lib/docker/volumes下）\n③具名挂载 -v 数据卷名:容器目录 （相对于匿名挂载，相当于给数据卷起了个名）\n④只读或读写 -v 宿主机目录:容器目录:ro/rw（默认读写rw） （容器不能写这个目录）\n⑤继承 \u0026ndash;volumes-from\n  \u0026ndash;rm参数\n当容器退出时自动删除容器，释放资源。可用与单元测试或压力测试\n  docker exec 进入容器\neg： docker exec -it mycontainer /bin/bash（要执行的命令，这里是打开bash）\ndocker start 启动容器\neg: docker start mycontainer01\ndocker stop 停止容器\neg: docker stop mycontainer01\ndocker kill 直接kill掉一个容器\ndocker cp 将文件拷贝到容器，或将容器中的文件拷贝到宿主机\ndocker cp 需要拷贝的文件或目录 容器名称：容器目录\ndocker cp 容器名称：容器目录 需要拷贝的文件或目录\ndocker logs 查看容器的日志\ndocker rename 容器重命名\n监控容器资源消耗 docker stats\n仓库 公共仓库 Docker Hub\n  docker login\t登录\n  docker tag 给image打标签\n  docker push 推送image\n  docker logout 退出\n  eg:\ndocker tag hello-world:latest hywong1996/hello-world-test:v1.0\ndocker push hywong1996/hello-world-test:v1.0\n注意：打标签时要改到自己的账户名下（hywong1996），否则会出错\n私有仓库   docker pull registry （用于搭建私有仓库的镜像）\n  修改配置文件\n/etc/docker/daemon.json\n添加\u0026quot;insecure-registries\u0026quot;:[\u0026ldquo;地址:5000\u0026rdquo;]\n  重新加载配置文件\nsystemctl daemon-reload\n  重新启动docker\nsystemctl restart docker\n  创建私有仓库容器\ndocker run \u0026ndash;name registry -id -p 5000:5000 registry\n  验证\n地址:5000/v2/_catalog\n  docker tag\n  docker pull\n  注意：如果出现”http: server gave HTTP response to HTTPS client“这个问题\nsystemctl enable docker.service\n修改 /usr/lib/systemd/system/docker.service 中的 ExecStart 选项，加入\u0026ndash;insecure-registry 地址:5000\nsystemctl daemon-reload\nsystemctl restart docker\n网络模式 docker network\nbridge模式（默认） docker run \u0026ndash;network bridge\nDocker守护进程会在宿主机上创建一个名为docker0的虚拟网桥，此主机上启动的Docker容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。\n从docker0子网中分配一个IP给容器使用，并设置docker0的IP地址为容器的默认网关。在主机上创建一对虚拟网卡veth pair设备，Docker将veth pair设备的一端放在新创建的容器中，并命名为eth0（容器的网卡），另一端放在主机中，以vethxxx这样类似的名字命名，并将这个网络设备加入到docker0网桥中。\nhost模式 docker run \u0026ndash;network host\n如果启动容器的时候使用host模式，那么这个容器将不会获得一个独立的Network Namespace，而是和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。但是，容器的其他方面，如文件系统、进程列表等还是和宿主机隔离的。\ncontainer模式 docker run \u0026ndash;network container:容器\n这个模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过 lo 网卡设备通信。 kubernetes中的pod就是多个容器共享一个Network namespace。\nnone模式 docuer run \u0026ndash;network none\n使用none模式，Docker容器拥有自己的Network Namespace，但是，并不为Docker容器进行任何网络配置。也就是说，这个Docker容器没有网卡、IP、路由等信息。需要我们自己为Docker容器添加网卡、配置IP等。\n自定义网络 docker network create\ndocker daemon 实现了一个内嵌的DNS Server，但是只能在自定义网络中使用，这样就可以通过容器名进行通信。\n常见问题   构建镜像时报错：runc: symbol lookup error: runc: undefined symbol: seccomp_api_get\n解决方法：yum install libseccomp-devel\n ","date":"2021-10-18","permalink":"https://why9661.github.io/myblog/posts/docker/docker%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/","series":null,"tags":["Docker"],"title":"Docker使用手册"},{"categories":["Redis"],"content":"主从模式 主从模式可降低读写压力，Master以写为主，Slave以读为主，Master节点更新后根据配置自动同步到Slave节点。\n过程   全量复制\nRedis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下：\n　1）从服务器连接主服务器，发送SYNC命令；\n　2）主服务器接收到SYNC命令后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令；\n　3）主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令；\n　4）从服务器收到快照文件后丢弃所有旧数据，载入收到的快照；\n　5）主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令；\n　6）从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；\n  增量复制\nRedis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。\n增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。\n  配置 REPLICATION\n  replicaof ：添加Master节点的ip和端口。\n  slave-serve-stale-data：默认值为yes。当一个 slave 与 master 失去联系，或者复制正在进行的时候，slave 可能会有两种表现：\n 如果为 yes ，slave 仍然会应答客户端请求，但返回的数据可能是过时，或者数据可能是空的在第一次同步的时候 如果为 no ，在你执行除了 info he salveof 之外的其他命令时，slave 都将返回一个 \u0026ldquo;SYNC with master in progress\u0026rdquo; 的错误    slave-read-only：配置Redis的Slave实例是否接受写操作，即Slave是否为只读Redis。默认值为yes。\n  除此之外，还需配置端口port、pid文件pidfile、log文件logfile、持久化文件路径dir等选项。\n例子 主节点6379配置\n1port 6379 2daemonize yes 3pidfile /var/run/redis_6379.pid 4logfile \u0026#34;6379.log\u0026#34; 5dir ./ 从节点6380配置\n1port 6380 2daemonize yes 3pidfile /var/run/redis_6380.pid 4logfile \u0026#34;6380.log\u0026#34; 5dir ./ 6replicaof 127.0.0.1 6379 从节点6381配置\n1port 6381 2daemonize yes 3pidfile /var/run/redis_6381.pid 4logfile \u0026#34;6381.log\u0026#34; 5dir ./ 6replicaof 127.0.0.1 6379 分别启动\n1redis-server /usr/local/redis/master6379/redis.conf 2redis-server /usr/local/redis/slave6380/redis.conf 3redis-server /usr/local/redis/slave6381/redis.conf 查看节点状态\n一些测试(就不截图了)\n 增量复制：主从节点启动后，主节点写，看从节点是否同步 全量复制：主节点先写入一些数据，启动从节点看是否同步 从节点只读 主节点宕机：主节点宕机后从节点角色还是slave，主节点恢复后还是master； ","date":"2021-10-11","permalink":"https://why9661.github.io/myblog/posts/redis/%E4%B8%BB%E4%BB%8E%E6%A8%A1%E5%BC%8F/","series":null,"tags":["Redis"],"title":"Redis-主从模式"},{"categories":["Golang"],"content":"1type ArbitraryType int 2type Pointer *ArbitraryType Sizeof、Alignof、Offsetof   unsafe.Sizeof\n1func Sizeof(x ArbitraryType) uintptr Sizeof函数返回操作数在内存中的字节大小。\nSizeof函数返回的大小只包括数据结构中固定的部分，例如字符串对应运行时结构体中的指针和字符串长度部分，但是并不包含指针指向的字符串的内容。\n1var s1 string 2var s2 []int 3fmt.Println(unsafe.Sizeof(s1)) //16 4fmt.Println(unsafe.Sizeof(s2)) //24   unsafe.Alignof\n1func Alignof(x ArbitraryType) uintptr unsafe.Alignof 函数返回对应参数的类型需要对齐的长度。\n内存对齐\n内存对齐就是将不同类型的数据安排到合适的地址，占用合适的长度。\nCPU从内存读取数据，需要通过地址总线将地址传递给内存，内存准备好数据后通过数据总线传递给CPU。\n如果地址总线为8根，那么地址就只有8位，最大寻址空间256B；如果地址总线位32根，那么地址就有32位，最大寻址空间4G\u0026hellip;\n如果数据总线为8根，那么每次能操作1B数据；如果数据总线为32根，那么每次能操作4B数据\u0026hellip;\n每次能够操作的字节数就是机器字长。\nx32的机器字长=4B=平台最大对齐边界\nx64的机器字长=8B=平台最大对齐边界\n数据类型的对齐边界(对齐值)=min(类型大小，平台最大对齐边界)\n  unsafe.Offsetof\n1func Offsetof(x ArbitraryType) uintptr Offsetof函数的入参必须是一个结构体字段 x.f, 然后返回 f 字段相对于 x 起始地址的偏移量, 包括可能的“空洞”。\n  *T、unsafe.Pointer、uintptr   *T\n普通类型的指针类型，用于传递地址，不能进行指针运算。\n  unsafe.Pointer\n通用指针类型，用于转换不同类型的指针，不能进行指针运算，不能通过解引用读取内存存储的值（需要转换为某种普通指针）。\n  uintptr\n可用于指针运算。\n  示例 []byte和string类型的转换 1func byteToString(b []byte) string { 2\theader := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;b)) 3 4\tnewHeader := reflect.StringHeader{ 5\tData: header.Data, 6\tLen: header.Len, 7\t} 8 9\treturn *(*string)(unsafe.Pointer(\u0026amp;newHeader)) 10} 11 12func stringToByte(s string) []byte { 13\theader := (*reflect.StringHeader)(unsafe.Pointer(\u0026amp;s)) 14 15\tnewHeader := reflect.SliceHeader{ 16\tData: header.Data, 17\tLen: header.Len, 18\tCap: header.Len, 19\t} 20 21\treturn *(*[]byte)(unsafe.Pointer(\u0026amp;newHeader)) 22} 23 24func main() { 25\tb1 := []byte{65, 66, 67} 26\ts1 := byteToString(b1) 27\tfmt.Println(s1) // ABC 28 29\ts2 := \u0026#34;ABC\u0026#34; 30\tb2 := stringToByte(s2) 31\tfmt.Println(b2) //[65 66 67] 32} 修改结构体字段 1type S struct { 2\ta bool 3\tb int16 4\tc []int 5} 6 7func main() { 8\tvar s S 9\tsb := (*int16)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;s)) + unsafe.Offsetof(s.b))) 10\t*sb = 100 11\tfmt.Println(s.b) 12} ","date":"2021-10-02","permalink":"https://why9661.github.io/myblog/posts/golang/unsafe%E5%8C%85/","series":null,"tags":["Golang"],"title":"Golang-Unsafe包"},{"categories":["MySQL"],"content":"原理   MySQL主库在事务提交时会把数据变更作为事件记录在二进制日志binlog中；\n  主库推送二进制日志文件binlog中的事件到从库的中继日志Relay Log中，之后从库根据中继日志重做数据变更操作，通过逻辑复制来达到主库和从库的数据一致性；\n  MySql通过三个线程来完成主从库间的数据复制，其中Binlog Dump线程跑在主库上，I/O线程和SQL线程跑在从库上；\n  当在从库上启动复制时，首先创建I/O线程连接主库，主库随后创建Binlog Dump线程读取数据库事件并发送给I/O线程，I/O线程获取到事件数据后更新到从库的中继日志Relay Log中去，之后从库上的SQL线程读取中继日志Relay Log中更新的数据库事件并应用。\n  实践 ​\t本次实践docker容器使用bridge网络模式。\n  使用docker启动一个mysql主实例\n1docker run -p 3307:3306 --name mysql-master \\ 2-v /mydata/mysql-master/log:/var/log/mysql \\ 3-v /mydata/mysql-master/data:/var/lib/mysql \\ 4-v /mydata/mysql-master/conf:/etc/mysql \\ 5-v /mydata/mysql-master/mysql-files:/var/lib/mysql-files \\ （当指定了外部配置文件与外部存储路径时，也需要指定 /var/lib/mysql-files的外部目录） 6 7-e MYSQL_ROOT_PASSWORD=123456 \\ 8-d mysql   修改配置文件\n在/mydata/mysql-master/conf目录下新建my.cnf，并作如下配置\n1 [mysqld] 2 ## 设置server_id，同一局域网中需要唯一 3 server_id=101 4## 指定不需要同步的数据库名称 5binlog-ignore-db=mysql 6## 开启二进制日志功能 7log-bin=mall-mysql-bin 8## 设置二进制日志使用内存大小（事务） 9binlog_cache_size=1M 10## 设置使用的二进制日志格式（mixed,statement,row） 11binlog_format=mixed 12## 二进制日志过期清理时间。默认值为0，表示不自动清理。 13expire_logs_days=7 14## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。 15## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致 16slave_skip_errors=1062   修改完后重启实例\ndocker restart mysql-master\n  进入容器，进入MySQL，创建数据同步用户\ndocker exec -it mysql-master /bin/bash\n1CREATEUSER\u0026#39;slave\u0026#39;@\u0026#39;%\u0026#39;IDENTIFIEDBY\u0026#39;123456\u0026#39;;2GRANTREPLICATIONSLAVE,REPLICATIONCLIENTON*.*TO\u0026#39;slave\u0026#39;@\u0026#39;%\u0026#39;;3-- mysql 8.0 默认使用 caching_sha2_password 身份验证机制 4-- 从原来的 mysql_native_password 更改为 caching_sha2_password，现在改回来 5ALTERUSER\u0026#39;slave\u0026#39;@\u0026#39;%\u0026#39;IDENTIFIEDWITHmysql_native_passwordBY\u0026#39;123456\u0026#39;;  使用docker启动一个mysql从实例\n1docker run -p 3308:3306 --name mysql-slave \\ 2-v /mydata/mysql-slave/log:/var/log/mysql \\ 3-v /mydata/mysql-slave/data:/var/lib/mysql \\ 4-v /mydata/mysql-slave/conf:/etc/mysql \\ 5 6-v /mydata/mysql-slave/mysql-files:/var/lib/mysql-files \\ （当指定了外部配置文件与外部存储路径时，也需要指定 /var/lib/mysql-files的外部目录） 7 8-e MYSQL_ROOT_PASSWORD=123456 \\ 9-d mysql   修改配置文件\n在/mydata/mysql-slave/conf目录下新建my.cnf，并作如下配置\n1[mysqld] 2## 设置server_id，同一局域网中需要唯一 3server_id=102 4## 指定不需要同步的数据库名称 5binlog-ignore-db=mysql 6## 开启二进制日志功能，以备Slave作为其它数据库实例的Master时使用 7log-bin=mall-mysql-slave1-bin 8## 设置二进制日志使用内存大小（事务） 9binlog_cache_size=1M 10## 设置使用的二进制日志格式（mixed,statement,row） 11binlog_format=mixed 12## 二进制日志过期清理时间。默认值为0，表示不自动清理。 13expire_logs_days=7 14## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。 15## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致 16slave_skip_errors=1062 17## relay_log配置中继日志 18relay_log=mall-mysql-relay-bin 19## log_slave_updates表示slave将复制事件写进自己的二进制日志 20log_slave_updates=1 21## slave设置为只读（具有super权限的用户除外） 22read_only=1   修改完后重启实例\ndocker restart mysql-slave\n    连接到主数据库\nshow master status;\n  连接到从数据库\n1changemastertomaster_host=\u0026#39;172.17.0.1\u0026#39;,master_user=\u0026#39;slave\u0026#39;,master_password=\u0026#39;123456\u0026#39;,master_port=3307,master_log_file=\u0026#39;mall-mysql-bin.000001\u0026#39;,master_log_pos=713,master_connect_retry=30;master_host：主数据库的IP地址；\nmaster_port：主数据库的运行端口；\nmaster_user：在主数据库创建的用于同步数据的用户账号；\nmaster_password：在主数据库创建的用于同步数据的用户密码；\nmaster_log_file：指定从数据库要复制数据的日志文件，通过查看主数据的状态，获取File参数；\nmaster_log_pos：指定从数据库从哪个位置开始复制数据，通过查看主数据的状态，获取Position参数；\nmaster_connect_retry：连接失败重试的时间间隔，单位为秒。\n  ​\tstart slave开始同步\n​\tshow slave status \\G查看同步状态\n","date":"2021-10-02","permalink":"https://why9661.github.io/myblog/posts/mysql/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","series":null,"tags":["MySQL"],"title":"MySQL-主从复制"},{"categories":["MySQL"],"content":"日志系统 redo log redo log是InnoDB引擎特有的日志。主要用于服务器异常宕机后快速恢复。\n当MySQL执行一条SQL更新语句时，InnoDB引擎会先把改动记录写到redo log里面并更新内存，这样更新就算完成了（此时内存和磁盘上的数据是不一致的），之后InnoDB会在适当的时候，将这些更改记录更新到磁盘里面。这种”先写日志，再写磁盘“的方式就是MySQL中的WAL技术（Write-Ahead Logging）。\nredo log的大小是固定的，采用循环写的方式记录，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，从头开始写，写到末尾时就又回到开头循环写。\n![redo log](C:\\Users\\hy_wo\\Desktop\\截图\\redo log.jpg)\nwrite pos表示日志当前记录的位置，当ib_logfile_3写满后，会从ib_logfile_0从头开始记录。\ncheck point表示当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到磁盘文件。\nwrite pos和check point之间的部分就是redo log空余的部分，用于记录新的改动更新。\n当write pos追上check point时，这个时候需要先擦除落盘一些记录，把check point推进一下。\n有了 redo log，当数据库发生宕机重启后，InnoDB就可以保证已提交的记录都不会丢失（check point后的数据），这种能力称为crash-safe。\n相关参数\n  innodb_flush_log_at_trx_commit\n0：每秒写一次日志并将其刷新到磁盘。\n1：事务commit时，必须将rodolog-buffer中的数据刷新进磁盘中（建议）\n2：事务commit时，将redolog-buffer中的数据刷新进OS Cache中，然后依托于操作系统每秒刷新一次的机制将数据同步到磁盘中，也存在丢失的风险。\n  binlog 相较于redo log是InnoDB引擎特有的日志，binlog则是MySQL数据库Server层的日志，即所有引擎都可使用。主要用于主从复制和备份。\nbinlog是追加写入的，当一个binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\nbinlog日志有3种模式，STATMENT、ROW、MIXED。\n STATMENT：记录每一条会修改数据的SQL语句 ROW：记录行的内容（两条，更新前和更新后） MIXED：MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择一种。  相关参数\n  sync_binlog\n1：表示每次事务的binlog都持久化到磁盘（建议）。\n  两阶段提交 深色表示执行器执行，浅色表示存储引擎内部执行。\nupdate T set c=c+1 where id=2；\n简而言之，两阶段提交的过程：\n①redo log写，进入prepare阶段\n②写binlog\n③进入commit阶段\n在②之前崩溃，重启恢复时发现没有commit，也没有binlog，回滚；\n在③之前崩溃，重启恢复时虽没有commit，但binlog完整，所以自动commit；\nbinlog和redo log有一个共同的数据字段XID。崩溃恢复的时候,会按照顺序扫描redo log。 如果碰到既有prepare、又有commit的redo log,就直接提交； 如果碰到只有prepare、而没有commit的redo log,就拿着XID去binlog找对应的事务；\nundo log undo log主要有两个作用：回滚和MVCC。\n在MySQL中，每条记录在更新的时候会同时记录一条回滚操作，记录上的最新值可以通过回滚操作得到前一个状态的值。当没有事务再需要用到这些回滚日志时（系统里没有比这个回滚日志更早的视图），回滚日志会被删除。\n参考：\n《MySQL实战45讲》\n","date":"2021-09-10","permalink":"https://why9661.github.io/myblog/posts/mysql/%E6%97%A5%E5%BF%97/","series":null,"tags":["MySQL"],"title":"MySQL-日志"},{"categories":["Golang"],"content":"GPM简介 G表示Goroutine，是Go语言调度的基本单位，可以认为是一种用户态的线程，与普通线程相比，Goroutine上下文切换在用户态可以减少开销，同时Goroutine本身是KB级别，而普通线程是MB级别。\nP表示处理器，可以认为是运行在线程上的本地调度器。P的数量由环境变量GOMAXPROCS决定，在程序初始化时创建。\nM表示操作系统线程，由操作系统的调度器调度和管理。最多可以创建10000个线程，但是同时只能有最多GOMAXPROCS个活跃线程能够正常运行。在大多数情况下，我们都会使用 Go 的默认设置，也就是线程数等于 CPU 数，默认的设置不会频繁触发操作系统的线程调度和上下文切换，所有的调度都会发生在用户态，由 Go 语言调度器触发，能够减少很多额外开销。\ng0是一个特殊的Goroutine，会深度参与到运行时的调度，包括 Goroutine 的创建、大内存分配和 CGO 函数的执行。\nm0是主线程对应的M，调度器初始化时时m0会与allp[0]绑定，程序一开始m0上执行的就是g0。\nG的状态\n   状态 描述     _Gidle 刚刚被分配并且还没有被初始化   _Grunnable 没有执行代码，没有栈的所有权，存储在运行队列中   _Grunning 可以执行代码，拥有栈的所有权，被赋予了内核线程 M 和处理器 P   _Gsyscall 正在执行系统调用，拥有栈的所有权，没有执行用户代码，被赋予了内核线程 M 但是不在运行队列上   _Gwaiting 由于运行时而被阻塞，没有执行用户代码并且不在运行队列上，但是可能存在于 Channel 的等待队列上   _Gdead 没有被使用，没有执行代码，可能有分配的栈   _Gcopystack 栈正在被拷贝，没有执行代码，不在运行队列上   _Gpreempted 由于抢占而被阻塞，没有执行用户代码并且不在运行队列上，等待唤醒   _Gscan GC 正在扫描栈空间，没有执行代码，可以与其他状态同时存在    M的状态\n运行中、自旋、休眠。\nP的状态\n   状态 描述     _Pidle 处理器没有运行用户代码或者调度器，被空闲队列或者改变其状态的结构持有，运行队列为空   _Prunning 被线程 M 持有，并且正在执行用户代码或者调度器   _Psyscall 没有执行用户代码，当前线程陷入系统调用   _Pgcstop 被线程 M 持有，当前处理器由于垃圾回收被停止   _Pdead 当前处理器已经不被使用    程序初始化 在程序初始化过程中，会进行调度器初始化，此时会根据GOMAXPROCS这个环境变量决定创建多少个P，并将m0和allp[0]关联起来。此后会创建main goroutine，然后开启调度循环。当main goroutine被调度执行时，会以runtime.main作为执行入口，执行创建监控线程(sysmon)、包初始化(init)等工作，然后会调用用户编写的main.main。\nGoroutine创建 初始化结构体 启动一个新的Goroutine需要使用go关键字，编译器会将go关键字转化为newproc函数调用。newproc函数首先会调用newproc1函数获取Goroutine结构体，在newproc1函数中：\n1、从当前G所在p的gFree列表或者调度器sched的gFree列表获取runtime.g:\n​\t①当P的gFree列表为空时，会将调度器持有的空闲Goroutine转移到当前P上，直到gFree 列表中的 Goroutine 数量达到 32；\n​ ②当P的Gorontine数量充足时，会从列表头部返回一个新的Goroutine。\n2、当调度器的gFree和处理器的gFree列表都不存在结构体时，会调用runtime.malg创建一个新的runtime.g分配2KB的栈空间，并追加到全局的G列表allgs中，此时这个Goroutine的状态是_Gdead。\n3、newproc1会将Goroutine置为_Grunnable状态并赋goid。\n运行队列 newproc会调用runtime.runqput将G放到运行队列中。G会优先加入到P的本地队列，如果P的本地队列已满，会将本地队列中前一半的G和新创建的G打乱顺序添加到全局队列中。如果此时系统中有空闲的P并且没有自旋状态的M，那么会启动一个M并置为spinning状态与空闲的P关联开始调度循环寻找G执行。\nP的本地运行队列是一个使用数组构成的环形链表，最多可以存储256个待执行任务。\n正常调度循环 函数runtime.schedule负责调度的逻辑：\n1、当全局运行队列中有待执行的G时，有较小的概率会从全局队列中获取G\n2、从p的本地队列获取G\n3、如果1、2都没有获取到G，那么会通过runtime.findrunnable寻找G，直到获取到待运行的G才会返回：\n​\t①从本地队列获取\n​\t②从全局队列获取\n​ ③从网络轮询器中查找是否有G等待运行（IO事件就绪）\n​ ④从其它P的本地队列中窃取一半的G\n获取到G后开始执行，当G中的函数返回时会执行runtime.goexit，最终会在当前m的g0栈上执行goexit0函数，该函数会将G转换为_Gdead状态、清理其中的字段、移除G和线程的关联并调用runtime.gfput重新加入P的gFree列表。在最后runtime.goexit0会重新调用runtime.schedule触发新一轮的调度。\n触发调度时机   协程创建/结束时\n新的协程创建时可能会触发调度循环(当系统中有空闲P时)。\n协程执行结束时，goexit0会触发调度。\n   抢占    主动挂起\n如time.Sleep、channel阻塞，这些操作最终调用gopark函数将Goroutine从_Grunning切换至_Gwaiting，移除当前线程和G的关联，并触发一次新的调度循环。\n当Goroutine等待的特定条件满足后，将Goroutine唤醒并将准备就绪的Goroutine切换至_Grunnable，加入运行队列等待调度。\n  系统调用\n文件IO、网络IO。在陷入系统调用之前，当前M会与当前P分离(变为_Psyscall状态)，监控线程发现这个P在一定时间没有执行时，会重新启动一个M与之关联，从而发生新的调度循环。\n当M从系统调用中恢复时，会先检测之前绑定的P是否被占用，如果没有被占用，那么就获取这个P继续使用，否则会去P的空闲队列中申请一个，如果没有申请到的话，那么会把G放到全局队列中，M休眠。\n    GC\nSTW之后，会重新选择G开始执行。\n  抢占   基于协作的抢占式调度\n这种基于协作的抢占式调度在Go1.2引入，监控线程sysmon会对运行时间过长P（G运行时间超过10ms）执行抢占操作，而这个抢占操作与栈增长有关。\n  Go编译器会在调用函数前在函数头部插入runtime.morestack；\n  Go 语言运行时会在垃圾回收暂停程序、系统监控发现 Goroutine 运行超过 10ms 时发出抢占请求，通过栈增长的相关代码将Goroutine的stackguard0字段设置为StackPreempt；\n  当发生函数调用时，可能会执行编译器插入的runtime.morestack，它调用的runtime.newstack会检查 Goroutine 的stackguard0字段是否为StackPreempt；如果stackguard0是StackPreempt就会触发协程调度从而使Goroutine让出当前线程实现抢占；\n  这种抢占方式依赖栈增长代码。如果有一个空的for{}，与栈增长无关，那么上面的逻辑就无法得到执行，程序最终会卡死。\n  基于信号的抢占式调度\n基于信号的抢占式调度在Go1.14中引入。\n未完待续\u0026hellip;\n ","date":"2021-09-08","permalink":"https://why9661.github.io/myblog/posts/golang/gpm%E8%B0%83%E5%BA%A6/","series":null,"tags":["Golang"],"title":"Golang-GPM调度"},{"categories":["Golang"],"content":"Go标准库提供了几个常用的Handler：NotFoundHandler、RedirectHandler、StripPrefix、TimeoutHandler、FileServer。\nhttp.NotFoundHandler\n1func NotFound(w ResponseWriter, r *Request) { Error(w, \u0026#34;404 page not found\u0026#34;, StatusNotFound) 2func NotFoundHandler() Handler { return HandlerFunc(NotFound) } NotFoundHandler非常简单，直接返回“404 page not found”以及状态码404。\neg:\n1http.Handle(\u0026#34;/a\u0026#34;, http.NotFoundHandler()) //访问localhost:8080/a 404 2http.Handle(\u0026#34;/b\u0026#34;, http.NotFoundHandler()) //访问localhost:8080/b 404 3http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) http.RedirectHandler\n1func RedirectHandler(url string, code int) Handler {...} RedirectHandler会返回一个Handler，这个Handler会将请求重定向到指定的url，并响应指定的状态码(3XX)。\neg:\n1http.HandleFunc(\u0026#34;/hello\u0026#34;, func(w http.ResponseWriter, r *http.Request) { 2\tw.Write([]byte(\u0026#34;Hello\u0026#34;)) 3}) 4http.Handle(\u0026#34;/\u0026#34;, http.RedirectHandler(\u0026#34;http://localhost:8080/hello\u0026#34;,http.StatusMovedPermanently)) 5http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) 访问localhost:8080/会跳转到localhost:8080/hello并响应301。\nhttp.StripPrefix\n1func StripPrefix(prefix string, h Handler) Handler {...} StripPrefix会将请求路径中的prefix移除掉，再交由传入的Handler处理，如果请求路径中不包含prefix，那么会返回404。\neg:\n1type helloHandler struct{} 2 3func (h *helloHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { 4\tw.Write([]byte(r.URL.Path)) 5} 6 7func main() { 8\th := helloHandler{} 9\thttp.Handle(\u0026#34;/prefix/hello\u0026#34;, http.StripPrefix(\u0026#34;/prefix\u0026#34;, \u0026amp;h)) 10\thttp.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) 11} 访问localhost:8080/prefix/hello，会显示/hello，即把原请求路径中的“/prefix”移除掉再交给传入的Handler执行。\nhttp.TimeoutHandler\n1func TimeoutHandler(h Handler, dt time.Duration, msg string) Handler {...} TimeoutHandler会返回一个Handler，用来在指定时间dt内执行传入的Handler，如果超时会将msg返回并相应503。\neg:\n1type helloHandler struct{} 2 3func (h *helloHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { 4\ttime.Sleep(2 * time.Second) 5\tw.Write([]byte(\u0026#34;Hello\u0026#34;)) 6} 7 8func main() { 9\th := helloHandler{} 10\thttp.Handle(\u0026#34;/hello\u0026#34;, http.TimeoutHandler(\u0026amp;h, time.Second, \u0026#34;Timeout!\u0026#34;)) 11\thttp.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) 12} 访问localhost:8080/hello，返回Timeout!并响应503。\nhttp.FileServer\n1func FileServer(root FileSystem) Handler {...} 2type FileSystem interface { 3\tOpen(name string) (File, error) 4} 5type Dir string //实现了FileSystem接口 FileServer返回一个Handler，使用基于root的文件系统来处理请求。\nFileSystem是一个接口，而http.Dir实现了这个接口\neg:\n文件目录如下\n1--front 2\tindex.html 3--main.go 1func main() { 2\thttp.ListenAndServe(\u0026#34;:8080\u0026#34;, http.FileServer(http.Dir(\u0026#34;front\u0026#34;))) 3} 访问localhost:8080/index.html，会定位到front目录下的index.html。\n","date":"2021-09-01","permalink":"https://why9661.github.io/myblog/posts/golang/%E5%86%85%E7%BD%AEhandler/","series":null,"tags":["Golang"],"title":"Golang-内置Handler"},{"categories":["Golang"],"content":"简介 Go的自动垃圾回收采用标记清扫算法，支持主体并发增量式回收，使用插入删除两种写屏障结合的混合写屏障。\n标记-清扫算法 标记清扫算法是最常见的垃圾收集算法，标记清扫收集器是跟踪式垃圾收集器，其执行过程可以分成标记和清扫两个阶段：\n  标记阶段 — 从根对象(栈、数据段上的对象)出发追踪并标记堆中所有存活的对象；\n  清扫阶段 — 遍历堆中的全部对象，回收未被标记的垃圾对象并将回收的内存加入空闲链表；\n  三色抽象 垃圾回收开始时所有数据都为白色，然后将根节点标记为灰色，灰色表示基于当前节点展开的追踪还未完成，当基于某个节点的追踪完成后将其标记为黑色，表示它是存活数据也不需要基于该节点再次进行追踪。当没有灰色节点时代表标记工作结束，存活对象都为黑色，垃圾对象都为白色。\nSTW\nSTW(Stop The World)即暂停用户程序只专注于垃圾回收。\n长时间STW进行垃圾回收是不合理的，所以通常是使用增量式垃圾回收。在增量式垃圾回收中，可能出现之前STW时标记为黑色的对象由于后面用户程序中的修改，到下一次STW标记时出现了黑色对象到白色对象的引用，同时又没有灰色对象指向这个白色对象，那么这个白色对象就会被误判为垃圾。\n强三色不变式：禁止出现黑色对象到白色对象的引用。\n弱三色不变式：存在黑色对象到白色对象的引用，但必须有灰色对象到该白色对象的引用。\n实现强弱三色不变式的通常做法是建立读写屏障。\n读写屏障 内存屏障技术是一种屏障指令，它可以让 CPU 或者编译器在执行内存相关操作时遵循特定的约束，目前多数的现代处理器都会乱序执行指令以最大化性能，但是该技术能够保证内存操作的顺序性，在内存屏障前执行的操作一定会先于内存屏障后执行的操作。\n垃圾收集中的屏障技术更像是一个钩子方法，它是在用户程序读取对象、创建新对象以及更新对象指针时执行的一段代码，根据操作类型的不同，我们可以将它们分成读屏障（Read barrier）和写屏障（Write barrier）两种，因为读屏障需要在读操作中加入代码片段，对用户程序的性能影响很大，所以编程语言往往都会采用写屏障保证三色不变性。\n插入写屏障：插入写屏障保证不会出现黑色到白色对象的引用，因此出现黑色对象到白色对象的引用时，可以将黑色对象退回为灰色，或者将白色对象变为灰色。\n删除写屏障：删除写屏障针对的是到白色对象的路径被破坏的行为，如一个灰色对象到白色对象的引用被删除，那么将这个白色对象变为灰色。\n增量和并发 增量式垃圾回收：用户程序和垃圾回收程序交替执行。增量式垃圾回收可以减少每次STW的时间，但会增加一次完整GC的总时间。\n并发垃圾回收：利用多核资源，使用户程序和垃圾回收并行执行。并发垃圾回收不仅能够减少每一次STW的时间，也能减少整个一次GC的时间。\n触发时机 手动触发\nruntime.GC()\n分配内存\n1、分配大对象时（\u0026gt;32KB）一定会尝试触发GC\n2、创建微对象、小对象需要从中心缓存或页堆中获取时，可能会触发\n超过特定时间\n在程序初始化时，会创建一个用于强制执行GC的协程（创建后进入休眠）。监控线程检测到距离上次GC超过指定时间时，会将这个协程添加到全局队列中，等到它调度执行时就会开启GC\n","date":"2021-08-30","permalink":"https://why9661.github.io/myblog/posts/golang/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","series":null,"tags":["Golang"],"title":"Golang-GC"},{"categories":["Redis"],"content":"RDB RDB做全量持久化，把数据以快照的形式保存在磁盘上，恢复时是将快照文件直接读到内存里。\nRDB保存的文件默认为dump.rdb。\n配置 SNAPSHOTTING\n 用来配置触发 Redis的持久化条件，也就是什么时候将内存中的数据保存到硬盘,如果只是用Redis的缓存功能，不需要持久化，那么可以注释掉所有的 save 行来停用保存功能。默认如下配置：  1save 900 1：表示900 秒内如果至少有 1 个 key 的值变化，则保存 2save 300 10：表示300 秒内如果至少有 10 个 key 的值变化，则保存 3save 60 10000：表示60 秒内如果至少有 10000 个 key 的值变化，则保存   stop-writes-on-bgsave-error ：最新的一次后台存储如果失败了,那么Redis是否停止接收新的写入。\n  rdbcompression ；默认值是yes。对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能，但是存储在磁盘上的快照会比较大。\n  rdbchecksum ：默认值是yes。在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。\n  dbfilename ：设置快照的文件名，默认是 dump.rdb。\n  dir：设置快照文件的存放路径(目录名)。\n  过程 Redis 使用操作系统的多进程 cow(Copy On Write) 机制来实现RDB快照持久化\n 执行bgsave命令的时候，Redis主进程会检查是否有子进程在执行RDB/AOF持久化任务，如果有的话，直接返回。 Redis主进程会fork一个子进程来执行执行RDB操作，fork操作会对主进程造成阻塞（影响Redis的读写），fork操作完成后会发消息给主进程，从而不再阻塞主进程。（阻塞仅指主进程fork子进程的过程，后续子进程执行操作时不会阻塞）。 RDB子进程会根据Redis主进程的内存生成临时的快照文件，持久化完成后会使用临时快照文件替换掉原来的RDB文件。（该过程中主进程的读写不受影响，但Redis的写操作不会同步到主进程的主内存中，而是会写到一个临时的内存区域作为一个副本）。 子进程完成RDB持久化后会发消息给主进程，通知RDB持久化完成（将上阶段内存副本中的增量写数据同步到主内存）。  触发   手动触发\nsave命令\n同步，在主线程中保存快照；阻塞当前Redis服务器，直到RDB过程完成为止，对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用。\nbgsave命令\n异步，Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短；BGSAVE命令是针对SAVE堵塞问题做的优化。因此Redis内部所有的设计RDB的操作都采用BGSAVE的方式，而save命令已经废弃。\n  自动触发\n根据配置文件的策略自动触发bgsave。\n  其它触发\n 如果从节点执行全量复制操作，主节点收到从结点的SYNC命令后自动执行BGSAVE生成RDB文件并发送给从节点。 默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则自动执行BGSAVE。    优缺点   优点\n适合定时备份和灾难恢复,在恢复大数据集的时候比AOF的速度快。\n  缺点\n会丢失数据。\n  AOF 全量备份总是耗时的，AOF是一种更高效的方式，与RDB持久化通过保存数据库中的键值对来记录数据库状态不同，AOF持久化是增量持久化，通过保存Redis所执行的写命令来记录数据库状态的。redis会将每一个收到的写命令都通过write函数追加到文件中(默认文件appendonly.aof)。\n配置 APPEND ONLY MODE\n appendonly yes: 是否启用aof持久化方式。 appendfsync always: 每次收到写命令就立即强制写入磁盘，最慢的，但是保证完全的持久化，不推荐使用。 appendfsync everysec: 每秒钟强制写入磁盘一次，在性能和持久化方面做了很好的折中，推荐。 appendfsync no: 完全依赖os，性能最好,持久化没保证。 auto-aof-rewrite-percentage 100: 默认值为100。aof自动重写配置，当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，即当aof文件增长到一定大小的时候，Redis能够调用bgrewriteaof对日志文件进行重写。当前AOF文件大小是上次日志重写得到AOF文件大小的一倍（设置为100）时，自动启动新的日志重写过程。 auto-aof-rewrite-min-size 64mb: 设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写。  重写 由于AOF持久化是Redis不断将写命令记录到 AOF 文件中，随着Redis不断的进行，AOF 的文件会越来越大，文件越大，占用服务器内存越大以及 AOF 恢复要求时间越长。为了解决这个问题，Redis新增了重写机制，当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。\n重写过程可手动触发（redis-cli -h ip -p port bgrewriteaof）或自动触发（配置文件）。\n过程如下：\n①redis调用fork创建子进程，现在有父子两个进程\n②子进程根据内存中的数据库快照，往临时文件中写入重建数据库状态的命令\n③父进程继续处理client请求，除了把写命令写入到原来的aof文件中。同时把收到的写命令缓存起来。这样就能保证如果子进程重写失败的话并不会出问题。\n④当子进程把快照内容写入已命令方式写到临时文件中后，子进程发信号通知父进程。然后父进程把缓存的写命令也写入到临时文件。\n⑤现在父进程可以使用临时文件替换老的aof文件，并重命名，后面收到的写命令也开始往新的aof文件中追加。\n需要注意重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件。\n优缺点   优点\n保证数据完整性更好。\n  缺点\n数据文件通常比RDB大,性能不如RDB。\n  混合持久化 当开启混合持久化时，主进程先fork出子进程将现有内存副本全量以RDB方式写入aof文件中，然后将缓冲区中的增量命令以AOF方式写入aof文件中，写入完成后通知主进程更新相关信息，并将新的含有 RDB和AOF两种格式的aof文件替换旧的aof文件。\n简单来说：混合持久化方式产生的文件一部分是RDB格式，一部分是AOF格式。\n配置  aof-use-rdb-preamble:yes表示开启，设置为no表示禁用。 ","date":"2021-08-28","permalink":"https://why9661.github.io/myblog/posts/redis/%E6%8C%81%E4%B9%85%E5%8C%96/","series":null,"tags":["Redis"],"title":"Redis-持久化"},{"categories":["redis"],"content":"哨兵模式 在Redis的主从模式下，一旦主节点由于故障不能提供服务（单点故障），需要人工将从节点晋升为主节点，在这段时间内，Redis不能提供正常服务。\nRedis Sentinel是一个分布式架构，其中包含若干个Sentinel节点和Redis数据节点，每个Sentinel节点会对数据节点和其余Sentinel节点进行监控，当它发现节点不可达时，会对节点做下线标识。如果被标识的是主节点，它还会和其他Sentinel节点进行“协商”，当大多数Sentinel节点都认为主节点不可达时，它们会选举出一个Sentinel节点来完成自动故障转移的工作，如将一个从节点晋升为主节点，同时会将这个变化通知给Redis应用方。整个过程完全是自动的，不需要人工来介入，所以哨兵模式能效地解决Redis的高可用问题。\n过程 三个定时监控任务\n1）每隔10秒，每个Sentinel节点会向主节点和从节点发送info命令获取最新的拓扑结构（确定master和主从关系）。\n2）每隔2秒，每个Sentinel节点会向Redis数据节点的__sentinel__:hello频道上发送该Sentinel节点对于主节点的判断以及当前Sentinel节点的信息，同时每个Sentinel节点也会订阅该频道，来了解其他Sentinel节点以及它们对主节点的判断。\n3）每隔1秒，每个Sentinel节点会向主节点、从节点、其余Sentinel节点发送一条ping命令做一次心跳检测，来确认这些节点当前是否可达。\n主观下线 因为每隔一秒，每个Sentinel节点会向主节点、从节点、其余Sentinel节点发送一条ping命令做一次心跳检测，当这些节点超过down-after-milliseconds没有进行有效回复，Sentinel节点就会对该节点做失败判定，这个行为叫做主观下线。\n客观下线 当Sentinel主观下线的节点是主节点时，该Sentinel节点会向其他Sentinel节点询问对主节点的判断，当超过quorum个数，那么意味着大部分的Sentinel节点都对这个主节点的下线做了同意的判定，于是该Sentinel节点认为主节点确实有问题，这时该Sentinel节点会做出客观下线的决定。\n领导者Sentinel节点选举 Raft算法。\n故障转移 1）领导者Sentinel节点在从节点列表中选出一个节点作为新的主节点\n2）上一步的选取规则是与主节点复制相似度最高的从节点\n3）领导者Sentinel节点让剩余的从节点成为新的主节点的从节点\n4）Sentinel节点集合会将原来的主节点更新为从节点，并保持着对其关注，当其恢复后命令它去复制新的主节点\n配置 sentinel.conf\n哨兵节点1配置\n1port 26379 2daemonize yes 3pidfile /var/run/redis-sentinel_26379.pid 4logfile \u0026#34;26379.log\u0026#34; 5sentinel monitor mymaster 127.0.0.1 6379 2 哨兵节点2配置\n1port 26380 2daemonize yes 3pidfile /var/run/redis-sentinel_26380.pid 4logfile \u0026#34;26380.log\u0026#34; 5sentinel monitor mymaster 127.0.0.1 6379 2 哨兵节点3配置\n1port 26381 2daemonize yes 3pidfile /var/run/redis-sentinel_26381.pid 4logfile \u0026#34;26381.log\u0026#34; 5sentinel monitor mymaster 127.0.0.1 6379 2 哨兵节点启动\n1redis-sentinel sentinel26379.conf 2redis-sentinel sentinel26380.conf 3redis-sentinel sentinel26381.conf 查看节点状态\n测试\n将6379主节点shutdown，发现6380从节点变为master\n6379节点重新启动后，变为slave\n","date":"2021-08-12","permalink":"https://why9661.github.io/myblog/posts/redis/%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/","series":null,"tags":["redis"],"title":"Redis-哨兵模式"},{"categories":["MySQL"],"content":"锁 根据加锁的范围，MySQL里的锁大致可以分为全局锁、表级锁、行级锁三类。\n全局锁 全局锁就是对整个数据库实例加锁。主要用于对整库进行逻辑备份时。\nFlush tables with read lock（FTWRL）可以加全局读锁。当需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：DML（数据的增删改）、DDL（包括建表、修改表结构等）和更新类事务的提交语句。（unlock tables解锁）\nFTWRL\u0026amp;设置readonly\n 在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大。 在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。  表级锁 表锁一般是在数据库引擎不支持行锁的时候才会被用到。\nlock tables 表名 read/write\n与FTWRL类似，可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放，lock tables语法除了会限制别的线程的读写外也限定了本线程接下来的读写操作。\n另一类表级锁是MDL(metadata lock)。\nMDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。比如一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。 因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。\n 读锁之间不互斥，因此可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。  事务中的MDL锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。\n行锁 行锁就是针对数据表中行记录的锁。\nMyISAM不支持行锁，InnoDB支持行锁。\n两阶段锁：在InnoDB事务中，行锁在需要的时候加上，但并不是不需要了就立刻释放，而是要等到事务结束后才释放。\n   事务A 事务B     begin;update t set x=x+1 where id=1;     begin;update t set x=x+1 where id=1   commit;     如上图所示，事务B的update操作会一直阻塞，直到事务A执行完成。\n死锁和死锁检测\n当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。\n   事务A 事务B     begin;update t set x=x+1 where id=1; begin;    update t set x=x+1 where id=2;   update t set x=x+1 where id=2;     update t set x=x+1 where id=1;    如上图所示，事务A在等待事务B释放id=2的行锁，而事务B在等待事务A释放id=1的行锁，这种互相依赖对方释放资源就是进入了死锁状态。当出现死锁以后，有两种策略：\n 直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。  参考：\n《MySQL实战45讲》\n","date":"2021-08-01","permalink":"https://why9661.github.io/myblog/posts/mysql/%E9%94%81/","series":null,"tags":["MySQL"],"title":"MySQL-锁"},{"categories":["Golang"],"content":"类型元数据 不管是内置类型还是自定义类型，都有自己的类型元数据。\n每种类型元数据都是由runtime._type和其它描述信息组成（如果是自定义类型，还会通过uncommontype记录类型元数据的信息）。\n一个例子：\n前者叫做给string取别名，MyType1和string对应同一种类型元数据，像rune和int32，byte和uint8就是这种关系；后者MyType2和string对应不同的类型元数据。\n1type MyType1 = string 2type MyType2 string 3 4func main() { 5\tvar s1 MyType1 6\tvar s2 MyType2 7\tvar s3 string 8\tvar s4 string 9\ts3 = s1 10\t//s4 = s2 //wrong 11 s4 = string(s2) 12} 数据结构 接口的底层数据结构有两种runtime.iface和runtime.eface。\neface表示不包含任何方法的空接口。\niface表示包含方法的接口。\n1type eface struct { 2 _type *_type //动态类型元数据 3 data unsafe.Pointer//动态值 4} 1type iface struct { 2 tab *itab\t//动态类型元数据、接口类型元数据（包含接口要求的方法列表）等 3 data unsafe.Pointer//动态值 4} 5 6type itab struct { // 32 字节 7\tinter *interfacetype 8\t_type *_type 9\thash uint32 10\t_ [4]byte 11\tfun [1]uintptr 12} 类型断言 类型断言作用于接口值（包括空接口和非空接口）。\n而断言的类型可以是具体类型或非空接口类型。\n语法：接口值.(断言类型)\n因此类型断言可以分为以下4种情况：\n  空接口.(具体类型) A.(B)\n判断A的动态类型是否和具体类型B的类型元数据相同，相同则断言成功，否则断言失败。\n断言成功返回A的动态值，类型当然是具体类型B，ok=true\n失败会触发panic（使用两个值接收断言的结果不会触发panic，返回B的类型零值，ok=false）。\n  非空接口.(具体类型) A.(B)\n判断A的动态类型是否和具体类型B相同，相同则断言成功，否则断言失败。\n断言成功返回A的动态值，类型当然是具体类型B。\n失败会触发panic（使用两个值接收断言的结果不会触发panic，返回B的零值）。\n  空接口.(非空接口类型) A.(B)\n判断A的动态类型是否实现了非空接口B，实现则断言成功，否则断言失败。\n断言成功返回一个B类型的接口变量，动态值与A相同，动态类型元数据与B相同。\n失败会触发panic（使用两个值接收断言的结果不会触发panic，返回B的零值）。\n  非空接口.(非空接口类型) A.(B)\n判断A的动态类型是否实现了非空接口B，实现则断言成功，否则断言失败。\n断言成功返回一个B类型的接口变量，动态值与A相同，动态类型元数据与B相同。\n失败会触发panic（使用两个值接收断言的结果不会触发panic，返回B的零值）。\n  switch的用法\n1switch x.(type) { 2 case nil: // ... 3 case int, uint: // ... 4 case bool: // ... 5 case string: // ... 6 default: // ... 7} 反射 反射的作用是把类型元数据暴露给用户使用。\n两个重要方法：reflect.TypeOf() reflect.ValueOf()\n两个重要类型：reflect.Value reflect.Type\n常用方法 reflect.Value.Kind()和reflect.Type.Kind()\n返回具体类型，如reflect.Struct、reflect.Ptr、reflect.String等。\nreflect.Type.Name()\n返回自定义类型在包中的名称\n1type student struct{ 2\tname string 3\tage int 4} 5 6func main() { 7\ts1 := student{ 8\tname: \u0026#34;why\u0026#34;, 9\tage: 18, 10\t} 11 12\tt := reflect.TypeOf(s1) 13\tfmt.Println(t.Name()) //student 14} **reflect.Value.Interface()**返回一个空接口，动态类型和动态值与v相同。\n通过反射修改值\n通过反射调用方法\n1type student struct{ 2\tname string 3\tage int 4} 5 6func (s student) Print() { 7\tfmt.Println(s.name) 8\tfmt.Println(s.age) 9} 10 11func main() { 12\ts := student{ 13\tname: \u0026#34;why\u0026#34;, 14\tage: 18, 15\t} 16 17\tt := reflect.TypeOf(s) 18\tv := reflect.ValueOf(s) 19 20\tm1, _ := t.MethodByName(\u0026#34;Print\u0026#34;) 21\tm2 := v.MethodByName(\u0026#34;Print\u0026#34;) 22 23 m1.Func.Call([]reflect.Value{reflect.ValueOf(student{\u0026#34;why\u0026#34;, 18})}) 24\tm2.Call([]reflect.Value{}) 25} 针对结构体的方法\n  **reflect.Type.NumField()**返回结构体的字段数目\n  **reflect.Type.Field()**返回结构体的第i个字段(reflect.StructField)，通过StructField可以获取该字段的名字、类型、tag等信息\n  **reflect.StructTag.Lookup()、reflect.StructTag.Get()**获取tag信息\n1type student struct{ 2\tname string `test:\u0026#34;test\u0026#34;` 3\tage int 4} 5 6func main() { 7\ts := student{ 8 name: \u0026#34;why\u0026#34;, 9 age: 18, 10\t} 11\ttag, ok := reflect.TypeOf(s).Field(0).Tag.Lookup(\u0026#34;test\u0026#34;) 12\t//tag := reflect.TypeOf(s).Field(0).Tag.Get(\u0026#34;test\u0026#34;) 13\tfmt.Println(tag, ok) 14}   注意事项   如果一个结构体嵌套的匿名结构体实现了某个接口，那么这个结构体也实现了该接口。\n  如果一个结构体实现了某个接口，那么该结构体类型和相应的指针类型都可以被声明为该接口类型。\n  如果一个结构体指针实现了某个接口，那么只有该结构体相应的指针类型才能被声明为该接口类型。\n  空接口类型并不等于任意类型\n1func main() { 2\tvar i *int 3\tvar e interface{} 4 fmt.Println(i == nil) //true 指针类型的零值是nil 5\tfmt.Println(e == nil) //true 接口类型的零值是nil 6\te = i //隐式的类型转换 7\tfmt.Println(e == nil) //false 空接口由两部分组成，将i赋值给e时，动态类型部分是*int 8}  ","date":"2021-06-06","permalink":"https://why9661.github.io/myblog/posts/golang/%E6%8E%A5%E5%8F%A3/","series":null,"tags":["Golang"],"title":"Golang-接口"},{"categories":["Golang"],"content":"简介 go test命令是一个按照一定的约定和组织的测试代码的驱动程序。在包目录内，所有以_test.go为后缀名的源文件并不是go build构建包的一部分，它们是go test测试的一部分。\n在*_test.go文件中，有三种类型的函数：测试函数、基准测试函数、示例函数。一个测试函数是以Test为函数名前缀的函数，用于测试程序的一些逻辑行为是否正确；go test命令会调用这些测试函数并报告测试结果是PASS或FAIL。基准测试函数是以Benchmark为函数名前缀的函数，它们用于衡量一些函数的性能；go test命令会多次运行基准函数以计算一个平均的执行时间。示例函数是以Example为函数名前缀的函数，提供一个由编译器保证正确性的示例文档。\ngo test命令会遍历所有的*_test.go文件中符合上述命名规则的函数，然后生成一个临时的main包用于调用相应的测试函数，然后构建并运行、报告测试结果，最后清理测试中生成的临时文件。\n测试函数 每个测试函数必须导入 testing 包。测试函数签名如下：\n1func TestName(t *testing.T) { 2\t// ... 3} 测试函数的名字必须以Test开头, 可选的后缀名必须以大写字母开头。\n一个例子\ncalc.go文件如下：\n1func Add(a, b int) int { 2\treturn a + b 3} 4 5func Sub(a, b int) int { 6\treturn a - b 7} calc_test.go文件如下：\n1func TestAdd(t *testing.T) { 2\tif result := Add(3, 2); result != 5 { 3\tt.Errorf(\u0026#34;Result: %d, Expected result: 5\\n\u0026#34;, result) 4\t} 5} 6 7func TestSub(t *testing.T) { 8\tif result := Sub(3, 2); result != 1 { 9\tt.Errorf(\u0026#34;Result: %d, Expected result: 1\\n\u0026#34;, result) 10\t} 11} 执行go test\n1PASS 2ok go_test/testexample 0.125s 参数 -v 用于打印每个测试函数的名字和运行时间\n1go test -v 2=== RUN TestAdd 3--- PASS: TestAdd (0.00s) 4=== RUN TestSub 5--- PASS: TestSub (0.00s) 6PASS 7ok go_test/testexample 0.121s 参数 -run 是一个正则表达式, 只有测试函数名被它正确匹配的测试函数才会被 go test 运行。\ngo test默认会执行单元测试，可以使用-run=none禁止运行单元测试。\n1go test -run TestAdd -v 2=== RUN TestAdd 3--- PASS: TestAdd (0.00s) 4PASS 5ok go_test/testexample 0.106s 子测试\n使用t.Run创建不同的子测试用例\n1func TestAdd(t *testing.T) { 2 t.Run(\u0026#34;pos\u0026#34;, func(t *testing.T) { 3 if result := Add(2, 3); result != 5 { 4 t.Fatalf(\u0026#34;Result: %d, Expected result: 5\\n\u0026#34;, result) 5 } 6 }) 7 8 t.Run(\u0026#34;neg\u0026#34;, func(t *testing.T) { 9 if result := Add(-2, -3); result != -5 { 10 t.Fatalf(\u0026#34;Result: %d, Expected result: 05\\n\u0026#34;, result) 11 } 12 }) 13} 1go test -run TestAdd/neg -v 2=== RUN TestAdd 3=== RUN TestAdd/neg 4--- PASS: TestAdd (0.00s) 5 --- PASS: TestAdd/neg (0.00s) 6PASS 7ok go_test/testexample 0.111s 表格驱动测试\n1func TestAdd(t *testing.T) { 2 testcases := []struct{ 3 inputA int 4 inputB int 5 expected int 6 }{ 7 {1, 2, 3}, 8 {-1, -2, -3}, 9 {0, 0, 0}, 10 } 11 12 for _, c := range testcases { 13 if result := Add(c.inputA, c.inputB); result != c.expected { 14 t.Fatalf(\u0026#34;Result: %d Expected result: %d\u0026#34;, result, c.expected) 15 } 16 } 17} 这种测试方式可以方便的添加测试用例，并且输出的测试报告易于阅读。\n帮助函数\n对一些重复的逻辑，抽取出来作为公共的帮助函数(helpers)，可以增加测试代码的可读性和可维护性。\n1package testexample 2 3import \u0026#34;testing\u0026#34; 4 5type testcase struct{A, B, Expected int} 6 7func createAddTestcase(t *testing.T, c *testcase) { 8\t//t.Helper() 9\tif result := Add(c.A, c.B); result != c.Expected { 10\tt.Fatalf(\u0026#34;Result: %d Expected: %d\\n\u0026#34;, result, c.Expected) 11\t} 12} 13 14func TestAdd(t *testing.T) { 15\tcreateAddTestcase(t, \u0026amp;testcase{1, 2, 3}) 16\tcreateAddTestcase(t, \u0026amp;testcase{1, 3, 3}) //wrong 17} 这里添加了一个错误的测试用例，运行go test会报告在帮助函数内部即代码的第10行发生错误，但代码的第15、16行都调用了该方法，不能根据错误信息直接定位问题。\n1go test 2--- FAIL: TestAdd (0.00s) 3 calc_test.go:10: Result: 4 Expected: 3 4FAIL 5exit status 1 6FAIL go_test/testexample 0.140s 使用t.Helper()函数，会准确的定位到第16行代码发生错误。\n1go test 2--- FAIL: TestAdd (0.00s) 3 calc_test.go:16: Result: 4 Expected: 3 4FAIL 5exit status 1 6FAIL go_test/testexample 0.141s 网络测试\n假设需要测试某个 API 接口的 handler 能够正常工作，例如 helloHandler\n1func helloHandler(w http.ResponseWriter, r *http.Request) { 2\tw.Write([]byte(\u0026#34;hello world\u0026#34;)) 3} 那我们可以创建真实的网络连接进行测试：\n1func helloHandler(w http.ResponseWriter, r *http.Request) { 2\tw.Write([]byte(\u0026#34;Hello World!\u0026#34;)) 3} 4 5func handleError(t *testing.T, err error) { 6\tt.Helper() 7\tif err != nil { 8\tt.Fatal(\u0026#34;failed\u0026#34;, err) 9\t} 10} 11 12func TestConn(t *testing.T) { 13\tln, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;127.0.0.1:8000\u0026#34;) 14\thandleError(t, err) 15\tdefer ln.Close() 16 17\thttp.HandleFunc(\u0026#34;/hello\u0026#34;, helloHandler) 18\tgo http.Serve(ln, nil) 19 20\tresp, err := http.Get(\u0026#34;http://\u0026#34; + ln.Addr().String() + \u0026#34;/hello\u0026#34;) 21\thandleError(t, err) 22\tdefer resp.Body.Close() 23 24\tbody, err := ioutil.ReadAll(resp.Body) 25\thandleError(t, err) 26 27\tif string(body) != \u0026#34;Hello World!\u0026#34; { 28\tt.Fatal(\u0026#34;expected hello world, but got\u0026#34;, string(body)) 29\t} 30} 执行go test -run=TestConn\n1PASS 2ok go_test/testexample 0.223s 针对 http 开发的场景，使用标准库 net/http/httptest 进行测试更为高效。\n1func TestConn(t *testing.T) { 2 req := httptest.NewRequest(\u0026#34;GET\u0026#34;, \u0026#34;http://example.com/foo\u0026#34;, nil) 3 w := httptest.NewRecorder() 4 helloHandler(w, req) 5 bytes, _ := ioutil.ReadAll(w.Result().Body) 6 if string(bytes) != \u0026#34;hello world\u0026#34; { 7 t.Fatal(\u0026#34;expected hello world, but got\u0026#34;, string(bytes)) 8 } 9} 基准测试 基准测试是测量一个程序在固定工作负载下的性能. 在Go语言中, 基准测试函数和普通测试函数类似, 但是以Benchmark为前缀名, 并且带有一个 *testing.B 类型的参数; *testing.B 除了提供和 *testing.T 类似的方法, 还有额外一些和性能测量相关的方法. 它提供了一个整数N, 用于指定操作执行的循环次数。\n和普通测试不同的是, go test默认情况下不运行任何基准测试，需要通过 -bench 命令行标志参数手动指定要运行的基准测试函数. 该参数是一个正则表达式, 用于匹配要执行的基准测试函数的名字, 默认值是空的. 其中 ‘‘.’’ 模式可以匹配所有基准测试函数。\n一个例子\n1func BenchmarkSprintf(b *testing.B) { 2\tnum := 123 3\tb.ResetTimer() 4\tfor i := 0; i \u0026lt; b.N; i++ { 5\tfmt.Sprintf(\u0026#34;%d\u0026#34;, num) 6\t} 7} 8 9func BenchmarkFormat(b *testing.B) { 10\tnum := int64(123) 11\tb.ResetTimer() 12\tfor i := 0; i \u0026lt; b.N; i++ { 13\tstrconv.FormatInt(num, 10) 14\t} 15} 16 17func BenchmarkItoa(b *testing.B) { 18\tnum := 123 19\tb.ResetTimer() 20\tfor i := 0; i \u0026lt; b.N; i++ { 21\tstrconv.Itoa(num) 22\t} 23} 1go test -bench=. 2... 3BenchmarkSprintf-4 7685479 155.8 ns/op 4BenchmarkFormat-4 25729987 46.18 ns/op 5BenchmarkItoa-4 25522030 46.91 ns/op 6PASS 7ok go_test/testexample 5.922s 基准测试名的数字后缀表示运行时GOMAXPROCS的值。报告显示每次调用Sprintf函数花费155.8纳秒，是执行7685479次的平均时间。\nb.ResetTimer重置计时器，可以在真正的测试代码前调用以避免其它代码干扰。\n测试时间默认是1s，可以使用-benchtime指定运行时间\n1go test -bench=. -benchtime=3s 2... 3BenchmarkSprintf-4 21998582 164.9 ns/op 4BenchmarkFormat-4 61516693 52.66 ns/op 5BenchmarkItoa-4 63125335 55.21 ns/op 6PASS 7ok go_test/testexample 10.820s -benchmem可以显示每次分配内存的次数，以及每次分配内存的大小\n1go test -bench=. -benchmem 2... 3BenchmarkSprintf-4 8621544 134.9 ns/op 3 B/op 1 allocs/op 4BenchmarkFormat-4 26064914 45.87 ns/op 3 B/op 1 allocs/op 5BenchmarkItoa-4 25207171 47.30 ns/op 3 B/op 1 allocs/op 6PASS 7ok go_test/testexample 3.932s 示例函数 第三种 go test 特别处理的函数是示例函数, 以 Example 为函数名开头. 示例函数没有函数参数和返回值。\n参考：\n《The Go Programming Language》\n","date":"2021-05-09","permalink":"https://why9661.github.io/myblog/posts/golang/%E6%B5%8B%E8%AF%95/","series":null,"tags":["Golang"],"title":"Golang-测试"},{"categories":["Golang"],"content":"方法本质上是一个函数，方法接收者就是隐含的第一个参数\n1type A struct { 2\tName string 3} 4 5func (a A) SayHello1() string { 6\treturn \u0026#34;Hello \u0026#34; + a.Name 7} 8 9func SayHello2(a A) string { 10\treturn \u0026#34;Hello \u0026#34; + a.Name 11} 12 13func main() { 14\tt1 := reflect.TypeOf(A.SayHello1) 15\tt2 := reflect.TypeOf(SayHello2) 16\tfmt.Println(t1 == t2) // true 17} 以下是一个常见的方法调用，这其实是一个语法糖，等价于注释行的函数调用。\n1type A struct { 2\tName string 3} 4 5func (a A) SayHello() string { 6\treturn \u0026#34;Hello \u0026#34; + a.Name 7} 8 9func main() { 10\ta := A{\u0026#34;why\u0026#34;} 11\tfmt.Println(a.SayHello()) 12\t//fmt.Println(A.SayHello(a)) 13} 如果需要通过方法调用来完成对接收者的修改，那么需要使用指针接受者\n1type A struct { 2\tName string 3} 4 5func (a A) Rename1(name string) { 6\ta.Name = name 7} 8 9func (a *A) Rename2(name string) { 10\ta.Name = name 11} 12 13func main() { 14\ta := A{\u0026#34;why\u0026#34;} 15\tb := A{\u0026#34;why\u0026#34;} 16\ta.Rename1(\u0026#34;why123\u0026#34;) 17\tb.Rename2(\u0026#34;why123\u0026#34;) 18\tfmt.Println(a.Name) //why 19\tfmt.Println(b.Name) //why123 20} 可以通过值调用指针接受者的方法，也可以通过指针调用值接收者的方法，这也是一种语法糖\n1type A struct { 2 Name string 3} 4 5func (a A) Rename1(name string) { 6 a.Name = name 7} 8 9func (a *A) Rename2(name string) { 10 a.Name = name 11} 12 13func main() { 14 a := A{\u0026#34;why\u0026#34;} 15 b := \u0026amp;A{\u0026#34;why\u0026#34;} 16 a.Rename2(\u0026#34;why123\u0026#34;) //在编译阶段会转换为(\u0026amp;a).Rename2(string) 17 b.Rename1(\u0026#34;why123\u0026#34;) //在编译阶段会转换为(*b).Rename1(string) 18 fmt.Println(a.Name) // why123 19 fmt.Println(b.Name) // why 20} 方法和函数一样可以赋值给变量\n1type A struct { 2 Name string 3} 4 5func (a A) PrintName() { 6 fmt.Println(a.Name) 7} 8 9func main() { 10 a := A{\u0026#34;why\u0026#34;} 11 f1 := a.PrintName //有捕获列表的Function Value 12 f2 := A.PrintName //Function Value 13 f1() //why 14 f2(a) //why 15} ","date":"2021-04-28","permalink":"https://why9661.github.io/myblog/posts/golang/%E6%96%B9%E6%B3%95/","series":null,"tags":["Golang"],"title":"Golang-方法"},{"categories":["Golang"],"content":"Function Value 在Go语言中，函数是头等对象，可以作为参数传递，可以作为返回值返回，也可绑定给变量。Go语言称这样的参数、返回值、变量为Function Value。\nFunction Value本质上是一个指针，指向一个runtime.funcval结构体：\n1type funcval struct { 2\tfn uintptr 3} 这个结构体持有一个指针fn，指向函数指令入口。\n例子\n函数A被赋值给变量f1和f2。\n编译器会做出优化，在只读数据段分配一个funcval结构体，f1和f2共用这个结构体，结构体中的fn指向函数A的指令入口。\n1func A() int { 2\ti := 1 3\treturn i 4} 5 6func main() { 7\tf1 := A 8\tf2 := A 9 fmt.Println(f1()) //1 10 fmt.Println(f2()) //1 11} 闭包 闭包可以简单理解为函数+引用环境，或者说闭包是有捕获列表的function value。\n例子\n返回的匿名函数引用了外部的局部变量x，返回的这个函数就是一个闭包。\n执行到f1:=A()时，函数A会在堆上分配一个funcval结构体，同时拷贝x的值到捕获列表，再将这个funcval的起始地址返回给f1。\n执行到f2:=A()时，函数A会在堆上再分配一个funcval结构体，同时拷贝x的值到捕获列表，再将这个funcval的起始地址返回给f2。\n1func A() func() int { 2\tx := 1 3\treturn func() int { //闭包 4\treturn x 5\t} 6} 7 8func main() { 9\tf1 := A() 10\tf2 := A() 11\tfmt.Println(f1()) //1 12\tfmt.Println(f2()) //1 13} 以上是被捕获的变量不会被修改的情况，直接拷贝值到捕获列表就ok。\n接下来看被捕获的变量会被修改的情况：\n捕获局部变量\n执行到f1:=A()时，函数A会在堆上分配一个funcval结构体，由于被捕获的变量被外部引用且被修改，x会逃逸到堆上，并且捕获列表存x的地址，然后将这个funcval的起始地址返回给f1。\n执行到f2:=A()时，函数A会在堆上再分配一个funcval结构体，由于被捕获的变量被外部引用且被修改，x会逃逸到堆上，并且捕获列表存x的地址，然后将这个funcval的起始地址返回给f2。\n1func A() func() int { 2\tx := 1 3\treturn func() int { //闭包 4\tx++ 5\treturn x 6\t} 7} 8 9func main() { 10\tf1 := A() 11\tf2 := A() 12\tfmt.Println(f1()) //2 13\tfmt.Println(f2()) //2 14\tfmt.Println(f1()) //3 15\tfmt.Println(f2()) //3 16} 闭包引起的一些问题\n1func main() { 2\tfor i := 0; i \u0026lt; 5; i++ { 3\tdefer func() { 4\tfmt.Println(i) 5\t}() 6\t} 7} 8//输出 9//5 10//5 11//5 12//5 13//5 解决方法：\n1func main() { 2\tfor i := 0; i \u0026lt; 5; i++ { 3 x := i 4\tdefer func() { 5\tfmt.Println(x) 6\t}() 7\t} 8} 9 10func main() { 11\tfor i := 0; i \u0026lt; 5; i++ { 12\tdefer func(x int) { 13\tfmt.Println(x) 14\t}(i) 15\t} 16} ","date":"2021-04-27","permalink":"https://why9661.github.io/myblog/posts/golang/%E9%97%AD%E5%8C%85/","series":null,"tags":["Golang"],"title":"Golang-闭包"},{"categories":["Golang"],"content":"标准库中的 text/template包是 Go 语言内置的文本模板引擎。\n而html/template是对text/template的封装，用法大同小异。\n常用方法\n解析模板\n1//创建一个模板对象 2func New(name string) *Template {...} 3 4func (t *Template) Parse(text string) (*Template, error) {...} 5func (t *Template) ParseFiles(filenames ...string) (*Template, error) {...} 6//支持模式匹配 如：\u0026#34;*.html\u0026#34; 7func (t *Template) ParseGlob(pattern string) (*Template, error) {...} 8 9func ParseFiles(filenames ...string) (*Template, error) {...} 10func ParseGlob(pattern string) (*Template, error) {...} 执行模板\n1//Execute方法用于渲染模板，该方法接受两个参数：输出对象和指定根对象 2func (t *Template) Execute(wr io.Writer, data interface{}) error {...} 3//当加载了多个模板文件时，使用ExecuteTemplate方法指定渲染某一个模板文件 4func (t *Template) ExecuteTemplate(wr io.Writer, name string, data interface{}) error {...} 给模板添加自定义函数\n1//除了内置的模板函数外，可以通过Funcs方法增加自定义模板函数 2func (t *Template) Funcs(funcMap FuncMap) *Template {...} 3 4//eg: 5func main() { 6\thttp.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { 7\ttemp := template.New(\u0026#34;test\u0026#34;).Funcs(template.FuncMap{ 8\t\u0026#34;area\u0026#34;: func(a, b int) int { 9\treturn a * b 10\t}, 11\t}) 12 13\t_, _ = temp.Parse(` 14Area: {{area12}}15`) 16 17\ttemp.Execute(w, nil) 18\t}) 19 20\tlog.Println(\u0026#34;Starting HTTP server...\u0026#34;) 21\tlog.Fatal(http.ListenAndServe(\u0026#34;localhost:4000\u0026#34;, nil)) 22} 模板中的Action（赋值、逻辑控制、函数等等）需要使用{{}}包裹，除Action之外的内容会原封不动的进行输出。\n{{.}}操作符默认指向根对象。\n注释的语法和 Go 语言程序代码中的块注释语法相同，即使用 /* 和 */ 将注释内容包括起来，例如：{{/* 这是注释内容 */}}。\n{{- 用于剔除模板左侧多余的空格， -}}用于剔除模板中右侧多余的空格\n示例\n直接渲染文本\n1func main() { 2\thttp.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { 3\ttemp, _ := template.New(\u0026#34;test\u0026#34;).Parse(\u0026#34;hello template\u0026#34;) 4 5\t_ = temp.Execute(w, nil) 6\t}) 7 8\tlog.Println(\u0026#34;Starting HTTP server...\u0026#34;) 9\tlog.Fatal(http.ListenAndServe(\u0026#34;localhost:4000\u0026#34;, nil)) 10} 在模板中引用根对象\n1type Rect struct { 2\tWidth int 3\tHeight int 4} 5 6func (r *Rect) Area() int { 7\treturn r.Width * r.Height 8} 9 10func main() { 11\thttp.HandleFunc(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, r *http.Request) { 12\ttemp, _ := template.New(\u0026#34;test\u0026#34;).Parse(`Rect 13Width: {{.Width}}14Height: {{.Height}}15Area: {{.Area}}16`) 17 18\twidth, _ := strconv.Atoi(r.URL.Query().Get(\u0026#34;w\u0026#34;)) 19\theight, _ := strconv.Atoi(r.URL.Query().Get(\u0026#34;h\u0026#34;)) 20 21\trect := \u0026amp;Rect{Width: width, Height: height} 22 23\t_ = temp.Execute(w, rect) 24\t}) 25 26\tlog.Println(\u0026#34;Starting HTTP server...\u0026#34;) 27\tlog.Fatal(http.ListenAndServe(\u0026#34;localhost:4000\u0026#34;, nil)) 28} ","date":"2021-04-10","permalink":"https://why9661.github.io/myblog/posts/golang/%E6%A8%A1%E6%9D%BF%E5%BC%95%E6%93%8E/","series":null,"tags":["Golang"],"title":"Golang-模板引擎"},{"categories":["Golang"],"content":"原子操作 原子操作与锁\n  原子操作趋于乐观，总是假设被操作的值未曾被改变，并一旦确认这个假设的真实性就立即进行值替换，那么在被操作值被频繁变更的情况下，CAS操作并不那么容易成功。\n锁趋于悲观，总假设会有并发的操作要修改被操作的值，并使用锁将相关操作放入临界区中加以保护。\n  原子操作比锁更轻量，多线程竞争的情况下，频繁的加解锁会导致很多的上下文切换和调度延时，性能会很差。\n  sync/atomic包提供了五种原子操作：\n Add 加减 Load 读取 Store 存储 CompareAndSwap（CAS）比较并交换 Swap 交换  通过CAS操作和for循环可以实现一个简单的自旋锁。\n数据结构 1type Mutex struct { 2 //互斥锁的状态 3\tstate int32 4 //信号量，用作等待队列 5 //runtime使用一个大小为251的semaTable来管理semaphore 6 //semaTable存储的是251棵平衡树的树根 7 //根据sema变量的地址计算映射到semaTable中的一棵树上，找到对应结点就找到该信号量对应的等待队列 8\tsema uint32 9} state的第一位用来表示是否已加锁；\nstate的第二位用来表示是否已有goroutine被唤醒；\nstate的第三位用来表示Mutex的工作模式；\n除了低3位的其余位数用来记录有多少个等待者在排队\n对应以下常量:\n1const ( 2\tmutexLocked = 1 \u0026lt;\u0026lt; iota 3\tmutexWoken 4\tmutexStarving 5 mutexWaiterShift = iota 6 starvationThresholdNs = 1e6 //饥饿阈值 1ms 7) 加锁\n1func (m *Mutex) Lock() { 2\tif atomic.CompareAndSwapInt32(\u0026amp;m.state, 0, mutexLocked) { 3\t... 4\treturn 5\t} 6 7\tm.lockSlow() 8} 解锁\n1func (m *Mutex) Unlock() { 2\t... 3 4\tnew := atomic.AddInt32(\u0026amp;m.state, -mutexLocked) 5\tif new != 0 { 6\tm.unlockSlow(new) 7\t} 8} 正常模式\u0026amp;饥饿模式 在正常模式下，一个goroutine若尝试加锁失败，那么会先自旋几次，继续尝试通过原子操作获得锁，若几次自旋后仍不能获得锁，则通过信号量排队等待，所有的等待者会按照FIFO的顺序排队。当锁被释放，第一个等待者被唤醒后不会直接拥有锁，而是需要和后来者竞争，也就是那些处于自旋状态尚未排队等待的goroutine，这种情况下后来者更有优势（正在CPU上运行，数量多），所以被唤醒的goroutine大概率拿不到锁，这种情况下它会被重新插入队列的头部，而当goroutine本次加锁等待的时间超过1ms后，它会把当前Mutex从正常模式切换到饥饿模式。\n在饥饿模式下，Mutex的所有权从unlock的goroutine直接传递给等待队列中的第一个goroutine，后来者不会自旋也不会尝试获得锁，它们会直接进入队列尾部排队。当一个等待者获得锁的时候，会在以下两种情况将Mutex切换回正常模式：1、它的等待时间小于1ms 。2、它是最后一个等待者。\n","date":"2021-04-10","permalink":"https://why9661.github.io/myblog/posts/golang/%E9%94%81/","series":null,"tags":["Golang"],"title":"Golang-锁"},{"categories":["Golang"],"content":"TCMalloc\nTCMalloc(Thread Cache Malloc)即线程缓存分配，Go语言的堆内存分配就借鉴了TCMalloc。\n同一进程的所有线程共享相同的内存空间，他们申请内存时需要加锁。\nTCMalloc为每个线程预分配一块缓存，线程申请小内存时，可以从缓存分配内存，有以下好处：\n 为线程预分配缓存需要进行1次系统调用，后续线程申请小内存时，从缓存分配，都是在用户态执行，没有系统调用，缩短了内存总体的分配和释放时间，这是快速分配内存的第二个层次。 多个线程同时申请小内存时，从各自的缓存分配，访问的是不同的地址空间，无需加锁，把内存并发访问的粒度进一步降低了，这是快速分配内存的第三个层次。  第一个层次：引入虚拟内存，让内存的并发访问问题的粒度从多进程级别，降低到多线程级别。\nTCMalloc的几个重要概念\n  Page\n操作系统对内存管理以页为单位，TCMalloc也是这样，只不过TCMalloc里的Page大小与操作系统里的大小并不一定相等，而是倍数关系。x64下Page大小是8KB。\n  Span：一组连续的Page被称为Span，比如可以有2个页大小的Span，也可以有16页大小的Span，Span比Page高一个层级，是为了方便管理一定大小的内存区域，Span是TCMalloc中内存管理的基本单位。\n  ThreadCache：每个线程各自的Cache，一个Cache包含多个空闲内存块链表，每个链表连接的都是内存块，同一个链表上内存块的大小是相同的，也可以说按内存块大小，给内存块分了个类，这样可以根据申请的内存大小，快速从合适的链表选择空闲内存块。由于每个线程有自己的ThreadCache，所以ThreadCache访问是无锁的。\n  CentralCache：是所有线程共享的缓存，也是保存的空闲内存块链表，链表的数量与ThreadCache中链表数量相同，当ThreadCache内存块不足时，可以从CentralCache取，当ThreadCache内存块多时，可以放回CentralCache。由于CentralCache是共享的，所以它的访问是要加锁的。\n  PageHeap：PageHeap是堆内存的抽象，PageHeap存的也是若干链表，链表保存的是Span，当CentralCache没有内存的时，会从PageHeap取，把1个Span拆成若干内存块，添加到对应大小的链表中，当CentralCache内存多的时候，会放回PageHeap。如下图，分别是1页Page的Span链表，2页Page的Span链表等，最后是large span set，这个是用来保存中大对象的。毫无疑问，PageHeap也是要加锁的。\n  小、中、大对象，Go内存管理中也有类似的概念，TCMalloc的定义：\n 小对象大小：0~256KB 中对象大小：257~1MB 大对象大小：\u0026gt;1MB  小对象的分配流程：ThreadCache -\u0026gt; CentralCache -\u0026gt; HeapPage，大部分时候，ThreadCache缓存都是足够的，不需要去访问CentralCache和HeapPage，无锁分配加无系统调用，分配效率是非常高的。\n中对象分配流程：直接在PageHeap中选择适当的大小即可，128 Page的Span所保存的最大内存就是1024KB即1MB。\n大对象分配流程：从large span set选择合适数量的页面组成span，用来存储数据。\n了解了TCMalloc，接下来看Go语言的内存分配。\n  Page\nx64下一个Page的大小是8KB。\n  Span\n一组连续的Page组成一个Span。（mspan）。\n  mcache\nmcache与TCMalloc中的ThreadCache类似，mcache保存的是各种大小的Span，并按Span class分类，小对象直接从mcache分配内存，它起到了缓存的作用，并且可以无锁访问。\n但mcache与ThreadCache也有不同点，TCMalloc中是每个线程1个ThreadCache，Go中是每个P拥有1个mcache，因为在Go程序中，当前最多有GOMAXPROCS个线程在运行，所以最多需要GOMAXPROCS个mcache就可以保证各线程对mcache的无锁访问，线程的运行又是与P绑定的，把mcache交给P刚刚好。\n  mcentral\nmcentral与TCMalloc中的CentralCache类似，是所有线程共享的缓存，需要加锁访问，它按Span class对Span分类，串联成链表，当mcache的某个级别Span的内存被分配光时，它会向mcentral申请1个当前级别的Span。\n但mcentral与CentralCache也有不同点，CentralCache是每个级别的Span有1个链表，mcache是每个级别的Span有2个链表，这和mcache申请内存有关。\n  mheap\nmheap与TCMalloc中的PageHeap类似，它是堆内存的抽象，把从OS申请出的内存页组织成Span，并保存起来。当mcentral的Span不够用时会向mheap申请，mheap的Span不够用时会向OS申请，向OS的内存申请是按页来的，然后把申请来的内存页生成Span组织起来，同样也是需要加锁访问的。\n但mheap与PageHeap也有不同点：mheap把Span组织成了树结构，而不是链表，并且还是2棵树，然后把Span分配到heapArena进行管理，它包含地址映射和span是否包含指针等位图，这样做的主要原因是为了更高效的利用内存：分配、回收和再利用。\n  微对象、小对象、大对象\n   类别 大小     微对象 (0, 16B)   小对象 [16B, 32KB]   大对象 (32KB, +∞)    堆上所有的对象都会通过调用 runtime.newobject 函数分配内存，该函数会调用 runtime.mallocgc 分配指定大小的内存空间，对于不同大小的对象，有以下的分配逻辑：\n1、微对象：先使用微型分配器(非指针类型)，再依次尝试线程缓存、中心缓存和堆分配内存；\n2、小对象：依次尝试使用线程缓存、中心缓存和堆分配内存；\n3、大对象：直接在堆上分配内存；\n","date":"2021-03-09","permalink":"https://why9661.github.io/myblog/posts/golang/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/","series":null,"tags":["Golang"],"title":"Golang-内存分配"},{"categories":["MySQL"],"content":"索引是帮助MySQL高效获取数据的数据结构。不过索引本身也很大，会占据不少的磁盘空间；索引还会降低表的更新效率，因为每创建一个索引，就会对应生成一个索引文件，在表数据更新时，需要同时更新这些索引文件。\n数据结构   哈希表\n可以使用key存储索引，value存储行记录或者行所在磁盘地址。\n精确查找速度快，但不支持范围查找。\n  二叉搜索树\n支持范围查找，查找效率也还不错。\n但在极端条件下会退化成链表。\n  平衡二叉搜索树\n平衡二叉树不会出现极端情况下退化成链表地情况，但随着数据量的增大树的高度还是会很高（磁盘IO次数增多），而且在插入、删除操作密集的场景中，平衡二叉树需要频繁地rebalance，增加性能开销。\n  B树\nMySQL的数据文件是存储在磁盘上的，而磁盘的IO速度慢开销大，因此降低磁盘IO的次数能很大程度提高MySQL的性能。树越高，磁盘IO操作次数就会越多，因此需要尽量降低树的高度，这就要每个节点多存储元素。\nB树就是一种多叉平衡搜索树。\n为了降低树的高度，需要让每个节点尽可能多的存储索引，因此就有了B+树。\n  B+树\nB+树与B树的区别在于B树的非叶子节点和叶子节点都会存储数据，而B+树的非叶子节点只存储索引，叶子节点存储数据，并且叶子节点之间使用双向指针连接。\n等值查询\n范围查询\n  不同存储引擎的实现 MyISAM MyISAM的索引文件和数据文件分开存储，索引文件存储在.MYI文件中，数据文件存储在.MYD文件中。\nMyISAM的主键索引和辅助索引的叶子节点都是存储的索引+索引所在行的磁盘地址（非行数据），属于非聚簇索引。\nInnoDB InnoDB的索引和数据存储在.ibd文件中。\n主键索引的叶子节点会存储索引+索引所在行的数据，属于聚簇索引；\n辅助索引的叶子节点会存储索引+索引所在行的主键值，属于非聚簇索引。\n 当表定义了primary key时，InnoDB将primary key用作聚簇索引 当表没有定义primary ket时，InnoDB会选择第一个not null的unique列用作聚簇索引 否则InnoDB会创建一个隐藏的row-id用作聚簇索引  联合索引\u0026amp;最左匹配\u0026amp;索引下推 联合索引是指多个字段联合组成一个索引，也是一种辅助索引（叶子节点会存主键值）。\n联合索引的存储方式：按联合索引的第一列排序，在前面列相等的情况下进行局部排序。\n联合索引的检索方式：和存储方式一样，先比较第一列，在前面列相等的情况下比较后面的列。\n像下面这种创建了联合索引(a,b,c)相当于创建了3个索引:(a)、(a,b)、(a,b,c)\n最左前缀匹配：\n  mysql会一直向右匹配直到遇到范围查询(\u0026gt;、\u0026lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c \u0026gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。\n  a = 1 and b = 2 and c = 3 建立(a,b,c)索引时可以任意顺序，mysql的查询优化器会优化成索引可以识别的形式\n  如果建立的索引顺序是 （a，b）那么直接采用 where b = 5 这种查询条件是无法利用到索引的，这一条最能体现最左匹配的特性。\n  索引下推：\n例如现在有一个联合索引(name,age)，需求是查出表中“姓王的10岁男孩”\n1select*frompersonwherenamelike\u0026#39;王%\u0026#39;andage=10\u0026amp;ismale=1;在这个查询中，能够使用到索引name。在MySQL5.6之前，找到name满足条件的主键后会一个一个回表，在主键索引上找到数据行，然后比对age和ismale的字段值。\n索引下推可以在索引遍历过程中，对索引包含的字段先做判断，过滤掉不满足条件的记录，减少回表次数。\n回表\u0026amp;覆盖索引 回表是指在使用辅助索引时，拿到主键值后还需要回到主键索引中查找需要的数据。\n覆盖索引是一种优化手段可以避免回表。\neg：\n主键为a,辅助索引为(b,c)，需要查询的数据为(a,b,c,d)\n在这种情况下，使用辅助索引查找时，需要先在辅助索引中找到主键a，再回到主键索引中找到记录a,b,c,d\n如果我们定义辅助索引为(b,c,d)，那么使用辅助索引查找到主键a即可得到a,b,c,d返回，不需要再进行回表查询。\n参考：\nhttps://blog.csdn.net/qq_35190492/article/details/109257302\r《MySQL实战45讲》\n","date":"2021-02-22","permalink":"https://why9661.github.io/myblog/posts/mysql/%E7%B4%A2%E5%BC%95/","series":null,"tags":["MySQL"],"title":"MySQL-索引"},{"categories":["Golang"],"content":"数据结构 1ch := make(chan int, 5) ch本质上是一个指针，指向堆上一个runtime.hchan结构体。\n1type hchan struct { 2\tqcount uint // total data in the queue 3\tdataqsiz uint // size of the circular queue 4\tbuf unsafe.Pointer // points to an array of dataqsiz elements 5\telemsize uint16 6\tclosed uint32 7\telemtype *_type // element type 8\tsendx uint // send index 9\trecvx uint // receive index 10\trecvq waitq // list of recv waiters 11\tsendq waitq // list of send waiters 12 13\t// lock protects all fields in hchan, as well as several 14\t// fields in sudogs blocked on this channel. 15\t// 16\t// Do not change another G\u0026#39;s status while holding this lock 17\t// (in particular, do not ready a G), as this can deadlock 18\t// with stack shrinking. 19\tlock mutex 20} channel可分为有缓冲channel和无缓冲channel，也可分为单向的只读\u0026lt;-chan、单向的只写chan\u0026lt;-以及双向channel。\nchannel常用操作是：发送数据、接收数据、关闭channel。\n发送数据 发送数据主要有以下情况：\n 向一个nil的channel发送数据，会阻塞 向一个closed的channel发送数据，会引起panic 当不存在缓冲区或者缓冲区已满时，且接收队列中没有等待的goroutine时，当前goroutine陷入阻塞，等待其他 goroutine 从 Channel 接收数据。 channel的缓冲区没有满时，将发送的数据写入channel的缓冲区。 当channel的等待队列存在被阻塞的接收goroutine时，那么channel会从等待队列中取出最先等待的goroutine并直接向它发送数据：  调用 runtime.sendDirect将发送的数据直接拷贝到 x = \u0026lt;-c 表达式中变量 x 所在的内存地址上； 调用 runtime.goready将等待接收数据的 Goroutine 标记成可运行状态 Grunnable 并把该 goroutine 放到发送方所在的处理器的 runnext 上等待执行，该处理器在下一次调度时会立刻唤醒数据的接收方；    接收数据   对一个nil的channel接收数据，会阻塞\n  对一个closed的channel接收数据，会返回零值；如果多使用一个接收参数，会返回false。\n  当缓冲区没有数据时且当前goroutine的发送队列中不存在等待的goroutine时，当前goroutine陷入阻塞，等待其他goroutine向channel发送数据。\n  channel的缓冲区有数据时，从缓冲区接收数据。\n  当channel的等待队列存在被阻塞的发送goroutine时：\n  如果 Channel 不存在缓冲区：\n调用 runtime.recvDirect 将 Channel 发送队列中 Goroutine 存储的 elem 数据拷贝到目标内存地址中；\n  如果 Channel 存在缓冲区：\n 将队列中的数据拷贝到接收方的内存地址； 将发送队列头的数据拷贝到缓冲区中，释放一个阻塞的发送方；    无论发生哪种情况，运行时都会调用 runtime.goready 将当前处理器的 runnext 设置成发送数据的 goroutine，在调度器下一次调度时将阻塞的发送方唤醒。\n  关闭channel  关闭已closed的channel，会引起panic 关闭为nil的channel，会引起panic  select语句 在select语句中，当有一个case可以执行时就执行这个case，如果多个case同时可以执行，那么select会随机地选取一个执行，都不能执行就处于阻塞状态直到有可以执行的case，当然也可以添加default分支，当没有case可以执行时执行default。\nfor range 当需要从channel中连续的读取数据时，使用for range是比较好的选择。\nfor range会持续地从channel中读取，直到channel被关闭，for range自动退出。\n未完待续。。。","date":"2021-02-16","permalink":"https://why9661.github.io/myblog/posts/golang/channel/","series":null,"tags":["Golang"],"title":"Golang-Channel"},{"categories":["Golang"],"content":"使用defer常见的两个现象   defer会预计算给函数传递的参数，即入参的值在使用defer关键字时就已经确定。\n一个例子\n1func main() { 2 startTime := time.Now() 3 defer fmt.Println(time.Since(startTime)) 4 time.Sleep(10 * time.Second) 5} 6//输出： 7//0s 以上代码并不能实现我们想要统计函数执行时间的需求，因为time.Since(startTime)在传入时值就已经确定。\n可以使用defer+匿名函数来避免这个问题。\n1func main() { 2 startTime := time.Now() 3 defer func() {fmt.Println(time.Since(startTime))}() 4 time.Sleep(10 * time.Second) 5} 6//输出: 7//10.0119478s   defer关键字注册的函数会表现为\u0026quot;倒序执行\u0026quot;\n一个例子\n1func main() { 2\tdefer fmt.Println(\u0026#34;1\u0026#34;) 3\tdefer fmt.Println(\u0026#34;2\u0026#34;) 4\tdefer fmt.Println(\u0026#34;3\u0026#34;) 5} 6//输出： 7//3 8//2 9//1   除此之外，涉及到defer的还有几种容易搞混的情况：\n1func A() int { 2\ta := 1 3\tdefer func() { 4\ta++ 5\t}() 6\treturn a 7} 8 9func B() (a int) { 10\tdefer func() { 11\ta++ 12\t}() 13\treturn 1 14} 15 16func C() (a int) { 17\tdefer func(a int) { 18\ta++ 19\t}(a) 20\treturn 1 21} 22 23func D() (a int) { 24\tdefer func(a *int) { 25\t*a++ 26\t}(\u0026amp;a) 27\treturn 1 28} 29 30func main() { 31\tfmt.Println(A()) //1 32\tfmt.Println(B()) //2 33\tfmt.Println(C()) //1 34\tfmt.Println(D()) //2 35} 首先需要明白return并不是一个原子操作，函数执行到return时：\n1、返回值赋值\n2、如果有注册的defer函数则执行defer函数\n3、ret指令返回\n其次，在Go中函数传参都是值传递。\n在第一种情况中，return a会先将局部变量a的值1赋给返回值，接着执行defer函数，其中a++操作的对象还是局部变量a而不是返回值。\n在第二种情况中，return 1会先将值1赋给返回值a，接着执行defer函数，其中a++操作的对象是返回值a。\n在第三种情况中，return 1会先将值1赋给返回值a，接着执行defer函数，其中传参的值是返回值a的副本，因此修改的a非返回值a。\n在第四种情况中，return 1会先将值1赋给返回值a，接着执行defer函数，其中传参的值是返回值a的地址，因此修改对返回值a有效。\n执行机制 defer关键字的处理有3种方式：堆分配、栈分配、开放编码。\n  堆分配\n兜底方案。\n  栈分配\ndefer关键字在函数中最多执行一次。\n  开放编码\n 函数的 defer 数量少于或者等于 8 个； 函数的 defer 关键字不能在循环中执行； 函数的 return 语句与 defer 语句的乘积小于或者等于 15 个；   ","date":"2021-02-13","permalink":"https://why9661.github.io/myblog/posts/golang/defer/","series":null,"tags":["Golang"],"title":"Golang-Defer"},{"categories":["MySQL"],"content":"当数据库中有多个事务并发执行的时候，就可能会出现以下问题：\n脏读：A事务还未提交，B事务就读到了A事务的结果。\n不可重复读：A事务在本次事务中，对某行多次读取，结果出现了前后不一致的情况。\n幻读：一个事务在前后两次查询同一范围的时候，后一次查询看到了前一次查询没有看到的行。\n为了解决上面的问题，就有了“隔离级别”的概念。\n事务的四个隔离级别\n  读未提交（read uncommitted）\n一个事务还未提交它做的变更就可以被另一个事务读取到。\n  读已提交（read committed）\n一个事务提交后它做的变更才可以被另一个事务读取到。\n  可重复读（repeatable read）\n一个事务执行过程中看到的数据总是跟这个事务在启动时看到的数据是一直的。\n  串行化（serializable）\n对同一行记录，写会加“写锁”，读会加“读锁”。当出现读写冲突时，后来的事务必须等前一个事务执行完成才能继续执行。\n  InnoDB默认的隔离级别是RR，默认开启事务自动提交（autocommit=on）。\n1showvariableslike\u0026#39;transaction_isolation\u0026#39;;2showvariableslike\u0026#39;autocommit\u0026#39;;事务的开启与提交有以下两种情况：\n1、若参数autocommit=off，事务在用户本次对数据进行操作时自动开启，在用户执行commit命令时提交，用户本次对数据库开始进行操作到用户执行commit命令之间的一系列操作为一个完整的事务周期。若不执行commit命令，系统则默认事务rollback。\n2、若参数autocommit=on，事务的开启与提交又分为两种状态：\n①当用户执行start transaction（begin）命令时，手动开启一个事务，当用户执行commit命令时当前事务提交。从用户开启事务到用户提交事务之间的一系列操作为一个完整的事务周期。若不执行commit命令，系统则默认事务rollback。\n②如果用户未执行start transaction（begin）命令而对数据库进行了操作，系统则默认用户对数据库的每一个操作为一个孤立的事务（除了select），也就是说用户每进行一次操作系都会即时提交。这种情况下用户的每一个操作都是一个完整的事务周期。\ncommit work and chain会提交事务并启动下一个事务。\nInnoDB的行数据有多个版本，每个数据版本有自己的row trx_id，每个事务或者语句有自己的一致性视图，普通查询语句是一致性读（快照读），会根据row trx_id和一致性视图来确定数据版本的可见性。而更新数据都是先读后写的，这个读是当前读（读取当前数据的最新版本），此外加锁的查询语句（for update/lock in share mode）也是当前读。\n\u0026ldquo;可重复读\u0026quot;的一致性视图是在事务开始时创建的，而“读提交”的一致性视图是在每一个语句执行前创建的。\n需要说明的是，start transaction/begin并不是一个事务的开始，而是在执行第一个操作表的语句时事务才会真正启动，要想立马启动一个事务，可以用使用start transaction with consistent snapshot这个命令。\n第一种方式的一致性视图是在第一次快照读的时候创建的。\n第二种方式的一致性视图是在start transaction with consistent snapshot时创建的。\n接下来详细介绍数据版本的可见性是怎么确定的：\nInnoDB里面每个事务有一个唯一的事务ID，它是在事务开始前向InnoDB事务系统申请的，这个ID是按申请顺序严格递增的。\nInnoDB里每行数据也都是有多个版本的，每次事务更新数据的时候，都会生成一个新的数据版本，并且把事务ID赋给这个数据版本，记为row trx_id，同时旧的数据版本要保留，并且在新的数据版本中，能够有信息可以拿到它（回滚指针+undo log）。\nInnoDB为每个事务构造了一个数组，用来保存在这个事务启动瞬间，当前系统中\u0026quot;活跃\u0026quot;的所有事务ID（启动了但还未提交）。数组里面事务ID的最小值记为低水位，当前系统里面已经创建过的事务ID的最大值加1记为高水位。这个视图数组和高水位就组成了当前事务的一致性视图，而数据版本的可见性规则就是基于数据的row trx_id和这个一致性视图对比得到的。\n对于当前事务的启动瞬间，一个数据版本的row trx_id就有以下几种情况：\n1、如果落在绿色部分，表示这个版本是已提交的事务，可见\n2、如果落在红色部分，表示这个版本是由将来启动的事务生成的，不可见\n3、如果落在黄色部分，那就包括两种情况：\n​\ta.若row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见\n​\tb.若row trx_id不在数组中，表示这个版本是由已提交的事务生成的，可见\n更清晰明了的判断方式：\n1、一个事务的更新对自己本身总是可见的\n2、版本未提交，不可见；\n3、版本已提交，但是是在视图创建后提交的，不可见\n4、版本已提交，是在视图创建前提交的，可见\n例子\n1createtablet(2idintnotnullprimarykeyauto_increment,3ageint4);5insertintotvalues(1,10);   事务A 事务B 事务C     start transaction with consistent snapshot;      start transaction with consistent snapshot;      update t set age=age+1 where id =1;    update t set age=age+1 where id=1;select age from t where id=1;    select age from t where id=1;commit;      commit;     下面来看事务A的查询结果，事务A的一致性视图是最先创建的\n事务B更新后的(1,12)还未提交，不可见；\n事务C更新后的(1,11)提交了但是是在事务A视图创建后提交的，不可见；\n(1,10)是在事务A视图创建前提交的，可见；\n所以事务A查询到的结果是10。\n接下来看一下更新逻辑，需要注意的是更新逻辑是\u0026quot;先读后写\u0026rdquo;，这个读是当前读即读到的是这个数据最新的版本。\n所以对于事务B的查询结果：\n更新语句会先读，读到的是事务C更新后的(1,11)；\n然后写变为(1,12)；\n事务内的更新对自己总是可见的，因此查询B的查询结果是12。\n把上面的例子修改一下\n   事务B 事务C     start transaction with consistent snapshot;     start transaction with consistent snapshot;update t set age=age+1 where id=1;   update t set age=age+1 where id=1;\u0026ndash;阻塞select age from t where id=1;     commit;   commit;     再来看下更新逻辑：\n事务C更新后数据的最新版本为(1,11)，但还未提交；\n根据两阶段锁，事务C会一直持有id=1这行记录的写锁，直到事务C提交释放锁，因此事务B会先阻塞直至事务C提交；\n参考：\n《MySQL实战45讲》\n","date":"2021-01-20","permalink":"https://why9661.github.io/myblog/posts/mysql/%E4%BA%8B%E5%8A%A1/","series":null,"tags":["MySQL"],"title":"MySQL-事务"},{"categories":["Golang"],"content":"Go使用UTF-8作为默认编码方式。\nString类型的数据结构 每一个字符串在运行时都会使用如下的数据结构\n1type StringHeader struct { 2\tData uintptr //指向字节数组的指针 3\tLen int\t//数组的大小（字节数） 4} 因为String类型指向的底层字节数组是只读的，所以不能像这样修改字符串：\n1fmt.Println(str[0]) // √ 2str[0] = \u0026#39;h\u0026#39; // × 要修改字符串，可以给字符串赋新值。\n1str = \u0026#34;new string\u0026#34; 使用unsafe包对字符串原地修改\n1func main() { 2\ts1 := \u0026#34;Hello World!\u0026#34; 3\ts2 := \u0026#34;why\u0026#34; 4 5\ttmp1 := (*reflect.StringHeader)(unsafe.Pointer(\u0026amp;s1)) 6\ttmp2 := (*reflect.StringHeader)(unsafe.Pointer(\u0026amp;s2)) 7\ttmp1.Data = tmp2.Data 8\ttmp1.Len = tmp2.Len 9 10\tfmt.Println(s1) //why 11} 字符串遍历   普通for循环遍历\n遍历的是单个字节（byte）\n  for range遍历\n遍历的是单个字符（rune）\n  1a := \u0026#34;H\u0026#34; 2b := \u0026#39;H\u0026#39; 3var c byte 4c = \u0026#39;H\u0026#39; 5fmt.Printf(\u0026#34;%T\\n\u0026#34;, a) //string 6fmt.Printf(\u0026#34;%T\\n\u0026#34;, b) //int32(rune) 7fmt.Printf(\u0026#34;%T\\n\u0026#34;, c) //uint8(byte) 反引号\u0026amp;双引号 使用双引号声明的字符串和其他语言中的字符串没有太多的区别，它只能用于单行字符串的初始化，如果字符串内部出现双引号，需要使用 \\转义 符号避免编译器的解析错误，而反引号声明的字符串可以摆脱单行的限制。当使用反引号时，因为双引号不再负责标记字符串的开始和结束，可以在字符串内部直接使用 \u0026quot;，在遇到需要手写 JSON 或者其他复杂数据格式的场景下非常方便。\n1json := `{\u0026#34;author\u0026#34;: \u0026#34;draven\u0026#34;, \u0026#34;tags\u0026#34;: [\u0026#34;golang\u0026#34;]}` String的常用操作 标准库strings和strconv包含了很多String的常用操作。\n注意事项 String类型可以和[]byte和[]rune类型直接转换（开销并不低，会发生底层数组的拷贝）。\n通过unsafe包实现[]byte和string类型的转换\n1func byteToString(b []byte) string { 2\theader := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;b)) 3 4\tnewHeader := reflect.StringHeader{ 5\tData: header.Data, 6\tLen: header.Len, 7\t} 8 9\treturn *(*string)(unsafe.Pointer(\u0026amp;newHeader)) 10} 11 12func stringToByte(s string) []byte { 13\theader := (*reflect.StringHeader)(unsafe.Pointer(\u0026amp;s)) 14 15\tnewHeader := reflect.SliceHeader{ 16\tData: header.Data, 17\tLen: header.Len, 18\tCap: header.Len, 19\t} 20 21\treturn *(*[]byte)(unsafe.Pointer(\u0026amp;newHeader)) 22} 23 24func main() { 25\tb1 := []byte{65, 66, 67} 26\ts1 := byteToString(b1) 27\tfmt.Println(s1) // ABC 28 29\ts2 := \u0026#34;ABC\u0026#34; 30\tb2 := stringToByte(s2) 31\tfmt.Println(b2) //[65 66 67] 32} ","date":"2021-01-18","permalink":"https://why9661.github.io/myblog/posts/golang/string/","series":null,"tags":["Golang"],"title":"Golang-String"},{"categories":["Golang"],"content":"Golang中变量分配在栈上还是堆上，取决于变量是否发生了逃逸，逃逸分析是在编译阶段确定的。\n检测逃逸的命令\n1go run -gcflags \u0026#34;-m -l\u0026#34; main.go 2go tool compile -m -l main.go 3... 变量逃逸场景\n  指针逃逸\n这是变量逃逸最普遍的一种场景，即变量在其作用域之外被引用。\n1func escape() *int { 2\tx := 10 3\treturn \u0026amp;x 4} 5 6func main() { 7\t_ = escape() 8} 运行go run -gcflags \u0026quot;-m -l\u0026quot; main.go\n1.\\main.go:4:2: moved to heap: x   闭包引起的变量堆分配\n1func closure() func() int { 2\tx := 10 3\treturn func() int { 4 x++ 5 return x 6\t} 7} 8 9func main() { 10\t_ = closure() 11} 运行go run -gcflags \u0026quot;-m -l\u0026quot; main.go\n1.\\main.go:4:2: moved to heap: x   interface{}类型在编译阶段无法确定具体类型，发生逃逸。\n1func main() { 2\tx := 10 3\tfmt.Printf(\u0026#34;%v\u0026#34;, x) 4} 运行go run -gcflags \u0026quot;-m -l\u0026quot; main.go\n  1 .\\main.go:7:12: ... argument does not escape 2.\\main.go:7:13: x escapes to heap 3 10 1func main() { 2 x := 10 3 fmt.Printf(\u0026#34;%v\u0026#34;, \u0026amp;x) 4} 运行go run -gcflags \u0026quot;-m -l\u0026quot; main.go\n1 .\\main.go:6:2: moved to heap: x 2.\\main.go:7:12: ... argument does not escape 3 0xc00000a0a8   变量太大\n1func generate8191() { 2\tnums := make([]int, 8191) // \u0026lt; 64KB 3\tfor i := 0; i \u0026lt; 8191; i++ { 4 nums[i] = rand.Int() 5\t} 6} 7 8func generate8192() { 9\tnums := make([]int, 8192) // = 64KB 10\tfor i := 0; i \u0026lt; 8192; i++ { 11 nums[i] = rand.Int() 12\t} 13} 14 15func generate(n int) { 16\tnums := make([]int, n) // 不确定大小 17\tfor i := 0; i \u0026lt; n; i++ { 18 nums[i] = rand.Int() 19\t} 20} 21 22func main() { 23\tgenerate8191() 24 generate8192() 25 generate(1) 26} 运行go run -gcflags \u0026quot;-m -l\u0026quot; main.go\n1.\\main.go:6:14: make([]int, 8191) does not escape 2.\\main.go:13:14: make([]int, 8192) escapes to heap 3.\\main.go:20:14: make([]int, n) escapes to heap   一个有趣的例子\n1type Person struct{} 2 3func main() { 4\ta := \u0026amp;Person{} 5\tb := \u0026amp;Person{} 6\tfmt.Println(a == b) //false 很合理，栈上两个不同变量的地址 7} 1type Person struct{} 2 3func main() { 4\ta := \u0026amp;Person{} 5\tb := \u0026amp;Person{} 6\tfmt.Printf(\u0026#34;%p\\n\u0026#34;, a) 7\tfmt.Printf(\u0026#34;%p\\n\u0026#34;, b) 8\tfmt.Println(a == b) //true ？？？ 9} 原因：\n1、fmt标准库的Printf的方法导致原本分配在栈上的变量a、b逃逸到了堆上\n2、runtime的一个优化细节：0字节在堆上分配时都会指向zerobase这一个地址\n1// base address for all 0-byte allocations 2var zerobase uintptr 1type Person struct{} 2 3type Animal struct{} 4 5func main() { 6\ta := \u0026amp;Person{} 7\tb := \u0026amp;Animal{} 8\tfmt.Printf(\u0026#34;%p\\n\u0026#34;, a) //0xb8c578 9\tfmt.Printf(\u0026#34;%p\\n\u0026#34;, b) //0xb8c578 10} 参考：\n公众号：脑子进煎鱼了\n","date":"2020-12-02","permalink":"https://why9661.github.io/myblog/posts/golang/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/","series":null,"tags":["Golang"],"title":"Golang-逃逸分析"},{"categories":["Golang"],"content":"数据结构 哈希冲突\n由于输入空间总是会大于输出空间，所以哈希冲突是不可避免的。\n解决哈希冲突通常有两种方法：开放地址法和链地址法。\n开放地址法 如果使用开放地址法来实现哈希表，那么实现哈希表底层的数据结构就是数组。\n链地址法 链地址法是哈希表最常见的实现方法。\n通常实现链地址法是采用数组加链表的方式。\n负载因子\n负载因子=键值对数 / 桶数\nGo语言的哈希表本质上是一个指针，指向一个runtime.hmap结构体。\n1type hmap struct { 2\tcount int\t//哈希表当前键值对数 3\tflags uint8 4\tB uint8 //桶的数目，len(buckets) == 2^B 5\tnoverflow uint16 6\thash0 uint32//哈希种子 7 8\tbuckets unsafe.Pointer //桶 9\toldbuckets unsafe.Pointer //旧桶 10\tnevacuate uintptr //即将迁移的旧桶编号 11\textra *mapextra 12} 13 14type mapextra struct { 15\toverflow *[]*bmap 16\toldoverflow *[]*bmap 17\tnextOverflow *bmap 18} 桶对应的数据结构是runtime.bmap。\n一个桶可以存储8个键值对，为了内存排列更紧凑，8个K放一起，8个V放一起，同时将每个K的哈希的高8位保存起来，还存有一个指针，指向一个溢出桶。当哈希表中存储的数据过多，单个桶已经装满时就会使用 extra.nextOverflow 中桶存储溢出的数据，溢出桶的使用可以减少扩容频率。\n在创建哈希表时，如果要分配的桶的数目大于2^4，那么就认为使用到溢出桶的概率比较大，会预创建2^(B-4)个溢出桶。溢出桶和常规桶在内存中是连续的。\n扩容规则 哈希表在以下两种情况会触发扩容：\n1、负载因子\u0026gt;6.5\n2、使用了太多的溢出桶\n翻倍扩容 负载因子超过6.5时，会触发翻倍扩容，分配新桶的数目是旧桶的两倍。每个旧桶中的键值对会分流到两个新桶中。\n等量扩容 使用溢出桶较多会触发等量扩容，分配新桶的数目和旧桶相同，将旧桶中的键值对迁移到新桶中。\n等量扩容的意义\n在很多键值对被删除的情况下，会出现负载因子没有超过上限值，但使用了很多的溢出桶。此时触发等量扩容将旧桶的键值对迁移到新桶，可以使哈希表排列紧凑，减少溢出桶的使用。\n注意事项 map不是并发安全的 1//fatal error: concurrent map writes 2func main() { 3\tc := make(map[string]string) 4\twg := new(sync.WaitGroup) 5\tfor i := 0; i \u0026lt; 10; i++ { 6\twg.Add(1) 7\tgo func(n int) { 8\tdefer wg.Done() 9\tk, v := strconv.Itoa(n), strconv.Itoa(n) 10\tc[k] = v 11\t}(i) 12\t} 13\twg.Wait() 14} 解决办法：1、加锁；2、sync.Map\nkey一定是要能比较的类型 也就是说，slice、function、map不能作为key。\nvalue可以是任意类型。\n操作未初始化的map 基于map的大部分操作，包括查找、删除、len、for\u0026hellip;range都可以安全地工作在为nil的map上，它们的行为和一个空的map类型。但是不能给为nil的map添加键值对。\n1//panic: assignment to entry in nil map 2var m map[string]string 3m[\u0026#34;why\u0026#34;] = \u0026#34;xp\u0026#34; map的遍历是无序的 解决办法：遍历一次得到所有key，将key排序，然后按序读取value。\n","date":"2020-11-09","permalink":"https://why9661.github.io/myblog/posts/golang/map/","series":null,"tags":["Golang"],"title":"Golang-Map"},{"categories":["Golang"],"content":"为了保证程序的执行高效与安全，现代编译器并不会将程序员的代码直接翻译成相应地机器码，它需要做一系列的检查与优化。Go编译器默认做了很多相关工作，例如未使用的引用包检查、未使用的声明变量检查、有效的括号检查、逃逸分析、内联优化、删除无用代码等。本文重点讨论内联优化相关内容。\n在Go中，一个goroutine会有一个单独的协程栈，协程栈又会包含多个函数栈帧，栈帧是函数调用时在栈上为函数所分配的区域。但其实，函数调用是存在一些固定开销的，例如维护帧指针寄存器BP、栈溢出检测等。因此，对于一些代码行比较少的函数，编译器倾向于将它们在编译期展开从而消除函数调用，这种行为就是内联。\n在程序代码中，想要禁止编译器内联优化很简单，在函数定义前一行添加//go:noinline注释即可。\n一个例子展现内联与禁用内联的性能差异\n1//go:noinline 2func maxNoinline(a, b int) int { 3\tif a \u0026gt; b { 4\treturn a 5\t} 6 7\treturn b 8} 9 10func maxInline(a, b int) int { 11\tif a \u0026gt; b { 12\treturn a 13\t} 14 15\treturn b 16} 17 18func BenchmarkNoinline(b *testing.B) { 19\tx, y := 1, 2 20\tb.ResetTimer() 21\tfor i := 0; i \u0026lt; b.N; i++ { 22\tmaxNoinline(x, y) 23\t} 24} 25 26func BenchmarkInline(b *testing.B) { 27\tx, y := 1, 2 28\tb.ResetTimer() 29\tfor i := 0; i \u0026lt; b.N; i++ { 30\tmaxInline(x, y) 31\t} 32} 33 34BenchmarkNoinline-4 280228629 4.380 ns/op 35BenchmarkInline-4 1000000000 0.5226 ns/op 可以使用内联的条件：\n function should be simple enough, the number of AST nodes must less than the budget (80); function doesn\u0026rsquo;t contain complex things like closures, defer, recover, select, etc; function isn\u0026rsquo;t prefixed by go:noinline; function isn\u0026rsquo;t prefixed by go:uintptrescapes, since the escape information will be lost during inlining; function has body; ","date":"2020-09-13","permalink":"https://why9661.github.io/myblog/posts/golang/%E5%86%85%E8%81%94/","series":null,"tags":["Golang"],"title":"Golang-内联"},{"categories":["Golang"],"content":"Slice的数据结构 slice在运行时使用以下的数据结构(reflect.SliceHeader)\n1type SliceHeader struct { 2\tData uintptr //指向第一个slice元素对应的底层数组元素的地址 3\tLen int\t//切片长度（slice的元素数目） 4\tCap int\t//切片容量（从slice的开始位置到底层数据的结尾位置的长度） 5} 注意以下声明切片的方式：\n1var s1 []int //Data=nil Len=Cap=0 没有分配底层数组 2s2 := make([]int, 0) //Data!=nil Len=Cap=0 分配底层数组 3s3 := []int{} //Data!=nil Len=Cap=0\t分配底层数组 4s4 := new([]int) //指向一个（Data=nil, Len=Cap=0）的slice 没有分配底层数组 多个slice可以共享底层数组，因此对一个切片的元素修改也会影响其它切片。\n1arr := [...]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10} 2s1 := arr[2:5] 3s2 := arr[3:6] 4fmt.Println(s1) //3,4,5 5fmt.Println(s2) //4,5,6 6s1[1] = 44 7fmt.Println(s2) //44,5,6 slice比较 slice不能直接用==比较。\n对于byte类型的slice，可以用标准库的bytes.Equal函数进行比较。\n对于其它类型的slice：\n  比较两个切片的长度，且两个切片对应下标的值也相等\n  reflect.DeepEqual\n两种方法简单的性能比较：\n1func genSlice(size int) ([]uint32, []uint32) { 2\trand.Seed(time.Now().UnixNano()) 3\ts1 := make([]uint32, 0, size) 4\tfor i := 0; i \u0026lt; size; i++ { 5 s1 = append(s1, rand.Uint32()) 6\t} 7\ts2 := make([]uint32, len(s1)) 8\tcopy(s2, s1) 9 10\treturn s1, s2 11} 12 13func compare(a, b []uint32) bool { 14\tif (a == nil) != (b == nil) { 15 return false 16\t} 17 18\tif len(a) != len(b) { 19 return false 20\t} 21 22\tfor i := range a { 23 if a[i] != b[i] { 24 return false 25 } 26\t} 27 28\treturn true 29} 30 31func BenchmarkCompare(b *testing.B) { 32\ts1, s2 := genSlice(1000) 33\tb.ResetTimer() 34\tfor i := 0; i \u0026lt; b.N; i++ { 35 _ = compare(s1, s2) 36\t} 37} 38 39func BenchmarkDeepEqual(b *testing.B) { 40\ts1, s2 := genSlice(1000) 41\tb.ResetTimer() 42\tfor i := 0; i \u0026lt; b.N; i++ { 43 _ = reflect.DeepEqual(s1, s2) 44\t} 45}   1 go test -bench=. 2 BenchmarkCompare-4 1621315 672.8 ns/op 3 BenchmarkDeepEqual-4 10000 137540 ns/op slice扩容   预估扩容后容量\n 如果扩容前容量*2\u0026lt;所需容量，那么预估容量=所需容量 如果扩容前容量*2\u0026gt;所需容量  如果切片长度\u0026lt;1024，那么预估容量=扩容前容量*2 否则预估容量=扩容前容量*1.25，直到预估容量\u0026gt;所需容量      计算所需的内存\n预估容量*元素类型大小\n  匹配合适的内存规格\n匹配足够大且最接近的规格\n  确定容量\n内存大小/元素类型大小\n  slice拷贝 拷贝的长度length=min(len(dst), len(src))\n1func copy(dst, src []Type) int 注意事项   Slice发生扩容时，会重新分配底层数组\n  对没有分配底层数组的slice进行赋值操作会触发panic，可以进行append操作。\n1var ints []int 2ints[0] = 1 //panic 3 4ints = append(ints, 1) //√   临界问题\n1func main() { 2\tnums := []int{1,2,3} 3\tnums1 := nums[:0] //ok 4\tfmt.Println(nums1, len(nums1), cap(nums1)) //[] 0 3 5\tnums2 := nums[3:] //ok 6\tfmt.Println(nums2, len(nums2), cap(nums2)) //[] 0 0 7} 1func main() { 2\tnums := make([]int, 1, 3) 3\tfmt.Println(nums[0]) 4\tfmt.Println(nums[1]) // panic越界访问 5}  ","date":"2020-07-05","permalink":"https://why9661.github.io/myblog/posts/golang/slice/","series":null,"tags":["Golang"],"title":"Golang-Slice"},{"categories":["Golang"],"content":"make的作用是初始化内置的数据结构，切片、哈希表和Channel。\nnew的作用是根据传入的类型分配一片内存空间并返回指向这片内存空间的指针。\nmake和new有哪些不同？\n  make仅用于slice、map、channel三种类型的创建，返回的是所创建类型本身。\nnew可用于任意类型的创建，返回的是指向所创建类型的指针。\n  make创建slice、map、channel时会初始化内部数据结构，如slice的创建，会分配底层数组(Data)、初始化长度（Len）、初始化容量（Cap）。\nnew不会对内部数据结构进行初始化。\n  关于make和new创建的变量是分配在堆上还是在栈上，需要进行逃逸分析，这和其它一些语言的new分配在堆上不同。\n ","date":"2020-06-05","permalink":"https://why9661.github.io/myblog/posts/golang/make%E5%92%8Cnew/","series":null,"tags":["Golang"],"title":"Golang-内置函数make和new的区别"}]